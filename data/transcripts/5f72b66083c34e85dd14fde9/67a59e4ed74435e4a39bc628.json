{
  "pid": "5f72b66083c34e85dd14fde9",
  "eid": "67a59e4ed74435e4a39bc628",
  "title": "Vol.217｜DeepSeek算命，AI能帮忙找到幸福吗？｜嘉宾：刘擎×翟志勇",
  "task_id": "gpjbqkmrylpenk2a",
  "transcription": [
    {
      "time": "00:00:00",
      "text": "人们经过使用AI的辅助，甚至主要使用AII的这样一个它的生成，造就那些新的话语、新的观点、新的论证、新的证据。他回到了AI那个语料库，那么就非常麻烦了。到最后我们就是真假难辨。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:19",
      "text": "AI生产的内容很容易模糊，真实与虚拟。以至于我们今天很多看到社交媒体上的视频，大家都不知道它到底是现实拍的，还是人工智能虚拟出来的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:32",
      "text": "人文社会科学的学者对于公共政策的制定来说，提出了一个非常高的要求，就是你能够提供什么样的规则。",
      "speaker": "发言人3"
    },
    {
      "time": "00:00:40",
      "text": "技术不管是实现我目标的工具，然后技术它其实在塑造我们，它已经显著的脱离了文化演化的那个能够吸纳的进程，这才是那个基点真正令人震惊的原因。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:02",
      "text": "大家好，欢迎收听由大观天下制作播出的播客东腔西调，我是何必。今天我们请到两位老朋友聊一期非常前沿的话题。这两位老朋友就是来自华东师范大学紫江特聘教授刘醒老师和来自北京航空航天大学法学院的翟志勇老师。两位老师和大家打个招呼。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:25",
      "text": "东山区朋友们大家好，我是刘晴。非常高兴在这里能够跟何必跟志勇一起来探讨一个新的有意思的话题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:33",
      "text": "东腔西调的朋友大家好，我是翟志勇。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:37",
      "text": "今天这个前沿的话题就是人本智能AI时代我们如何生活的更幸福。说到AI其实是这两年非常热门的一个话题，业界很多人都在讨论。在新年第一周，人工智能的领域又有两个大佬发了两篇重磅的文章或者是演讲。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:58",
      "text": "第一篇是1月6不好，OpenAI的奥特曼发了一篇博文，他说OpenAI基本明确的找到了通向通用人工智能AGI的路径。也就是说在今年或者是很短的一段时间内，奥特曼很乐观的认为OpenAI可以找到一整套的通用人工智能，就不再需要一个单个的这种特殊的算法模型了。然后同时他也认为说今年第一批人工智能体就能进入到劳动力市场。我猜想因为OpenAI主要是在做软件性的工作，他可能会今年找一些机器人厂商共同合作，来去做一些能够实施通用人工智能的智能体，在劳动力市场做一些试水。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:49",
      "text": "第二篇是1月7号，英伟达的黄仁勋在CES就是美国消费品电子展览上谈了英伟达的今年的五个展望。其中有一个展望让我特别的震惊，就是他提了一个概念叫物理AI那什么是物理AI呢？他说今年英伟达要推出一个Cosmos世界基础模型。因为在训练AI大模型的时候，通常需要现实世界里的很多数据输入进去，让AI去自主的学习。而这个过程本身其实是有很多的障碍或者是低效率的。所以黄仁勋就说我要去创造一个世界基础模型，把目前当下现实世界里所有的物理定律都放到这个模型里面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:38",
      "text": "到时候每个AI厂商想要去训练自己的AI都可以用我这个基础模型。比如说有一个厂商想训练一个山地地区，可以开展交通的AI算法，那他就直接用这个cos mouse，直接用这样一个世界基础模型，虚拟出一个山地世，也让AI公司去训练。那这样的话就是AI本身几乎可以就完成了一个自循环了。就是我自己生产出一个环境，虚拟出一个很现实的环境，然后让AI自己去可以说六号和七号这两篇很重磅的文章和演讲，再一次向大家展示了AI人工智能给我们未来的发展带来的一系列的愿景。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:26",
      "text": "但是我们也知道AI发展的如此迅速，但是也给我们带来了很多的问题。比如之前我们一直在讨论AIGC，也就是AI生产的内容很容易模糊真实与虚拟。以至于我们今天很多看的社交媒体上的视频，大家都不知道它到底是现实拍的，还是人工智能生产出来的。再比如很多厂商其实在一些陪伴性的游戏里面就嵌入AI可以做这种情感陪伴。越来越多的人可能觉得AI要比周围现实中的人更了解自己。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:02",
      "text": "再有就是像我们做内容的会特别敏感，就是AI生产了很多文字、图片、视频信息，那这些信息它的版权是谁的？是AI自己的，还是我们给AI发命令的这些人的版权，还是说就压根就没有版权了。我想这一些都是我们现在当下世界运行里面和AI不太能够去适应的这些矛盾的地方。所以今天就想请两位老师一起来聊一聊，既然AI技术发展如此迅速，同时又和我们当下世界有这么多的矛盾和冲突。那我们如何去适应它，如何能够让AI技术能够让我们生活的更幸，关于人和技术矛盾的这个问题，其实我自己有一个基本认识，就是这个东西应该不是一个新问题。两位老师感觉。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:51",
      "text": "我先讲一个有点体感的这个状态。就是你现在看这个只要你用社交媒体或者任何媒体，大概我一个星期会收到3次或者两三次，又有一个突破，然后这真是逆天了。你就然后你会非常惶恐，然后对你的这个实际生活有什么影响。像我们这种人是跟这个世界会有一个习惯，是要保持一定距离。你就是说不能随着这个随波逐流，世界上什么流行了，什么时尚了，你就跟着走。我们是我们是不是紧跟的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:26",
      "text": "但是现在在这样一个话语环境下，你会惶恐。因为你发现他有一个非常大的改变，就是由于它是跟内容生产有关系的，像AIGC这种。然后你现在像我们这种人是内容生产，也算是就是你要输出一些，无论是你的演讲视频、备课、写作、著作研究，这时候你会发现出现了一个第三方。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:54",
      "text": "以前是没有的。以前就是我针对我的读者，现在我在上说这个话的时候，在做这个论证的时候，想这个观点的时候，我要问问这个人我要问问这不是人，问问ChatGPT怎么说的，问问其他的人工智能的，就是他们最新的研究是不是有有新的东西。然后你会心猿意马，你真的是会被disturbing的，会被烦扰到的。因为你你对自己不确信的，以前你看我搜查到的文件好，我就开始展开了。现在做一个事情维持特别慢的来说，现在他会怎么说？就出现了一个第三方。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:33",
      "text": "而且这个第三方不光是他生产的东西，他生产的那些话语形象也好，他又进入到了我们现在的语料库，进入到了我们的这样一个话语当中。也就是说它不光是版权的问题，它会再生产。就是说AII自己也会受到人们经过使用AI的辅助，甚至主要使用AI的这样一个它的生成，造就那些新的话语、新的观点、新的论证、新的证据。他回到了AI的那个那个语料库，那么就非常麻烦了，到最后我们就是真假难辨。有的时候AI告诉我们这样我还不能确认，我还要用其他的AI的不同AI的软件来相互让让他们这个cross check相互对，看一下就就你你现在你现在的生活实际上就对我来说就这几个月。非常强的觉得存在着一个第三方力量。这个第三方力量是崭新的，因为它是进入了我们的话语系统的，这个是一个切实的问题。我不知道智勇会有这种感受吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:43",
      "text": "对，翟老师你在自己的工作中有没有感觉到AI开始入侵你的生活和工作了？",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:50",
      "text": "入侵其实上是会有了，因为基本上你会主动的去用它，有时候你也会被动的会去用，对吧？被动用主要是学生用这个ChatGPT写作业，你怎么样能够识别出来？对我今年在课堂上经常虽然我一再强调，但是仍然能够看得出来有些学生会用这个大模型来写作业。你被迫的要去使用这个技术熟悉它。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:18",
      "text": "刚才刘老师分享，我突然也想到一个前两天和一个画家朋友聊天的一个讨论，特别有意思。因为他发给我一个有人写的一个文章，他想在抱怨什么呢？抱怨说他现在想在网上找一些图片，大家已经很难找到人拍的那个图片了，很多的图片都是AI生成的。就是你去搜索一个什么主题，比如马上十年了，你要搜索一个什么主题的图片出来的，排在前面的大部分都是AI生成的。他想去找一个比如人画的，人拍的就已经很难了。然后这朋友是个画家的朋友，他就想说我们将来还存在还有什么意义了？",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:00",
      "text": "对，画家就是要创作这个作品的本身就是要创作的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:04",
      "text": "但是后来我就安慰他，我说你要这么想，就是当我们每个人去网上搜图片的时候，我们搜的都是AI生成的。我们特别想渴望有一个人画的图片的时候，画家的意义真正的凸显出来了。就是你创作出来的，你自己亲笔画的那个画，未来会特别的珍贵。因为我们其他的都是AI生成的，反而人创造出来的是一个特别珍贵的东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:27",
      "text": "志勇谈到这个我就只想插一句，就是在大机器工业时代会发展出一个叫手工制品。当然他们仍然打不过整个大机器流水线的生产。比如说手工刺绣对吧？然后手工的水饺，对它不是那种。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:43",
      "text": "机械手表跟电子表，这是一个非常典型的例子。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:47",
      "text": "就是是man made homemade这样的食品也好，用品也好，但是他们仍然存在是小众。我在想现在网络上是不是会办一个网站，说我们这里所有照片都没有美颜的，就去美颜素颜这个图库。然后还有就是无论是你绘画也好，视频也好，完全不借助AI会有人做这个的。因为就像刚才志勇谈到那个画家的那样一种关切，他那种忧虑会有人做。但是我觉得他是非常小众的。所以现在我们用多少是home made，就是有人做的，比如说奶茶是自己怎么样做的，手手水水饺是人工感的包的，它它是会存在，它是由于有大工业的这样的生产，他会有他的自己的特色，但是确实特别少了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:39",
      "text": "对我想接着刚才刘老师说，就是您提到了大工业对于人的生活的改变。其实在这个意义上我们会发现，新技术对于人类自身熟悉的社会的冲击，并不是第一次AI某种影响。只是我们在近500年进入现代社会，不断的技术。眼睛中最新的一朵浪花。此前在这个过程中，我们知道像大航海时代，欧洲的这种商人可以从美洲攫取大量的金银，改变欧洲的这种的社会结构。再比如说像刚才老师讲的就是大机器工业，最典型就是食品工业，就可以通过工厂生产食品，能够养活很多人。但是我们之前特别熟悉的小时候妈妈的味道，就那些手工的东西反而变成了某种奢侈品。就在不断的冲击着既有的这样一个社会体制。两位老师能不能从各自比较熟悉的角度先给我们回顾一下，就是过去500年有哪些技术进步或者是重要的技术发明，对人类社会产生了非常大的冲击。以至于在思想史的角度，在制度史的角度，让人们做了一些对于我们现在来说很熟悉也很重大的这种改变或者突破思想首先。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:05",
      "text": "说首先是一个对技术的理解的问题。最早我们有一个比较朴素的技术观，就是技术工具人。我们知道技术先开始是把它看作人类的肢体的延伸。可能最早掌握的技术，人类最早掌握技术是火，火当然是自然的东西，森林的火。但是对火的驯化的使用是人类最早的，就是它可以用来取暖、烹饪、防止野兽，到后来我们发现这种技术它不是一个工具。这个观点大概至少到海德格尔那里就有了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:39",
      "text": "但最重要的一个技术哲学家之一，是法国哲学家stiller。在他不久前刚刚去世，他就认为讲人这个技术是会塑造人的。就是我们以前讲技术，它可能行善，可能作恶。技术本身是中立的，技术是造福人类还是会带来灾难的，取决于我们人谁来用，怎么来用，人类怎么样来对待技术。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:03",
      "text": "但是你会发现它是有两面的。一方面是说对于我们现存的人类的心智认知和价值观来说，这个技术给我们来实现我们本来已经有的那些理想、愿望、目标，带来了更快捷、更便利、更有效的工具。但是只是一面，另外一面他重新塑造了我们的愿望，我们的欲望。比如我可以举两个例子，一个就是我们如何看待人自己的欲望。比如说避孕工具。改变了我们的弗洛伊德以后，弗洛伊德产生的这个思想在20世纪初就有了，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:43",
      "text": "但它带来的性解放的那个运动，作为一个社会运动和社会思潮，大概要五六十年代、六七十年代以后才发生的。因为那个技术变得available了避孕工具，于是我们对性有了重新的认识，就是性欲望变得正当化了。他不再是说是羞耻的，是需要接受宗教和社会传统的那些规训，是需要压制的，疏解的，而它是正当的，是可以积极去追求欲望的。这个性的思想就是人类你看新演化出来的面对的技术的一个适应。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:21",
      "text": "另外就是一个关于工作，因为比如说大的工业文明带来的那个人的在流水线上那个工作，他变得是非常把人也变成了机器。人是机器，好像机器整个流水线的一部分。而不是一个活生生的一个有有感情的，有喜怒哀乐的人。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:41",
      "text": "那这时候如何理解工作当中对工作有新的看法？比如说韦伯讲的说，工作本身是跟工作伦理有关系的，把工作神圣化。但后来发现这个东西它不起作用。是这个是在齐格蒙特鲍曼写的那个工作消费主义和新穷人里面，他专门讲了我们怎么样让工作能够重新变得有意义、有价值。因为工作是劳苦的，不光是在体力上牢固，它主要在精神上，你发现你就是一个大的流水线的一部分，你淹没掉了，你没有对那个产品的整体感。最后他就是说我们建立了新的一个想法，我工作只是把自己当做工具，但是我又可以把自己当成目的的地方是什么呢？消费是对我那些在工作当中受苦售出的那些付出的辛苦的一个巨大的奖赏。消费主义就开始变成了好像我们应对这样一个技术，使得工作无意义的一个补偿。有很多很多思想，有的思想就可以说是意识形态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:40",
      "text": "就出来了。刘老师后面讲的这两个案例其实非常有有代表性，而且非常有意思。就是一方面我们看到技术的演进对人的思想，对人的现实生活都有很多的具体的影响。然后最简单，比如说像刚才讲的这种时空时空观的转变，以及对于工作观念，对于生育观念和性观念的这种变化。另一方面我们也知道刚才刘老师最后讲的说工作伦理要和消费结合在一起。这个事儿要想能够完成一个循环的话，就得有制度上的安排。我们就要有严格的工作福利保障，有严格的休假制度，你才能有充足的时间去消费，你才能把工作赚就赚到的钱去花。除了这种很具体的制度之外，翟老师您有没有从更宏观的制度，或者是更宏观的这种社会规则的这种角度去看，近500年技术进步给人类带来的很重要的遗产。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:42",
      "text": "我觉得有一些点可以作为我们观察的出发点。第一个就是技术发展本身的不可预期。就是很多重要的技术的诞生其实上都是偶然性的。波兰亚瑟有本书叫做技术的本质，他也在讲，其实我们说的所有的技术，其实都是过往各种积累，各种小的技术积累。积累到一定程度的时候，它突然一个大的变化。比如说智能手机，就是苹果发明这个iphone之前，其实所有的技术都存在了。对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:18",
      "text": "只不过是它重新组合了一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:20",
      "text": "那个时候它能够把它重新组合的智能手机就出来了。然后它就会带来非常大的一些的影响。回到技术的历史，你会发现大部分技术其实都不是在预期之内发生的，都是在预期之外去发生的。所以这是第一个就是技术本身的发展实际上是不可预期的，非常大的不确定性。今天我们讲这个人工智能其实也是一样。你看这些大佬今天说这个，明天说那个，对吧？每个人都在预测，其实每个人都没有那么确定说未来一定会是怎么样。第二个是技术产生的社会的影响，也是完全不可预期的。就是大行海的时候，更多的是他只是想找到一条通往东方的贸易路线。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:05",
      "text": "多赚点钱。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:06",
      "text": "对但当地这个贸易路线被开通之后，你会发现它带来的就不仅仅是贸易了，带来的不仅仅是赚钱了。比如说贩卖黑奴，这完全不在他们最初的预料之内，对吧？以及因为贸易路线的开辟，后来带来的大的工业化的生产，其实这也不在他们的预期之内，那他所带来的这种刚才刘静老师讲的对人的时间感、空间感的改变，这也完全不在预期之内。所以技术的产生所带来的社会效应，它是个滞后的效应。它可能过了十年、20年，甚至是说更长的时间，我们才会发现，原来发生的种种变化是因为之前的某一个技术上的变化所产生的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:53",
      "text": "第31点，回到你刚才反复讲到的，比如说法律也好，制度也好，其实他的回应会更慢。因为法律对于社会现象的回应往往是某一种新的东西出现，而且他形成一定的模式之后，他还会去做出一个回应。也就是说立法者其实更不会去主动的去预期说未来会发生什么，我提前给他制定法律，而不是立法者往往是说一个事情反复的出现，大家认为说他不得不去管了，不得不去通过法律来去治理了，那他才会进行立法。我可以举个例子，比如说因为刚才刘老师也提到这个工作，工人你也提到我们现在都会知道，我们工作有各种各样的工作福利，也有各种各样的工作的保障。那包括工作场所的安全的保障。但实际所有的这些东西，都是技术带来的一系列的社会灾难之后的结果。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:59",
      "text": "就是每一条安全规则后面都是一系列血泪的故事。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:02",
      "text": "对，比如说消防，其实早年曼哈顿兴起也是好多的制衣工厂，有点类似于我们东莞这种质疑工厂一样。其实就很简单的，楼里边很多的人在那做衣服，然后就发生了大火，造成了很多的女工的死亡。然后大家才会知道要有消防，要有这个工作环境的安全的保障，要有逃生的通道。所以我们法律里边有一本书叫做事故共和国。其实主要是讲美国，就是美国的法律的变迁是如何通过一个个血泪的故事，造就的一系列的法律上的制定也好，变革也好。所以就是从技术的产生到它所造成的社会的效应，再到比如思想家学者对于这些社会效应的讨论形成一些共识，再到法律和政策的回应，实际上是一个很漫长的一个发展的过程，当然可能在过去会更漫长，那现在可能会回应的更为及时。比如说现在AI一出现，立刻有非常多的讨论，然后就有欧盟就通过了人工智能法，这是因为技术的节奏太快了，它带来的社会变化也特别快。所以因此的话他就要求要学者也好，立法者也好，你要迅速的去做出一些回应。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:23",
      "text": "我觉得刚才翟老师的这样一个解释，深刻地印证了黑格尔的一句话，密涅瓦的猫头鹰总是要在黄昏后才起飞。就是思想这个东西一定是要在经验的事实已经出现了以后，才能对它做一定的回应。但是今天我们讲AI的这个主题，讲人本智能的这个话题，我想有一个很重要的现实性的因素，就是AI技术发展的太快了。而且不仅发展的快，他和我们个人结合的也越来越紧密了。比如说我在准备。咱们今天这一期播客的时候，我也运用了AI技术。既然是AI主题，我也要运用一下AI技术。我就尝试把国内几个目前主流的AI都注册了一下，然后我用相同的问题去问他们，让准备比如说关于人工智能在2016年就是阿尔法狗产生以来的时间线的分析。再比如说像人工智能可能给我们目前的社会造成的一些矛盾或者一些张力，有哪些比较典型的案例来问他们不同的。然后两位老师要是看这个电子稿，后面我会有很多参考材料。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:36",
      "text": "这一次的这五六条参考材料都是AI生成，而且这个速度真的很快。以往要想查这些材料，我每一个问题都要在搜索里面去查，然后把不同的这个网页阅读它，我们读一遍，然后自己再总结，然后再会起来。现在不用3个AI1开并列的，然后一比较一下，而且他们生成文本结构都特别，我就复制下来，然后一比较再再稍微润色一下就可以了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:05",
      "text": "在这个意义上我们会发现AI技术跟过往的技术的爆发有一个很不一样的特点。就是它能够非常深刻的影响到我们个人的生活。就像最开头刘老师您刚才讲的，就是它甚至形成了一个AI内容生产的回音壁，AI生产东西给了我，然后我今天做的这一期内容，说不定下一次谁在想搜索的时候，AI又把我的内容再检索到了，然后他又去把它作为一个AI产生的内容又给了别人，就形成这样一个不断的婚姻。在这个状况下，人们可能会遇到一些之前这500年我们没遇到过的情况。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:46",
      "text": "刘老师您在11月份参加财新峰会的时候，也讨论了人工智能的善治之道，一个很主题性的论坛。在这里面您有一段话让我印象非常深刻。就是您说人类正在转向三无人类的状态，无历史的时间感，无实体的空间感，无目标的体验感。在未来的虚拟空间里，有虚拟的国度，虚拟的星球，甚至还有虚拟的恋人。您似乎对未来这种AI对我们人的影响有一个预想。目前我看到的很多报道里面，其实只是把您这段经典的话给列出来。我很想听听您是为什么会做出这样的判断，以及您的这个判断能不能向我们再展开一下。您觉得AI这项技术，人工智能这项技术给我们自身带来了什么样的这种变化？这个三无到底是什么呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:44",
      "text": "就是我刚才开始讲的，就是我们摒弃了一种叫技术工具论的看法，对吧？技术不光是实现我们目标的工具，然后技术它其实在塑造我们，这是所谓技术生成论。Take genders这些一个观点，像那个库兹韦尔，他也是说的库兹韦尔他就是祭奠临近的那个作者，他说我们的技术和机器其实就是我们的humanity的一部分。我们扩创造他们来扩展我们自己，这正是人类的独特之处。他是意识到这个问题，就是说技术会改变人类，会生成我们人的很多很多非常基础性的层面。但他他是非常乐观的一个人，或者说他是一个基础乌托邦主义者或者加速主义者。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:31",
      "text": "但是我们发现在历史上我们都是要想通过文化演化来适应的。但是这一次我觉得你你你想我们人类说我们每次对新的技术，从路德派的砸机器这些好像都说当时都很恐慌，但后来都还可以，还我们就走过来了，对吧？比如说对环境的破坏，我们后来有了环保主义运动，有了环境运动，比如说生态的这个伦理，这些都都发展出来。但是你想其实我们整个20世纪，我们适应的并不那么好。我们20世纪留下了很多问题，包括现在一直谈谈的那个精神世界的那种迷茫，现在每一代年轻人都会有的那种所谓相对主义、虚无主义的问题，一直是所谓现代性的问题。它在某种意义上或者在某个层面上，它就是技术适应不良的反应。而这一次我觉得是我觉得人的理想从没有出现过这样的时刻，就是技术发展到如此的它是迅猛，他已经显著的脱离了文化演化的那个能够吸纳的进程，这才是那个基点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:47",
      "text": "真正令人震惊的原因，就文化在以前它有蛮大的适应能力，包括对火药、蒸汽机、印刷术、电气升级、通讯技术，我们都好像还勉强适应了。但这次你会发现吗？他那个升级换代，你知道现在的那个代机划分之细密，以前比如说我们就十年或者五年十一代，现在人家说95后和00后都不能够完全算作一代了。现在人家讲什么JZ就是Z世代，所以Z世代这个太粗了，因为有些人他就是特别能够适应最新一代的技术，因为他们是原住民，天然就好。我们好多人都是技术的移民，就是你你很多技术还来不及，新的这个技术还来不及，我们还没没用熟它，还不知道怎么掌握，甚至不知道怎么操作。它已经升级换代了，他已经有新的update upgrade，有新兴的升级版了。最重要的是他现在是他那个介入如此之深，他成了我们构成性的一部分。就包括刚才讲话语，我讲的这个三无，其实它是构成了我们最重要的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:07",
      "text": "就是说我们人如果作为一个文化存在，我们的时间感、空间感、社群感都是在跟自然、跟他人、跟自我这三重关系当中建立的。它最终会构筑我们的一个意义结构，或者说意义阐释结构。我们知道人的意义它是赋予它不是一个动物性的自然的这样一个结构。它是但是这个意义阐释结构一般来说是要有一个连续的时间，连续的明确的空间和一个分布自己能够掌握的一个跟他人的关系网络在里面能够建立一个相对完整的意义阐释结构。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:57",
      "text": "但是你看现在我们的时间是破碎的。还不光是说我们经常在使用短视频这样一些东西，我们其实在多个时间频道上生活的。就是为什么说我会说一个是没有历史的时间。没有历史的时间是说我们的时间，我们对过往的追溯，它不再能够安排在一个相对来说完整连续的叙事框架里面。我们讲自己的过往会讲出一大堆故事。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:30",
      "text": "比如说我现在在工作，这是一条时间线，朝九晚五也好，996也好，它相对来说是有这样一个被公司的这样一种工作纪律安排的时间。但是在同时我在上班的时候我会摸鱼，对不对？我会摸鱼有比如说最基本的两条，一条是我购物的时候，我是有一个另外一个时间线的。就是比如说遇到特别是遇到什么双十一，这时候我要怎么抢购，他那个时间是争分夺秒的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:04",
      "text": "然后我有跟朋友的共同兴趣爱好的朋友，我们可能是读书或者是什么登山、健身，我会跟不同的人在不同的时间平然后自己的亲密关系，恋人、家庭给孩子辅导作业。我们同时在不同的这个时间的频度里边生活，而这个时间对我们的重要性影响也是不一样。所以你看我们很难说你过去一年做了什么。你发现以前我们做年度总结的时候，在我少年时代、青年时代是可以清楚地写出一条主线的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:42",
      "text": "现在变成一个什么？现在变成一个比复调音乐还复杂的。就等于说你有一个主旋律，但是有很多副歌。这个主旋律有的时候它在形式上你的工作是主旋律，对吧？但是有的时候你的工作你是很讨厌的。在表面上你主要生活在工作的那个时间结构里，但实际上你自己最兴奋、最愉快或者最重要的。比如说有的妈妈，我就知道她在上班的时候主要是在处理孩子的作业，所以你会发现她她构不成一个音乐，你知道吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:15",
      "text": "本来是有主旋律，有副歌。你现在想象一下，一个音乐家把我们过去一年的这样的一个生活的心态谱写成为了一个音乐。它是一个既无调性又没有旋律，是一个杂七杂八的这样一种状态。所以他没有历史，这是我讲的无历史的时间感。然后你你就你的记忆就变得麻烦了。你每一天好像都要新颖的，是要从零开始，和过去只有一些模糊稀薄的联系，所以我们的时间感是破碎的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:50",
      "text": "第二个就是无实体的空间，就是我们的主要生命活动对物理空间的依赖是越来越少了。我们人在办公室里，我们连通到各个不同的空间。这个就互联网的空间里边，微信也好，还有各种各样社交媒体也好。所以你的生命活动发生在越来越多的生命活动，主要发生在一个好像既不存在，因为它在物理上是零，但是又无所不在的一个互联网空间里面。所以我们是一个无实体的空间感。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:23",
      "text": "由于这种时间和空间造成了我们意义阐释结构的巨大的困难，你要提供一个完整的意义是非常麻烦的。所以怎么办呢？活在当下。现在大家知道你就活在当下，你就体验就好了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:39",
      "text": "你现在但是你会发现这无目标体验的他的那个感官快乐好像是可以找到。你看到一段小视频，一段脱口秀的段子，你会很开心。看谁做了一个美食很难看，一个小姐姐跳舞你也会很开心。但是这些体验你没有办法make sense。也就是说其实人的意义像存在主义，像萨特老师讲，就是你的意义要阐释出来。但那个阐释结构已经被被变得四分五裂了。所以我们就没有办法说这件事情有多少意义，只要我们在当下去体验就好了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:13",
      "text": "你不要想它能够对你的生活愿景，长远的目标产生什么。所以这就叫无目标的体验，我就为体验本身而体验开心的。然后你无数个瞬间的小快乐、小开心、小惊喜，你并不能够编织为一个你的生活好像是有一个矢量，有一个明确的目标，相对明确的一个目标的这样一种体验。最这种体验是破碎的，是无目标的一个体验。所以这样一种我们好像变得是三无状态了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:44",
      "text": "但是当我说这个话的时候，我在想我是不是这里边有一个价值的偏见呢？可能是因为我们是那个老旧的启蒙时代主张的阅读文化。这是在波斯曼讲娱乐至死的时候，他讲的专门是那种由于阅读建立一个理性线性结构的这样一种框架里生出来的人。可能现在小孩子他就天生处在这样一种，他就是三无状态的这个原住民，他可能很适应？也不是。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:15",
      "text": "所以我觉得有的时候人类他还是有年轻的人和老年的人之间，他还是有一些共享的人类一些更基础的结构。当这些结构被困扰的话，它会有很多不是。所以现在的孩子他他的状态是经常不稳定的这不是说要从我们外部评他自己对自己的状态不满。你看现在孩子你就最近我们去，因为我跟闫飞老师有一本新书，跟好多年轻人交流，不是说要我们外部评价他对我自身的状态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:49",
      "text": "当然这一方面有就业压力，有经济的问题，但他自己的情绪情感状态处在一个自己觉得又是失控又想驾驭的矛盾状态当中，我觉得这是一个挺大的问题。最重要的是我们的这个技术发展太快，我们的文化适应文化演化赶不上这个技术发展。技术发展这个速度和强度。它是介入性的，它是介入到你的生活当中的，就是超越了超出了我们文化适应对很多人来说适应的能力。这是我觉得是一个征兆，就包括我说现在我要写一个东西，包括要准备这个谈话，我都会心猿意马想另外一方多出来的一个player，这个AI的这些辅助软件，它会怎么说？他会带给我什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:42",
      "text": "对我我我我想接着刚才刘老师这个，我觉得您对于那个时代的判断还是很有意义的。就是在更前几年就是区块链火的那一阵，我关注了另外一个跟区块链很相关的技术，就是NFT的艺术。就是我们作为可能作为老古董，大家一般对艺术的理解，还希望它会在技法上，在细腻程度上会有一些。无论是雕塑还是绘画都希望它更复杂一点。但是NFT的艺术它就是几个像素点组合成了一个很粗糙的小表情或者一个小图片。但就有像刚才刘老师说的，技术原住民很年轻的家里家境很好的人愿意去炒这个东西，愿意去做NFT的艺术收藏。我觉得这里面的确会有世代的这样的变化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:34",
      "text": "但是刘老师也提了一个很很严峻的问题，就是在这个过程中，AI会给我们个体性的人的，我称之为精神结构会有很多新的改变。这种改变在一个个个体上会汇聚成一个洪流，它就会变成一个社会现象。在这个过程中，翟老师您觉得在制度层面，您觉得这种个体性的改变，目前已经给我们的社会生活带来了很显著的变化吗？还是说您觉得这个变化还可以再再观察。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:12",
      "text": "其实已经带来了非常显著的变化。如果我们从还是回到前面讲到技术发展的历史来讲的话，你会发现其实在信息技术之前，人类技术的发展，新的技术它传导到个体往往是经过很多的环节。比如说大航海航海技术的发展到它这个结果传导到一个个体，其实经过漫长的联调。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:41",
      "text": "工业时代也一样。工业时代更多的技术突破实际是在工厂发明了蒸汽机，发明了新的生产机器，让他生产出新的产品。这些产品再到我们每个人消费者的手里，实际上有一个漫长的一个链条。而信息技术实际上它的发展每一步都是直接做共用于个体的。就像刚才刘老师讲，今天人工智能的发展，它每发展一步，只要他出来之后，我们立刻就能够去体验到。然后他就会改变我们的生活，改变我们的工作。这样的话实际上每一个个体作为单独的个体，一下就会抛到这个技术的洪流里。那实际上这个变化是非常大的一个变化。如果说从社会回应上来讲的话，我其实刚才讲到是有说法律的回应往往都是滞后的，但是这其实上是基于过往人类历史的经验。我们也会发现在当下，其实很多法律的回应已经开始做一些我们叫做预防性的立法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:43",
      "text": "就是先发制人。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:45",
      "text": "对，我知道他未来会产生一个巨大的影响，虽然我不清楚的影响会是什么，但是我要提前的去做一个预防。像欧盟人工智能法就是一个非常典型的预防性的立法。我们可以说今天真正意义上的人工智能，这个全貌是什么？我们其实并不太清楚，对吧？我们今天更多的谈的人工智能，其实际上是基于这个大语言模型来讲。但这只是人工智能的一个侧面。对它是因为它只是处理语言问题。还有很多的其他的人工智能还在发展的过程之中。但是欧盟已经迫不及待的要做一个人工智能这样的一个立法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:23",
      "text": "为什么？就是他一想到这个东西会产生巨大的影响，那我现在必须要去采取一些措施进行去应对。它是他未来会产生什么样的影响，我也不清楚，那怎么办？那你就看他的立法就会他其实是上是基于风险来进行立法，就是他把它转过来，就是有一些风险我是完全不可以接受的对吧？OK那我就做非常严格的限制，而有一些风险是我经过一定的限制我可以接受的，还有一些风险可能就是一个通常来讲，我们就可以很自然的去接受，因为所有的东西都会带来一些风险，所以它实际上是去把未来技术可能带来的风险做划分，每一类的风险我要去采取什么样的一个应对的措施。至于什么东西会落入到他所划分的这个风险等级里面，其实让他不清楚。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:18",
      "text": "那你就会发现欧盟人工智能法和我们过去的法律的不一样的地方就在于说，它没有办法拿过来直接执行。因为几乎所有的规定都是原则性的，都是不明确的。所以他才会在立法之后成立一个欧盟的人工智能的一个专业的部门。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:36",
      "text": "这个专业的部门干嘛呢？实际上是再去具体的去细化每一条规定或者每一个要求，我怎么样去执行它。而它的这个细化过程，实际上它要非常紧密的去和技术发展结合在一起。就是说某种程度上来讲，你出了什么东西我就立刻给你一个应对。你出了什么东西我立刻就给到你一个应对。这其实也是一个没办法的办法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:01",
      "text": "就是说回到刚才这个刘老师讲的，就是它变化太快了，它发展的太快，然后它带来的危害，带来的影响又特别的大，那怎么办？那你就必须要去做的就是你立法能够对所有的变化做出一个迅速的回应，这个迅速的回应你又不能够瞎回应，对吧？怎么办呢？就是立法者给到你一个基本的原则跟框架，然后靠执行者根据技术的发展不停的去有针对性的来做一个回应。所以他会去改变未来人类法律的一些形态。我们过往法律的形态更多的是非常成熟的立法，按部就班的去执行，然后严格的一个司法。未来可能更多的话，我们法律中也有一个讲法，叫做回应性的立法，回应性的这个执法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:52",
      "text": "回应性的司法就是你出现了什么问题，我立刻的来做一个一个回应。但是实际上法律其实很难去解决一些很根本性的问题。就是说我们只能去防止最坏的那个情况去发生，但是有很多的问题是法律没有办法去解决的。比如说我们刚才刘是讲到的这种人工智能技术的发展，以及它的使用所造成的人类的这种三无状态，对吧？或者说三无人类实际上立法完全我们今天的立法其实没有办法去禁止说，因为人类可能进入到三无状态，所以技术就不要发展，其实是没有办法做到的对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:37",
      "text": "这是不可能的。技术一定是会向前走的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:39",
      "text": "那技术只但是我你先说那那立法其实只能怎么立法，只能有一个基本的导向，就是说你所有技术的发展仍然是要以人作为一个根本就是你不能够把人当成一个工具来进行发展。就是人仍然是一个目的，就是你这个技术要最终还是服务于人类的福祉，把人当成这是原则，对不对？这是一个原则，这个原则必须在今天的立法里边去捍卫，就像你讲到的人本智能，就是你智能的发展实际上是为了解放人类？使人类获得更多的福祉，而不是说把人类变成了一个工具？最后变成人，变成人工智能的一个工具。这样的一个基本的原则，其实是今天的立法实际上是去捍卫住。那至于捍卫主张的一个基本原则，如何在具体的实践之中能够得到一个实施？很多的时候可能光靠立法是没有办法去解决的那包括像知识界、思想界，包括这些人工智能的企业，可能都要承担起这样的一个社会责任。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:42",
      "text": "就是我想起尤瓦尔赫拉利他有一次演讲当中，他提到这样一个问题。他说我们对比一下。就现在的整个人工智能对我们的这个介入，特别是话语的介入这么大。但是他这些人工智能的软件就有一个私营公司。他们自己研发出来以后，他直接向社会就release了，就发布了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:08",
      "text": "他对比他说有没有一家药物公司可以这样做，他不能。可是在美国你药物公司你要特别当然都是要以人为本的，对人健康带来它有动物实验，有小小的样本实验，有大实验。然后要申报这个FFFDA，对不对？FDA是国家的所有私营公司，要通过像FDA这样的一个机构。FDA他帮背后当然是有议会什么这种要有一个公共机构来认可你，才能够像市场来发布你这个产品。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:46",
      "text": "但是我们人工智能就不是这样，他认为人工智能是对我们生活的影响，可能在很多层面上要超过一个药物。这边就带来了麻烦了，就是药物的这个你做小事，做中事，做大试验，你是还是有明确的我针对什么症状，我改变啥，就治疗了它，改善了它，副作用是什么，对不对？但是你说我们发布一个新的软件，我们讲短视频，就是我们中国比如发明的某音，对不对？这个是特别短的超视频。他当然要是人喜欢的，是人喜欢它是对人有利的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:25",
      "text": "你看伊朗马斯克，他就他最近他他有一个演讲说他认为像他认为的那个twitter就是X是好的。你他说花半个小时时间，你如果看X然后你还会有一点收益，你会觉得这个半个小时的时间是值得的。但是你就刷那种超短视频的，他当指指向某某个软件，他就说你花了三四个小时，你觉得你好像陷入在空虚无聊当中，是不是能够用这种感受作为说对人是不是好的，是不是把人当做了赚取流量的工具，还是把服务于人。因为服务的人他接受这个他都是自愿的。我们对自己自愿的事情是不是对人类就是好的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:20",
      "text": "在以前是会有一个权威的等级结构来规定你的。在这样一个平民主义的时代，在这样民主化时代，在文化民主化的时代，你是谁？你来规定我说我应该怎么样。但是我们确实会发现文化有巨大的改变。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:38",
      "text": "你知道最近我收到图书行业的一个报告，就是在讲去年出现的那个新的书出版状态到了什么地步。64%的书。半年内销售不到100本。而做到了发行到5000以上的书，半年内只有整个出版行业书的种类的4%，就是我们的阅读。人们对书的购买了还不一定阅读，对不对？整个的阅读就这是整个的是一个文化的范式性的转变。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:20",
      "text": "我们的阅读以后，我觉得是会变成一个非常小的传统。就像现在的书法协会一样，就书法爱好者他们写写书法，大部分人他们的整个的这样一个世界是一个影像的世界。你说这个到底对人带来的我们很难评估了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:40",
      "text": "什么叫对人本身是好的？他没有把人作为工具，而是把人作为了目的。我们是不是能这里边的评价是非常复杂的，所以这是带来了立法的困难。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:56",
      "text": "我就想说尤尔赫拉利的这样一个例子，在原则上来说，我们可以说新的这样技术跟药物是同等对我们的生活有着严重的影响的。但是你要如果成立一个相对相应的像FDA的这样一个官方的政府的机构来审核它，依据什么呢？FDA作为药物来说，我们有明确的相对来说明确的判断标准，而对新技术它很难。所以这是非常具有挑战性的。就像志勇说的，可能他只能达成一些原则性，但是下面要肯定成立委员会，这个委员会会多到。因为对一个新的技术，马上就会出来一个相应的一系列的后果的评价，这个评价的标准本身还在争议当中。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:44",
      "text": "现在不光是AIAI跟更特别是跟生物技术关联在一起的那样一些新的发明创造。比如说如果能够特别有效的增加我们的记忆力，那会怎么样？那会是不是是现在很多学习变得完全不必要，或者是根本性的改变了我们的学习成长的经历。如果我们的我们的记忆可以外包的话，那对我们人意味着什么？这是把人当做目的，还是当做手段了呢？我觉得历史上没有这么严重的挑战过。因为这次重新塑造是在我们人类的这个humanity非常底部的一些原则的改变，这是一个非常大的挑战。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:28",
      "text": "刚好接着刘老师对未来的展望，我想也有个新闻，就是开头我讲的AI界两个大消息。那也是前不久就是google的下面，他deep man做的一个阿尔法fold。就是他他做了阿尔法go去去下棋，阿尔法的就是做这个蛋白质结构的探索。他用这个人工智能做蛋白质的结构分析，去帮助人类探索各种各样的蛋白质结构。之前人们花了数十年时间，刚探索了二十多万个。阿尔法fold一来就把剩下所有的二十多亿个的这样一个数量都给算出来了。而这个过程里面，谷歌就做了一个很乐观的预估，就是大概在未来很短的时间内，人类一切疾病都可以攻克了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:20",
      "text": "对，这次不是那个谁诺贝尔奖获得者，他说只要你熬过这十年。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:25",
      "text": "他熬过这十年，我想我们应该都能熬得过。的确假如我们回到一开始最开头刘老师讲的，对于技术和人的关系来讲，就是技术不再是一个外在的工具，而是人的本身的某种延伸的话。那AI这样一项和我们自己有如此紧密结合的技术，的确会需要让我们去规定一些最基本的原则。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:51",
      "text": "翟老师刚才您讲到欧盟的人工智能立法，它的一个原则，在我理解了看来还是一个有点非人本。他并不是要去面对人，他其实是基于风险管控的理念，要去把可能的风险给降低。在这里面它会有一些基本的内容上的原则设定。但更根本的一个逻辑，刚才刘老师也反复讲，就是技术和人竟然有如此紧密的过程。一开始我们对技术的规训，或者说对这个技术的引导的设定，本身可能就要有一个更深层、更底层的全面性的原则思考。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:34",
      "text": "在这里面，刘老师上次参加的11月份的财信峰会，我想中国也有很多企业在做这方面的努力。联想和交大，还有esg、三菱一些行业内的和学界的机构共同去撰写的人本智能的这样一个报告。其实就想去提供一个在人工智能时代有一个最基本的治理的原则。那就是从人的角度出发，要去对AI有一系列的这样的规制。在这里面可能还涉及到一些内容，就是刘老师刚才也提出了这个难题，什么是人我想这里面就会有一些需要在操作上可能对这个内容有一个更规范化的那翟老师您是怎么看？就是我们有了一个原则，说我们需要人本智能的话，我们有哪些细致的方面可能去做一些拓展。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:31",
      "text": "我先接着刚才刘老师讲到的赫拉利的这个讲法因为他的讲法确实很有意思。因为刚才刘老师讲说，我们所有的药物都要审批才能够上市。但其实我们不仅仅是药物，你像食品也是一样。我们所有的食品虽然它不需要审批，但实际上都有非常严格的食品安全的标准。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:53",
      "text": "而且需要。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:54",
      "text": "监管FDH即时药物和食品。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:57",
      "text": "对它实际上有非常严格的这各种各样的食品安全的标准。所以我们最近这些年中国其实一方面食品安全不是很好，另一方面经常会出现违反食品安全被重罚的这个个案。实际上这个确实是一个很好的一个问题，就是说为什么这些跟我们日常生活相关的药品食品，可以有一个监管部门做一个非常细致的监管。而像这些社交媒体，这些人工智能似乎精神食粮。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:32",
      "text": "对这也可以说是是人家精神食粮。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:35",
      "text": "传统的对精神食粮，似乎没有人或者没有一个机构能够做一个严格的审批或者是监管。让我联想到刚刚发生的一个事情，就是meta meta宣布他要放弃第三方的人工审查。因为meta是在一个是在剑桥分析公司这个事件之后，因为他被美国的联邦贸委员会处罚。那么处罚中附带的一个就是他20年之内要将接受一个监管。另外还有就是上次大选特朗普冲击国会山这个事件带来一系列的影响。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:17",
      "text": "后来meta实际上是委托一个第三方公司来对meta旗下的产品，包括facebook和其他产品中的内容进行一个审核。也是被标注有问题的内容，他人工进行审核，然后进行判断，然后进行处理。他现在实际上是放弃了这样的一个机制，他给出的一个理由就是说这种人工的审核会带有审核员的偏见。那他可能会去限制一些他不认可的东西，而放纵另外一些他认可的东西。所以他就把这种审核抛弃掉，这种抛弃掉实际上是不这个X就是twitter的后尘。因为马斯克收购了twitter之后，马上就取消任何的审核。那实际上意味着说在美国的社交媒体中，比之前监管会更怂，以前还有一些审核员一些监管，现在实际上是没了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:21",
      "text": "但是他们相应的也会采取一些措施，就是靠用户来进行审核。就是你认为这个东西是虚假的，你可以给打打标签。你认为这个东西是有害的，你也给他贴标签。它变成了一个用户自己自我的内容的一个治理。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:38",
      "text": "好，那就回到刚才刘老师这个问题，就是为什么会是这样？就是为什么我们今天的社交媒体没有办法像过去的，比如电视台也好，报纸也好，所有的内容输出其实都有审核的对吧？但是今天没有了，我将非常重要的一个原因就在于说这些平台今天的特殊性就在于说它实际上某种程度上来讲，跟刘老师的一个研究相关。它是一个民主化的公共言论的一个空间。因为它所有的内容的生产，其实上都是用户生产的，而不是平台自我去生产的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:13",
      "text": "海量的用户上传了海量的信息。我那天看tiktok的判决书，我才发现就是facebook上每天竟然有1000亿条信息，我都不敢相信。加上一就每一个算算记1000亿个一条信息，所有的这些信息其实上是完全不可能有任何的机构，任何的组织来去审查的，而且尤其是你也没办法事先制定一个审查的标准，说我什么东西是可以过，什么东西是不可以过。那这就实际上确实会使得他带来一个问题，这样的一个完全的由用户生成的，某种程度上大众民主化的这样一个平台怎么进行去监管？",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:01",
      "text": "好，那就回到刚才你问的这个问题。就是今天事实上对于平台的监管，对于人工智能的监管，国家主权国家实际上是非常头疼的，头疼在什么地方呢？就是你一方面尤其像自身还想发展人工智能技术的国家，你监管太严了不致力于技术的发展，你监管太松了可能会带来一系列的问题，而且所有的这些东西基本上是全球性的，就是你你可以管的很严，对吧？但是别人只要管得很松，他那个地方仍然可以发展起来，而且这个产业就流过去了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:36",
      "text": "对，今天欧盟其实面临着这样的一个困境，对吧？你只能说我欧盟立法管我欧盟境内的这样的这些平台，但是其实欧洲人也可以越过欧盟的进去访问美国的。因为比如说一个facebook，它可能有欧盟版，有美国版，你也可以访美国版。实际上这个监管就会使得它的效果其实并没有那么好啊。但是可能对于整个欧盟的人工智能产业的打击会是非常大。回到刚才讲到的这个内容审核，就是实际上现在的对于这类新技术的监管，就公司本身实际上变得越来越重要，就是你公司如何的进行自律。公司如何的去制定规则，然后去做内容的监管也好，或者是这种危险的防范也好，实际上是非常重要的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:35",
      "text": "这就是说我们去理解欧美在人工智能包括社交媒体上监管的不同的思路，这个确实会和欧美整个的法律体系也会有关系。因为欧洲的大陆法系的传统，罗马法的传统就是一个自上而下的，立法者制定规则，然后你就服从规则就可以。然后英国跟美国的普通法传统，实际上就是一个自生自发的一个秩序。它就是靠出了什么问题解决什么问题，然后一点点的去应对这些新的东西，然后积累规则，慢慢去形成一个自制的或者是自律的这样的一套秩序。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:17",
      "text": "那今天你仍然能够非常清晰的看到，就是欧盟跟美国在这个方面的不同。比如说举个例子，他GPT出来之后，很快的当时拜登政府就约谈几个美国的大公司，就讲未来美国的人工智能的治理。那拜登政府就提出来很简单，安全我要对吧？隐私我要，那这个具体怎么做，你们公司自己想办法对吧？我要我要你最终的产品来保证安全，保证隐私。那具体你如何去实现，那你自己的事情，或者说那是你们这些大的公司的事情，你如果没有实现，那我可能会有这个处理的方式所以它就会变成使得这些公司如在发展自己技术的同时，会去注意或者说会去做这类的监管。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:15",
      "text": "当然很多人会一些批评，这些公司怎么可能会去自我监管呢？我觉得某种程度上来讲的话，这确实会是一个公司的社会责任承担的问题。当然会有一些公司完全无所谓对吧？我就优先发展技术，但尤其是大的公司，会起到一个标杆化的这样的一个作用。就是你怎么你以什么样的态度来对待你的这个技术，尤其是说在一个开放的一个社会，因为还有更多的不同的组织会盯着你，对吧？因为你是个标杆的公司，人家会看你怎么去做。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:51",
      "text": "其实今天欧盟I受到的批评是最多多的，因为大家都会矛头，所有的关于人工智能的这个问题，都会矛头都会对对准他。因为他是标杆公司。对，因为它是个标杆公司。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:04",
      "text": "那这样的话，实际上我们法律中有一个讲法叫做法律上的正当程序。其实技术领域中也借鉴那个讲法，也讲叫做技术正当程序。就是在技术发展的这个过程中这个过程里边，如何能够把一些法律的要求、伦理的要求、公共政策的要求纳入到技术的研发和使用的过程中。这实际上某种意义上来讲，其实上是对于人文社会科学的学者，对于公共政策的制定来说，提出了一个非常高的要求。就是你能够提供什么样的规则，人工智能的伦理规则，你能够提供什么样的伦理规则？这些大的公司才有可能是说我把这些伦理规则纳入到我的这个技术的程序里边。那监管者你能够提出什么样的一个监管性的要求，这个要求是能够是一个切合实际的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:03",
      "text": "所以像刚才你提到的，像联想他们做的人工智能的这样的一个宣言。其实这类宣言有很多的机构都在去做，包括联合国也在做，欧盟也在做，有很多的NGO组织也都在做，企业其实也在做，但是所有这些东西，企业做，我觉得有一个特别的意义。就是比如说你第三方组织做，仍然只是说你提出一个倡议，提出一个呼吁。但是企业参与去，发布这样的一个宣言，实际上某种程度上是一个承诺，对吧？就是你对于社会公众做出来的一个承诺，那这个承诺反而会成为大家去监督企业，你是不是实现了这个承诺的一个最重要的一个机制。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:52",
      "text": "就是美国的技术治理。为什么他会看重这些公司的承诺？就是因为美国联邦贸易委员会对于大公司治理的一个重要的一个方式。就是说什么样的规则我不管你自己去制定，但是你制定的规则你得遵守，因为否则就是欺诈。我承诺对吧？我承诺要保护安全，我承诺要保护你的隐私，但是我做的所有的东西都不是保护你的隐私的那他就可以是说，那你就相当于你对用户的一个欺诈那联邦某委员会就可以管。当年facebook因为剑桥分析公司的那个事件被罚了50亿美元。原因就是因为你承诺保护用户的隐私保护用户的数据。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:37",
      "text": "但是你还是被剑桥分析公司扒掉了那么多的数据，造成那么坏的影响，那你就是对用户的一个欺诈所以facebook也没办法，他就接受这样的一个一个罚款。所以回到这个根本，我觉得最终其实上在人工智能也好，社交媒体也好，在这些问题上的治理上，可能他确实没有办法像食品跟药品那样，依赖于某一个国家的机构去来审查、去来备案、去来批准。可能更多的要依赖于这些大的技术公司，他们要去制定一个相应的一个审查和治理的一个标准。我们现在面临的问题就是说，我们有什么样的机制使得他们愿意主动的去做这件事情，并且有什么样的机制使得他没有做到他的承诺。我们有什么样的这个机制能够去对他进行一个监管。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:32",
      "text": "刚才翟老师说的这一点，我倒是对未来倒是有了一些畅想。刚才翟老师讲到不同地区的这样一个治理，我们会发现它有一些差别的。美国跟欧洲跟东亚之间都是有一些差别的。而这个差别之间，在我理解看来，其实它是有更底层的对于人的理解的文化差异。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:56",
      "text": "你比如刚才张老师讲说美国人去监管说企业你做什么规则不重要。但是第一人的隐私，就在信息领域了。人的隐私以及你公司的经营者的诚信，真诚诚实这件事儿，这是他所看重的那规则本身的内容他不care。而在欧洲我们看到欧盟在立法的时候，其实他要对这些实质性的内容有进一步的规定，他觉得这个也很重要。在东亚我们看无论是中国还是像新加坡这些地方，他可能会更强调说在制定一些底线性规则之后，希望人能够快速的把它去应用下来。这就意味着其实在目前来看的话，不同的治理逻辑或者说治理体制下面，其实是有基于地方性的或者地区性的文化差异的那刘老师您反正时间也到后面了，您能不能给我们做个畅想？",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:55",
      "text": "就是我们会看到英美传统、欧洲大陆传统、东亚传统，他对于人的这种基本的想象可能都不一样。那在未来的话，他们各自能够制定出来的AI治理的策略，和未来这些不同的地区它的AI的发展可能会有什同样的差异。您能不能给大家做个畅想？",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:17",
      "text": "我觉得这是会有一个时序上的差异，但最后可能都不行。我为什么这样谈呢？就说我可以讲这样讲，就是说大概在前现代或者早期现代，我们其实都有一个家长制或者叫权威主义的文化，威权主义的文化。这威权主义文化它不一定是以前是有联名的等级的，后来这个等级它不是制度化，但它是隐形的。比如说你出版一本书，发表一篇文章，它都是有门槛的。你的作者，你的发布者，他都是要有很多资质的。这个资质是他可能是大学学位，可能是各种评级机构。",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:56",
      "text": "但是现在到了一个推翻维权主义文化的时代，这个时代最早来临大概是英美。他是放任的，但是他规定一些底线，比如说隐私，不伤害他人等等。其他的只要你不伤害他人，不不暴露隐私等等，不造谣，不对社会秩序有一种恐慌性的冲击，那一切都是你的自由，言论自由是特别重要的。但是我在欧洲，可能他东亚国家更是这样。他就是觉得有的时候是他把民众在某种意义上当成孩子一样。就是说你并不知道什么对你真正是好的，特别是你长远的最深层的利益是好的，你不能说我要就好了。所以有一个正面的监管，就是在在英美它是一个消极监管，说你不要突破这个底线就好了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:50",
      "text": "那么这个现在能不能维持？我觉得它是是会有不同的录像。比如说像我们这次的那个人本智能这个倡议，我觉得他是说的特别好的，就是说以人为本，智能向善，这是核心原则对吧？然后他要保证什么呢？要保证是可控，它是实现安全可控，确保AI技术是服务于人的，不偏离人类文明的进步方向。",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:18",
      "text": "但你知道我们现在有大量蛮难判断的灰色地带，怎么样呢？我宁可慢一点，保守一点，我可以走的慢一点，来来让自己的节奏放慢以后调整我的判断。因为好多东西我现在是一时无法判断。比如说我再讲一个事情，比如隐私你保证了？不伤害他人保证的那这个东西就是好的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:43",
      "text": "你看我们在平时对一个人使用暴力肯定是坏的，你的自由伤害了别人的自由，对吧？伤害了别人的基本权益，但在游戏世界里他可以是例外的。我实现了我的这个暴力的欲望，杀人的欲望，但是我并没有伤害他人。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:01",
      "text": "这个需要监管吗？可能在一个比较家长制的威权的这个文化里边。就会觉得这是需要有引导的。比如至少成年人是可以的，但是孩子还不能够确定自己。所以我们有一个什么青少年模式，大家知道对吧？但是这个东西能够维持的住吗？就是我们对于大量的灰色地带，我们不能够做决定的时候，我们放慢一点。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:30",
      "text": "但是你前面大概在去年12月，jeffrey hinton就是所谓AI的教父。他也得了今年的诺贝尔物理学，就去年的诺贝尔物理学，诺贝尔奖，他是觉得没办法的，为什么呢？他说如果有一个人，他他他当然从OpenAI的内部那个分类里边，我们知道那个伊力就是他的学生，他跟奥特曼就闹分歧了。这里边就有所谓加速主义跟对齐派之间的分歧。他说只要两个东西存在，你就没办法让那些走的特别快，特别冒险的路径，能够服从一种保险的、稳重的、比较保守的、稳健的那种做法。为什么？一个是资本主义，一个是地缘政治。他说如果OpenAI这样做了，它能够非常大的吸引他的消费者用户，你就没办法跟他竞争。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:39",
      "text": "所以你不能够取一个特别保守的渠道，所以open I会这样做。那谷歌你没办法让它限制它的发展。所以只要资本主义这样一个竞争模式在的话，他最后都会大家越做越快。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:52",
      "text": "还有一个就是地缘政治。你说如果我们中国采取一个特别安全保守的方式解决的要智能向善，他善恶还不能分歧的时候，我们宁可走得慢点。但是美国发展了，我们怀疑美国在发展，美国突破底线了，或者反过来，美国怀疑中国会不管这些底线，突破底线可以发展出新的技术。大家在这种相互的猜疑和恐慌当中，他会走就会走那种非常冒险的路径。所以他他是非常悲观的，就觉得我们哪怕现在有一些原则性的想法，到最后都会屈从于技术竞争、资本主义竞争、地缘政治竞争带来的那种加速模式。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:43",
      "text": "所以我的看法实际上你说会在不同的地域，现在会有不同的差异。但是你你你可以从现代性的转型来看，最后大家都走到了差不多的路径。就是比如说一个民主化的文化，每个人只要不妨碍他，你自己觉得好就是好。没有另外一个家长能够正当地告诉你说，你这样使用，你看这样的视频是不对的，到最后会有什么状态。你只要知道整个虚拟世界在游戏世界，如果这个游戏世界实物成为我们生命活动和意义的主要来源的话，我们的现实物理空间它会变成废墟的。就是像有就像有些现在农村地区他们被荒废了，他们移民到这个城市来了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:32",
      "text": "现在很多人他不是真的能够，因为虚拟空间他不是一个地理，他的心性、他的情感、他的认知都移民到那个虚拟世界里面。那个虚拟世界它都只能给你特别底层的，比如说隐私权，伤害他人的禁止，那一切都是他的。然后物理世界、现实世界就只能是成为让我们身体维持生物生存的一个世界。而主要的精神情感的活动都发生在虚拟世界。但是他就是很难管控的。这样一种状态，你说到底对人类是什么叫向善的？就连善恶对错的这些标准，就连我们什么是要服务于人的目的，那个人的目的本身都已经在改变了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:14:26",
      "text": "在这一点我来看，最后大家都会走到差不多的这样一个状态。因为如果你一种比较过度的监管，它会妨碍技术突破的可能。而技术突破它又有资本主义的竞争模式和地缘政治竞争模式所所驱使。如果没有一个全球性的共同治理非常困难。",
      "speaker": "发言人1"
    },
    {
      "time": "01:14:47",
      "text": "刘老师这个担忧我觉得是非常有现实性的一个担忧。张老师最后一问一个问题。其实在您最早参加我们东腔西调的时候，也是因为赶上区块链的那次技术爆发，然后有很多关于数字立法的讨论。其实除了外部的数字立法以外，咱们还很深入的讨论着说区块链内部会有一些技术性，让不同的链本身会有不同的价值取向。然后它会有自身的这种那种数字空间的立法，然后会说引导不同的人在在不同的链上去去开展自己的活动。在这个意义上，刚才刘老师所期待的说需要有一个全球性的治理，也就意味着在挨着的这个环境里面，业界需要达成一个共识。在您看来如果在可操作的层面上，您畅想或者预期的话，您觉得在这样一个技术环境里面，业界有没有什么途径会有一个共识，能够把这种技术的发展和对于人本的取向能够结合起来。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:55",
      "text": "我觉得有两个方面一个还是回到刚才刘老师那个问题。因为我之前有一次给我们开会，我画过一个图，就是你会发现全球，因为刚才你也提到全球最重要的三个地方就是欧盟，然后美国跟东其实在全球的三个地方，在国家，大的公司和个人之间。因为我们想，其实说今天涉及到所有的问题就是国家、公司跟个人三者之间。如果三者之间画一个三角形，那三个地区在这个三角形里边的位置是不一样的。大体上来讲的话，美国是公司和个人画到一边，就是你在三角形中画一条线，美国可以把公司的个人画到一边，他们共同对抗国家，就是你国家不要管，你少干涉对吧？我们自己的事情我们自己来解决，尤其是在社交媒体上，是因为受到言论自由，那你国家不要管，欧盟大体上是国家跟个人划到一边，他们共同的来对抗大公司。就是你不能够侵犯个人的隐私，不能够侵犯个人的数据，对于个人有非常严格的保护。中国或者说东亚可能更多的是国家跟公司划到一边，各自的站位是不一样的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:22",
      "text": "由此就带来第二个问题，就是刚才你讲到的就是未来的这个治理，我是觉得欧盟的立法很多人都会去批评他说你欧盟的立法太严格了，根本没办法执行。对于整个欧盟的人工智能产业，或者说他以前的这个互联网产业是毁灭性的打击。如果从产业的角度来讲，或许是啊我只能说或许。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:50",
      "text": "是他而且现在欧盟的经济这么困难的时候。",
      "speaker": "发言人1"
    },
    {
      "time": "01:17:54",
      "text": "对吧？对，是的，对。但当然也有人会讲是说欧盟即便没有这么严格的立法，欧盟也发展不起来。因为这个不仅仅是立法，只是其中一个方面但是我是认为说他仍然有一个非常正向的意义。就是欧盟的立法，包括他围绕立法的所有的讨论，实际上是在为整个的这样的一个数字世界在这立法，因为它相当于把数字世界整体上以人为核心的，以人为本的这样的一个规范提高了。就是你无论观念的水平，还是伦理的水平，规则的水平，他都给你提高到一个非常高的这样的一个位置。这个位置虽然它并不直接的作用于比如中国或者美国的公司，但我们会上经常会讲一个叫做布鲁塞尔效应，就是欧盟的立法会有一个溢出性的一个效应。它会使得这一类的标准间接的影响到美国，包括中国的公司，比如说对中国的影响，对中国影响最典型的就是我们中国最近的几年。",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:07",
      "text": "实际上是在人工智能领域也好，然后数字领域，有有大量的立法。王英曼，有很多的规范，这些规范哪里来的？其实都是因为欧盟有相应的规范，我们也会有相应的这样一个规范，如果没有欧盟的立法，其实我们可能至少不会这么快，这些法律也会因为美国大量的互联网公司都在欧盟有业务，他要遵守欧盟的业务，他必须达到欧盟的立法的一个要求。那他会同样的问题会回传到美国，因为对于美国的消费者来讲的话，他会面临同样问题。那你凭什么保护欧盟的人？",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:47",
      "text": "不保护我们。",
      "speaker": "发言人2"
    },
    {
      "time": "01:19:48",
      "text": "对不保护我们对吧？他其实会面临着非常大的一个压力，虽然这个监管不是美国政府给到他的，但他会面临着同样的这个问题。因为在美国的这样的一个市场里，各个公司之间，比如他们在隐私政策之间是有相互的竞争的，因为你的隐私政策不好，对吧？比如说苹果说我的隐私政策好，那你相当于你在这个市场里边的声誉就不好你保护隐私保护不好，就是你会发现美国在言论自由上的治理跟他在这一类的技术上的治理是一个逻辑。就是他某种程度依靠到以社会治理。言论自由也是这样。",
      "speaker": "发言人3"
    },
    {
      "time": "01:20:30",
      "text": "言论自由的话，之所以这强烈的排斥政府来管他的理由就是说这个言论市场言论本身就是个市场，这个市场上就有各种各样的一个讲法，你A的讲法不好，因为有B的讲法可以对冲他，那可能还有C的讲法对吧？因为到底谁的讲法好，到底谁谁的讲法对，或者说最终被接受，你要在这个市场中去竞争，对吧？而不是说政府说A只能A的讲，B不能够讲，所以他认为说这个东西，言论这种东西就是要靠相互的对冲，然后才能够知道真相到底是什么。其实它的技术治理也是，技术治理某种程度上它也是靠相互的对冲，你这OpenAI你不是要这个加速主义，对吧？那伊利亚就出来，我要搞一个对齐主义，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "01:21:19",
      "text": "我就要搞一个跟你不一样的这样的一个公司，然后就会反着反制是你的这样的一个公司，就是它某种程度上上也会也是有不同的。价值观的人，不同的立场的人，这个市场会给他们所有的这类的不同的价值观，不同立场你同等的一个机会，你可以去做你的这个产品，我觉得某种程度上来讲，这样的一个相互的竞争，实际上也提升了这些公司的基础治理的这样的一个水平。其实那些搞家族主义的人，也有一个他们的自己的理由。他认为说这种东西你只有跑出来，你才能知道有啥问题，对吧？你这有啥问题再给我解决啥问题。然后最终跑出来的可能是少数的公司，在他们看来反而是有助于这个问题的解决。因为你只要解决这两个公司就可以了。对，如果说这是一大堆的公司，其实你很难去解决。因为你你不作恶他会作恶，对吧？你最后又就剩了两家大的公司，那OK大家只要盯住他们就行，他们只要他们不作恶就可以了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:31",
      "text": "但是批评者会认为说，那你一旦就剩你们两个了，那你们想做恶谁还能管得住，对吧？所以当然会是有很多的争论。我觉得目前来讲的话，刚才刘老师也讲新论，也有很多的担忧，但是似乎我的技术发展似乎是势不可挡的。尤其是说马上特朗普政府上台，为什么硅谷的很多的精英转而去支持他？其实寻求的就是一个对于监管的放松，特别是对人工智能监管的一个放松。因为拜登政府后期实际上已经开始推动这对人工智能的强监管。包括加州这些互联网大厂在的地方，加州都要推人工智能的这个立法。在虽然最后被否掉了，被州长否掉了，但实际上也是要加强强监管。那这样的话特朗普政府大概率会进一步的放松监管，其实包括对于平台言论的一个监管，所以这个可能会是像辛顿他们感到担忧的一个也是一个很重要的原因了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:38",
      "text": "就是说在人工智能技术最发达的这样的美国，反而是监管最松的这样的一个国家，这可能确实会带来很多的问题，我觉得很短期之内可能也难以解决。某种程度上，我我我是从过往的历史中，法律历史中吸取的这个经验，可能有点就像原子弹一样，就是说它不造成一场灾难，人类很难去立刻达成某一种监管的共识，并且去执行下来。其实后来对于核能的监管，就是因为二战的原子弹爆炸，所以之后成立国际原子能机构，然后有一系列的监管大国之间能够达成共识。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:20",
      "text": "其实人工智能我想可能也是这样，就是不出点问题之前大家很难下决心要进行监管，或许要出了一些问题，比如说今年6月份，美国的一个小孩儿跟一个聊天的人工智能对话，Carry cuter AI对话之后自杀了，对吧？那他被告了。其实还有一个大家可能不太关注一个一个小孩儿也是模仿tiktok中的一个视频。就是那个视频是用胶带把自己嘴蒙上，看谁憋的时间最长，一个窒息的一个视频，最后把自己闷死了。也被他母亲告到了这个法院。",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:03",
      "text": "最近刚刚发生的说这美国的这个爆炸案是这个人用ChatGPT去学习如何制造爆炸，对吧？然后最终实施了，其实就是可能很现实的很残酷的现实。就是只有当一系列的这类问题出现了之后，才会有大家下定决心制定监管规则，并且去执行这样的一个规则。这些大的公司才有可能有这样的一种紧迫性，对吧？就是他必须要去解决一系列的问题。这可能是一个技术发展过程中，我觉得一个非常残酷的一个现实。",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:42",
      "text": "可能也是不得不去接受这个现实。这也是志勇开始谈的你们这个立法跟灾难史是有关系的，对不对？对，从防火就是你要有一些火灾才会有整个的防火措施。现在就是这个AI这笔大火全球性的大火已经看到他势不可挡。但是他哪天造成了一个大的火灾，就会有更有大家的共识。有大家有意愿来一起，所以也不至于这么灰心。无论如何我们提出人本智能这样一个倡议，这样一种思考方向还是特别重要。",
      "speaker": "发言人1"
    },
    {
      "time": "01:26:18",
      "text": "最后说来的话就是其实两位老师都会确认说技术发展的潮流其实是不可阻挡的。就是我们无法通过禁止掉这门技术来去避免可能的问题。但是这个技术既然如此发展，然后现实又如此会有如此的紧迫。那更需要一些我们提前预备好一些原则性的预案去去准备好。就是一旦需要行业有共识，需要整个全球有共识的时候，我们能够拿得出一个方案来去给这个共识添上它的内容，能够知道说要去怎么做。我觉得这个也许是我们在技术大爆炸的时代，可能能够做预7的话，是一个目前已知的最好的选择方向。",
      "speaker": "发言人2"
    },
    {
      "time": "01:27:04",
      "text": "但现在在现在时代，每个人的心情我觉得都是兴奋，又不安，对不对？",
      "speaker": "发言人1"
    },
    {
      "time": "01:27:11",
      "text": "每个人都是这样。对，非常兴奋。",
      "speaker": "发言人2"
    },
    {
      "time": "01:27:13",
      "text": "他在这个领域特别兴奋，同时你又又在另外一个技术方面你就会有不安。所以我觉得是兴奋，它是一直会造成，因为技术发展它会让人兴奋。但是让我们保持在在这种不安的状态当中，让我们保持警觉，保持审慎，然后有不断的这样一种原则性的方案，然后能够对具体的技术，有具体的这种法律措施和实施的不断的出现，这也是某种与时俱进。我们只能如此。我们人类一直是在尝试纠错当中发展，这一次的冲击很大。但是我们能够有的这种精神资源就是保持审慎和警觉。对于风险。",
      "speaker": "发言人1"
    },
    {
      "time": "01:27:53",
      "text": "我我我补充一点就是，我觉得在这个过程中，可能这种大的企业，要作为数字世界的立法者。我就我经常会讲这个所谓的大立法者，其实一个非常现实的一个原因，就在于说，主权国家其实没有一个强烈的监管。某种程度上来讲是希望人工智能产业能够很好的一个发展，但他必须要去考虑一个问题，就是一旦你造成了这个损害，他就必须要去进行强监管。其实等如果说真到了那个的时候，出了很多问题，主权国家强监管的话，他一定是要么不出手，一出手肯定会很重。其实最好的状态，其实是企业能够在发展的过程之中，始终能够去控制这样的一个风险。你不造成特别大的一个危害，主权国家也不会下重手来进行治理，其实这是一个特别良性的一个状态。",
      "speaker": "发言人3"
    },
    {
      "time": "01:28:57",
      "text": "其实你想就是自律，用自律来避免更强的更更强的那种摧毁性的压迫性的那种阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "01:29:06",
      "text": "对，其实就是以自律来取代监管。就是他的地方出来之后，其实当时那个奥特曼在很多的场合中，他是最早来提出来说对人工智能进行监管。当然我讲的他背后的这个用意可能有有多方面的。但是我想他其实上意识到一个问题，就是这个东西如果出了大的娄子，捅了他的娄子，出了他的东西，那政府突然出手的话，open I一定是。",
      "speaker": "发言人3"
    },
    {
      "time": "01:29:34",
      "text": "第一个枪打枪打出头鸟。",
      "speaker": "发言人2"
    },
    {
      "time": "01:29:36",
      "text": "对，那其实反而是说如果能够有一些可行的监管措施，那不至于将来出了大的问题。或者说即便出了一些问题的话，OK监管措施已经有了，对吧？我也是依照着这个规则来做的那他可能不会遭受一个毁灭性的这样的这样的一个打击。在这种意义上来讲，我觉得无论是美国还是中国真正的头牌的企业，应该从一个立法者的角度来思考这个问题。",
      "speaker": "发言人3"
    },
    {
      "time": "01:30:05",
      "text": "就是企业要有立法者的自觉。对你怎么样。",
      "speaker": "发言人2"
    },
    {
      "time": "01:30:08",
      "text": "能够使得这样的一个产业的发展，这样的一个技术的发展，它始终是安全的、可控的，是服务于人类的福祉的。而不是说最终成这个技术本身成了人类的功底，企业成了人类的功底。真的哪一天出了大的问题，技术或者企业成为人类的工具的时候，那个时候可能真的是一个毁灭性的打击。所以中国的大的企业在人工智能这个领域里边，基本上说可以是全球领先的了。因为除了美国的头牌就是中国的了。我觉得在这个时候，可能也是中国企业真正的走向国际化，走向全球的一个很重要的一个表态。就是说你如何在这个过程中承担起来这样的一个责任。",
      "speaker": "发言人3"
    },
    {
      "time": "01:30:50",
      "text": "对规则制定者的责任。",
      "speaker": "发言人2"
    },
    {
      "time": "01:30:52",
      "text": "你以前更多的是啊人家美国的企业发布什么样的这个规范，我们去跟着对吧？那现在我觉得中国企业其实也可以去讲来发布这样的一个规范。那我们提倡什么样的一个规则，其实我们也可以去引领整个的这人工智能产业发展未来的这样的一个规则的一个方向。",
      "speaker": "发言人3"
    },
    {
      "time": "01:31:11",
      "text": "就在这次联想在参与的这个倡议书，人本智能倡议书里边，这上面有一条第三条，它是讲加强行业的自律，就倡导行业各个利益相关方都要积极参与和制定更负责任的行业标准和规则。这个也是我觉得现在大企业都意识到的一个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:31:32",
      "text": "好，非常感谢两位老师今天就AI技术的发展做了如此深入的讨论。我想从我目前看到的内容和听到的节目来看的话，深度还没有到两位老师这么深的那本期节目开头也讲了，其实黄仁勋和奥特曼在年初已经放了两个大炮了。可以看到今年我想AI技术它无论是在应用还是在本身的技术突破上都会可能还会有新的。进展。我想两位老师可能今天还会有更多的机会来我们东腔西调一起来聊一聊AI技术的新突破。非常期待两位老师能够在日后能够再次相聚，这期也是我们东腔西调在蛇年的第一期，在这里面祝愿大家新春快乐。",
      "speaker": "发言人2"
    },
    {
      "time": "01:32:20",
      "text": "大家狗年后大家蛇年快乐，祝大家蛇年快乐。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "随着人工智能（AI）技术的迅速发展，监管相对滞后的问题日益凸显，特别是在美国这样的技术先进国家。历史上重大事故促使国际社会对核能制定更严格的监管措施，类似地，AI领域也需要经历一系列问题后，才会促使人们加强监管。讨论中提到AI引发的错误模仿行为、利用AI学习犯罪等严重问题，强调了监管的紧迫性。企业自律被重视，同时强调了中国在AI领域进步和责任，指出发布负责任的行业标准和规则的必要性。专家们深入探讨了AI技术如何改变我们的语言、观点、论证和证据的生成方式，如何使得真假难辨，突显了制定相应规则和法律以保护个人隐私、确保技术正向发展的重要性。技术与人类社会的关系被强调，技术已经成为人类自身的一种延伸，需要维持其正向轨迹，确保AI技术服务于人类福祉。对话还触及了全球合作、跨学科研究以找到确保技术发展服务于人类社会的可持续发展解决方案。总之，随着AI技术发展，需紧密关注其伦理影响和社会责任，确保技术进步造福人类社会。",
    "qa_pairs": [
      {
        "question": "在AI技术快速发展的背景下，人们如何适应它，以让生活变得更幸福？",
        "answer": "这是一个前沿且重要的话题。最近OpenAI和英伟达分别发布了关于通用人工智能AGI的进展以及物理AI的概念，展示了AI对未来发展的愿景。然而，AI发展也带来诸多问题，如AIGC产生的内容真假难辨、AI在情感陪伴中可能取代真实社交、AI生成信息的版权归属等。要适应AI，我们需要思考如何在享受AI带来的便利的同时，解决这些由AI发展引发的社会矛盾。",
        "time": "00:05:02"
      },
      {
        "question": "AI是否已经开始入侵您的生活和工作？",
        "answer": "是的，AI已经不可避免地进入了我们的生活和工作，有时是主动使用，有时则是被动接触，比如学生可能利用ChatGPT写作业，迫使教师不得不去熟悉并应对这一技术。",
        "time": "00:08:50"
      },
      {
        "question": "新技术对于人类社会的冲击是否是第一次？能否回顾一下过去500年有哪些重大技术发明对人类社会产生了深远影响？",
        "answer": "技术对人类社会的冲击并非第一次，从大航海时代、大机器工业时代到如今的AI时代，每一次技术革命都会带来类似的冲击。例如，在大机器工业时代，虽然手工制品依然存在，但因其稀少而显得珍贵；新技术会重新塑造人的欲望和价值观，如避孕工具改变了人们对性的认知，使之更加正当化；同时，工业流水线工作也改变了人们对工作的认知，使人在工作中更像机器的一部分。这些例子都表明，新技术往往会带来社会结构和思想观念的重大变革。",
        "time": "00:11:39"
      },
      {
        "question": "在齐格蒙特·鲍曼的作品中，他提出了如何让工作重新变得有意义和有价值？",
        "answer": "齐格蒙特·鲍曼认为，在工作被技术简化，个体淹没于流水线且缺乏对产品整体感的情况下，我们构建了新的观念，即工作只是作为实现消费奖赏的工具，通过消费来补偿工作中的艰辛。他主张需要有严格的福利保障制度和休假制度，使人们有足够的消费时间，从而赋予工作一定的意义和价值。",
        "time": "00:15:41"
      },
      {
        "question": "技术发展对人的思想和现实生活有哪些具体影响？",
        "answer": "技术演进具体影响了人的时空观、工作观念、生育观念和性观念等方面。例如，随着技术的发展，人们的时间感、空间感发生了变化，并且对工作的理解也有所改变，同时催生了消费主义，将其视为应对技术导致的工作无意义的一种补偿方式。",
        "time": "00:16:40"
      },
      {
        "question": "技术发展是否存在不可预期性？",
        "answer": "是的，技术发展具有不可预期性。许多重要的技术突破往往是偶然性的，它们基于过往各种技术积累，在某个临界点上产生大的变革，如智能手机的出现就是一个例子。此外，技术产生的社会效应也是不可预期的，例如大航海时代的开辟并未预期到贩卖黑奴和工业化生产等后果。",
        "time": "00:18:20"
      },
      {
        "question": "法律和制度对于技术带来的社会效应有何回应？",
        "answer": "法律和制度回应通常滞后于社会现象的出现和发展。它们往往在某一新事物形成一定模式并造成普遍影响后才进行立法。比如工作福利和安全保障等，都是在一系列社会灾难之后才逐步建立健全的。",
        "time": "00:19:53"
      },
      {
        "question": "AI技术发展有何独特之处？",
        "answer": "AI技术发展速度快且与个人生活紧密相连，形成AI内容生产的回音壁，其影响力超越了以往任何技术，深刻地改变了个人生活，甚至可能导致人类进入一个虚拟与现实交织、缺乏历史时间感、实体空间感和目标体验感的“三无”状态。",
        "time": "00:24:05"
      },
      {
        "question": "为什么认为当前人类面临技术适应不良的问题？",
        "answer": "因为当前技术发展迅猛，已经显著脱离了文化演化的吸纳进程，人们来不及适应新科技的快速迭代升级，许多人感觉自己处于技术移民的状态，难以掌握和应对最新的技术变革。这种技术发展速度之快和深度之深，使得传统的文化演化适应机制失效，从而引发了现代性问题，如精神世界的迷茫和相对主义、虚无主义倾向。",
        "time": "00:26:31"
      },
      {
        "question": "在当前时代背景下，人们的日常生活是否还能够形成清晰的时间主线？",
        "answer": "现在人们的生活时间感变得复杂且无历史感，像复调音乐，主旋律与副歌交织，难以用单一主线概括。由于工作、家庭、个人兴趣等多种活动在不同时间段发生，且影响力各异，导致记忆变得模糊，日常生活呈现破碎状态。",
        "time": "00:31:04"
      },
      {
        "question": "空间方面发生了什么变化，带来了什么样的体验？",
        "answer": "空间方面，我们的主要生命活动对物理空间的依赖正在减少，越来越多地发生在一个虚拟的、无所不在但又不存在实体的互联网空间中，因此我们有了无实体的空间感。",
        "time": "00:32:50"
      },
      {
        "question": "这种时间和空间的变化对个体的意义阐释造成了什么影响？",
        "answer": "这种变化导致意义阐释结构变得困难，提供完整意义变得麻烦。因此，人们倾向于活在当下，享受即时的感官快乐和体验，而无法为这些碎片化的快乐赋予明确的意义或长远目标。这种体验被称为无目标的体验。",
        "time": "00:33:23"
      },
      {
        "question": "AI的发展和技术进步是否已经对个体和社会生活产生显著影响？",
        "answer": "AI的发展确实带来了非常显著的变化。信息技术时代的技术进步每一步都直接应用于个体，使得个体迅速融入技术洪流中。在制度层面，法律已经开始针对AI带来的风险进行预防性立法，如欧盟人工智能法，以应对未来可能产生的巨大影响。",
        "time": "00:38:12"
      },
      {
        "question": "面对快速发展的AI技术和其带来的风险，立法应该如何应对？",
        "answer": "立法应采取原则性与具体细化相结合的方式，设定基本框架并由执行者根据技术发展不断做出针对性的回应。同时，立法强调以人作为根本目的，保障人工智能服务于人类福祉，而非将其作为工具。除了立法，知识界、思想界以及人工智能企业都应承担社会责任，共同促进技术向善发展。",
        "time": "00:43:39"
      },
      {
        "question": "人工智能对生活的影响是否可能超过药物，并且在何种层面上存在挑战？",
        "answer": "是的，人工智能的影响可能超越药物。药物的研发有明确的目标、效果和副作用，而发布新的软件如短视频平台，在人们自愿使用的情况下，其对人的影响更为复杂，很难量化评估其好坏。比如某音这类短视频软件，用户可能在不知不觉中花费大量时间，陷入空虚无聊中，这引发了关于它们是否真正为用户带来益处，还是仅仅作为赚取流量的工具的讨论。",
        "time": "00:45:46"
      },
      {
        "question": "文化民主化时代下，权威等级结构的变化以及现代阅读状况如何？",
        "answer": "在文化民主化时代，传统的权威等级结构逐渐瓦解，阅读习惯也发生了巨大变化。据统计，目前图书行业中有64%的新书半年内销售量不到100本，而达到5000册以上的书籍仅占整个出版行业种类的4%。人们的阅读方式正转变为以影像为主，这使得我们很难评估这种转变对人的整体影响。",
        "time": "00:47:38"
      },
      {
        "question": "新技术与药物相比，在立法和监管方面存在哪些挑战？",
        "answer": "新技术与药物在对生活产生严重的影响方面具有同等性，但新技术的立法和监管困难更大。药物有明确的标准和判断依据，而新技术的应用场景广泛、后果难以预测，导致难以建立相应的审核机构和评价标准，比如AI技术和生物技术的结合体，可能会对记忆等人类基本能力产生根本性改变，这是前所未有的挑战。",
        "time": "00:48:56"
      },
      {
        "question": "欧盟在人工智能立法上的原则是什么，以及与人本智能的关系？",
        "answer": "欧盟的人工智能立法基于风险管控理念，设定一些基本原则以降低潜在风险。然而，根本逻辑是要从更深层、更底层进行全面性的原则思考，确保AI与人的关系是“作为目的而非手段”。此外，中国企业和学界也在尝试提出人本智能治理原则，即从人的角度出发对AI进行规制，但这需要进一步细化和规范化操作层面的内容。",
        "time": "00:51:51"
      },
      {
        "question": "为何对社交媒体和人工智能的监管相较于传统药品、食品严格程度较低？",
        "answer": "社交媒体和人工智能内容的生产主要由用户完成，而非平台直接生产，且信息量庞大，无法逐一审查。与传统药品、食品监管不同，后者经过严格审批并有食品安全标准，而社交媒体目前更多依赖用户自我审核和平台自律，导致监管难度加大。此外，各国对于新兴技术的监管态度各异，欧盟和美国分别采取了自上而下的立法和自下而上的自发秩序形成方式来应对这一挑战。",
        "time": "00:53:57"
      },
      {
        "question": "在技术领域中，如何将法律、伦理和公共政策的要求融入到技术研发和使用过程中？",
        "answer": "这实际上涉及到技术正当程序的概念，即在技术发展过程中，如何将法律、伦理及公共政策的要求纳入其中。对于人文社会科学学者和公共政策制定者来说，提供人工智能伦理规则是一项挑战，以便相关公司能将这些规则融入技术程序内。同时，监管者也需要提出切实可行的监管要求。",
        "time": "01:02:04"
      },
      {
        "question": "企业参与发布人工智能相关宣言有何重要意义？",
        "answer": "企业参与发布宣言意味着做出了承诺，是对社会公众的一种承诺。这种承诺成为公众监督企业履行责任的重要机制。例如，美国联邦贸易委员会看重大公司的承诺，如果企业承诺保护用户隐私但未遵守，则可能被视为欺诈行为并受到处罚。",
        "time": "01:03:03"
      },
      {
        "question": "如何处理不同地区对人工智能治理的不同态度和文化差异？",
        "answer": "不同地区如美国、欧洲和东亚在治理人工智能方面存在文化差异。比如，美国更看重企业的诚信经营和对隐私的尊重；欧洲则更注重实质内容的规定；东亚地区可能更强调快速应用底线性规则。未来不同地区可能会基于自身文化传统和发展阶段制定出差异化的AI治理策略。",
        "time": "01:05:56"
      },
      {
        "question": "对于目前无法明确判断的灰色地带，应如何处理？",
        "answer": "在面对大量灰色地带时，可以选择放慢脚步，保守决策，确保AI技术的安全可控，并服务于人类文明的进步方向。同时，不同地区可能会有不同的监管方式，如英美采取消极监管模式，而欧洲和东亚可能更倾向于积极监管以引导正确发展。",
        "time": "01:08:50"
      },
      {
        "question": "在全球范围内建立共同治理框架的可能性有多大？",
        "answer": "全球性共同治理框架的建立具有现实性担忧，因为过度监管可能妨碍技术突破，而技术竞争、资本主义竞争以及地缘政治竞争会驱使业界加速发展。然而，在可操作层面上，业界可能会通过达成共识，在不同链或技术环境中引导活动，以结合技术发展与人本取向。此外，不同国家和地区之间的立法立场不同，如欧盟注重个人隐私保护，美国倾向于公司和个人权益对抗国家的干预，中国或东亚可能更侧重国家与公司间的合作。",
        "time": "01:14:26"
      },
      {
        "question": "欧盟的立法对数字世界有何正向意义？欧盟的监管对美国和中国有何具体影响？",
        "answer": "欧盟的立法及其讨论为整个数字世界以人为核心、以人为本的规范提高了标准，提升了观念水平、伦理水平和规则水平。虽然它不直接作用于中国或美国公司，但其立法的溢出效应会间接影响到这些国家的公司。欧盟的监管会对在美国市场的公司产生压力，尽管监管不是由美国政府直接施加，但因需满足欧盟标准，美国公司仍会面临类似问题。同时，欧盟对隐私政策等的严格要求也会间接影响到中国的发展。",
        "time": "01:17:54"
      },
      {
        "question": "欧盟在人工智能和数字领域的立法对其他国家有何影响？",
        "answer": "欧盟在这些领域的立法和规范，即使没有直接作用于其他国家，由于美国互联网公司在欧盟业务的需要，他们必须遵守欧盟的立法要求，这将压力和标准回传到美国和中国等国家。",
        "time": "01:19:07"
      },
      {
        "question": "言论自由治理和市场竞争的关系是什么？",
        "answer": "言论自由治理在一定程度上依赖于市场竞争机制，各种观点在市场上相互对冲，以竞争决定哪种观点更受接受。技术治理也是如此，不同价值观和立场的企业在市场上竞争，促使整体治理水平提高。",
        "time": "01:20:30"
      },
      {
        "question": "对于强监管与技术发展的讨论现状如何？在人工智能技术快速发展下，应如何应对监管问题？",
        "answer": "目前存在对强监管与技术发展的争论，特朗普政府上台后倾向于放松监管，特别是对人工智能领域的监管。然而，随着问题出现，如人工智能引发的安全事件，人们开始重新审视并推动制定更严格的监管规则。技术发展势不可挡，需要提前预备原则性的预案，在出现问题后能够迅速达成行业共识并采取行动。大企业在技术发展中应承担立法者角色，通过自律避免更强的政府干预，并引领人工智能产业安全可控地服务于人类福祉。",
        "time": "01:22:31"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "AI时代：人本智能与未来生活幸福",
        "summary": "本期播客讨论了人工智能（AI）在人本智能时代如何影响我们的生活，以及如何在技术迅速发展的同时确保我们的幸福感。对话提到了OpenAI和英伟达在AI领域的最新进展，包括通向通用人工智能（AGI）的路径和物理AI的概念。同时，也探讨了AI生产的内容模糊真实与虚拟边界所带来的问题，以及AI在情感陪伴领域的应用，引发人们对于AI与现实人际关系的思考。"
      },
      {
        "time": "00:05:02",
        "title": "AI技术发展对内容生产和版权的挑战",
        "summary": "讨论集中于AI技术快速发展对内容生产和版权归属的影响，以及由此产生的版权归属问题，即AI生成内容的版权归属是AI自身、命令AI的人，还是没有版权。此外，还探讨了AI技术对内容生产者带来的第三方影响，导致内容生产者在创作过程中必须考虑AI生成的内容，以及由此带来的对传统创作方式和版权体系的挑战。"
      },
      {
        "time": "00:08:43",
        "title": "AI技术对现代生活和工作的冲击与反思",
        "summary": "对话围绕AI技术对生活和工作的渗透展开，讨论了学生使用AI写作业、AI生成图片占据网络搜索结果等问题，引发了对人类创造价值的思考。进一步探讨了技术进步，如大工业时代和大航海时代，如何改变了社会结构和人们的生活方式，以及这些变化对思想和制度的影响。最后，对话转向回顾过去500年间重大技术发明对人类社会的深远冲击。"
      },
      {
        "time": "00:13:05",
        "title": "技术进步对人类思想和社会规则的重塑",
        "summary": "技术从最初的工具性被理解为能塑造人类心智、认知和价值观的重要因素。早期的技术观认为技术是中立的，其影响取决于使用者，但现代观点认为技术不仅能够实现人类已有的理想和愿望，还能重新塑造人的欲望和需求。通过避孕工具和工业文明带来的工作模式变化等例子，展示了技术如何影响人类对性的认识、工作的意义以及消费主义的兴起。这些变化不仅体现在个人层面，还要求社会制度和规则进行相应的调整，以适应技术进步带来的挑战和机遇。"
      },
      {
        "time": "00:17:42",
        "title": "技术发展、社会影响与法律回应的不确定性",
        "summary": "对话围绕技术发展尤其是人工智能的不可预期性展开，强调技术诞生及其社会影响往往超出预期，且法律制度对这些变化的回应通常滞后。讨论中指出，技术的产生及其引发的社会效应存在滞后性，而法律对于新兴技术导致的社会现象的回应更慢，往往在问题反复出现并形成一定模式后才会进行立法。随着AI技术的快速发展，其与个人生活结合日益紧密，导致了前所未有的影响和挑战。举例说明了AI在信息检索和内容生产上的效率，以及由此可能形成的AI内容生产的回音壁现象，提出了未来可能面对的全新情况。"
      },
      {
        "time": "00:24:45",
        "title": "人工智能对人类文化与社会意义的影响",
        "summary": "在讨论人工智能的善治之道时，提到了人工智能可能引导人类进入一种“三无人类”的状态，即无历史的时间感、无实体的空间感和无目标的体验感。这种状态反映出技术，特别是人工智能，不再仅仅是实现目标的工具，而是塑造人类社会和文化的重要力量。通过分析技术的发展速度与人类文化演化的速度之间的差距，探讨了技术进步对人类社会、文化意义结构的深远影响，以及这种变化对人类适应性和意义构建带来的挑战。"
      },
      {
        "time": "00:29:57",
        "title": "现代生活中的时间碎片化与无目标体验",
        "summary": "现代生活的时间被多个频道和活动所分割，导致时间感变得破碎，难以形成完整连续的叙事框架。人们在工作、购物、社交和家庭等不同时间频道中生活，每种活动对时间的重要性不一，使得年度总结变得复杂而无主次。此外，物理空间的依赖减弱，生命活动主要发生在虚拟的互联网空间，导致空间感变得无实体。这种时间和空间的变化使得提供完整的意义变得困难，因此人们倾向于活在当下，追求无目标的体验，通过无数个瞬间的小快乐编织成生活的体验，但这些体验往往无法形成明确的生活目标和方向。"
      },
      {
        "time": "00:34:44",
        "title": "技术发展与人类文化适应的冲突",
        "summary": "对话探讨了技术快速发展对人类文化和心理状态的影响。一方提出，当前技术进步速度超越了文化适应的速度，导致年轻人情绪和情感状态的不稳定，以及对自我控制的矛盾感受。此外，还提到了NFT艺术作为一种新兴现象，反映了技术原住民与老一代对艺术理解的世代差异。这些现象表明，技术的介入性及其带来的变化，正在挑战传统的文化结构和人类的适应能力。"
      },
      {
        "time": "00:37:34",
        "title": "人工智能技术对个体和社会的影响与法律回应",
        "summary": "对话深入探讨了人工智能技术快速发展对个体精神结构和社会生活带来的显著变化，以及这种变化如何在制度层面引发新的法律回应。指出，与以往技术发展相比，信息技术和人工智能技术更直接地影响个体，加速了技术与个体之间的互动。此外，讨论了法律回应的滞后性以及预防性立法的必要性，以应对人工智能技术可能带来的未知风险。还强调了立法者需要通过基本原则和框架，结合技术发展的动态，来灵活应对技术带来的新挑战。最终，提出技术发展应以人类福祉为核心，避免将人类变成技术的工具，强调了人本智能的重要性。"
      },
      {
        "time": "00:44:42",
        "title": "人工智能技术的伦理挑战与监管困境",
        "summary": "尤瓦尔·赫拉利在演讲中对比了人工智能与药物对人类生活的影响，指出人工智能软件由私营公司直接发布，无需经过类似FDA的严格审查，而药物则需要经过动物实验、临床试验等环节并获得FDA批准。人工智能对生活的影响可能超过药物，但评估其对人是否有益的标准更为复杂。此外，新技术如增强记忆力的应用，也引发关于人类本质和目的的深刻讨论，这为相关立法和监管带来了巨大挑战。随着新技术的快速发展，如何制定明确的评估标准并设立相应的监管机构成为亟待解决的问题。"
      },
      {
        "time": "00:50:27",
        "title": "人工智能技术的伦理与治理挑战",
        "summary": "对话围绕人工智能（AI）技术，特别是阿尔法折叠（AlphaFold）在蛋白质结构探索中的突破及其对疾病研究的潜在影响展开。讨论指出，AI技术不仅是一个外在工具，更是人类能力的延伸，因此需要基于人本智能的基本原则进行规制。此外，还探讨了技术与人紧密相连的背景下，如何设定全面性的原则思考，以及在操作层面如何规范和拓展这些原则。讨论还提及了食品安全监管与社交媒体内容审核之间的对比，强调了在AI时代，对技术的规制应从人的角度出发，以确保技术的健康发展和社会福祉。"
      },
      {
        "time": "00:56:38",
        "title": "社交媒体与人工智能监管挑战",
        "summary": "讨论集中在当前社交媒体与人工智能监管面临的挑战。指出社交媒体平台因其内容主要由用户生成，数量庞大，难以进行全面的审核，这导致了监管的复杂性。此外，讨论还触及到国家在人工智能技术发展与监管之间的平衡难题，以及欧美在监管思路上的不同，尤其是欧盟与美国在法律体系和监管方式上的差异。进一步强调了技术公司自律的重要性，以及如何通过自我监管和承诺来应对监管挑战。最后，指出了在人工智能和社交媒体治理上，如何将法律、伦理和公共政策要求融入技术发展的过程，以及企业如何通过发布宣言和承诺来接受公众监督的重要性。"
      },
      {
        "time": "01:05:32",
        "title": "不同地区AI治理策略的文化差异与未来畅想",
        "summary": "对话讨论了美国、欧洲和东亚地区在AI治理策略上的文化差异，指出这些差异源于对人的基本理解的不同。美国强调隐私和诚信，欧洲则在立法中注重实质性内容的规定，而东亚国家更强调快速应用底线性规则。未来，这些地区的AI发展将受到各自文化背景的影响，形成不同的治理逻辑。在前现代或早期现代，各地普遍存在权威主义文化，但随着时代变迁，英美转向放任但设定底线的治理模式，而欧洲和东亚则可能更倾向于积极监管，认为有时需要引导民众以保障其长远利益。面对难以判断的灰色地带，如隐私保护和暴力游戏的监管，不同文化背景下采取的策略也将有所不同。"
      },
      {
        "time": "01:10:30",
        "title": "AI技术发展与全球治理的挑战",
        "summary": "对话围绕AI技术快速发展及其对社会和全球治理带来的挑战展开。讨论指出，AI领域的竞争由资本主义和地缘政治驱动，这可能导致技术发展走向极端和冒险，进而影响技术向善的目标。同时，讨论触及虚拟世界与现实世界的关系，表达了对于人们情感、认知移民到虚拟世界可能带来的社会现实空间荒废的担忧。最后，探讨了在区块链技术爆发背景下，如何在业界达成共识，结合技术发展与人本取向，实现全球性治理的可行性。"
      },
      {
        "time": "01:15:55",
        "title": "全球数字治理的区域差异与影响",
        "summary": "对话探讨了全球数字治理中欧盟、美国与中国或东亚的不同立场，及其在国家、公司和个人之间的角色分配。欧盟侧重于严格立法以保护个人隐私，其立法的溢出效应影响了全球其他地区的数字政策。美国则强调市场自我调节，通过公司间的竞争提升治理水平，同时存在对政府监管的抵触。中国和东亚地区则表现出国家与公司在数字治理上的合作。此外，讨论还触及了技术发展与监管放松之间的关系，以及不同治理模式对人工智能产业可能产生的影响。"
      },
      {
        "time": "01:23:38",
        "title": "人工智能技术发展与监管挑战",
        "summary": "讨论了在人工智能技术快速发展背景下，尤其是美国这种技术最发达但监管较为宽松的国家，可能出现的问题及其监管挑战。通过历史经验，如核能监管的形成过程，指出只有在出现重大问题后，人们才能达成监管共识并执行。讨论还涉及近期与AI相关的安全事故，强调企业应承担起自我监管的责任，以避免政府的强力介入。同时，提出企业应有立法者的自觉，通过自律来推动技术安全、可控地服务于人类福祉，以及中国企业在国际上应承担起规则制定者的角色。"
      }
    ],
    "mindmap": null
  }
}