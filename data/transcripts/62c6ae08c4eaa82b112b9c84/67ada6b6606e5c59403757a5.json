{
  "pid": "62c6ae08c4eaa82b112b9c84",
  "eid": "67ada6b6606e5c59403757a5",
  "title": "Vol.154 产业观察26｜“DeepSeek开了第一枪，更值得期待的是AI普惠”：与季宇聊AI产业新机遇",
  "task_id": "2yjoqzbaj7gbq68l",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "大家好，欢迎大家来到今天的高能量，我是峰瑞资本的李峰。这一期我们做的是产业观察。因为在这个春节期间最热闹的话题之一，跟中国的科技界一样，也过了个春晚，就是关于dept sick的在中国和在世界的出圈。这里面有非常多各种不同的讨论。从最宽泛的来讲，大家说这个影响了美国科技行业姐妹花的估值，带崩了美股。也有说因为这个事儿带动了中国的科技的重估和希望，所以说中国的资本市场因此就开始上涨了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:33",
      "text": "具体在技术上，大家关心的可能更多的问题是deep seek到底会好在哪里？以及dept yu e到底做了哪些不同的事情？它到底是个科学创新，是个工程创新，还是个技术创新？为什么他做成了其他的这些大模型公司，或者国外的这些公司并没有做这些事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:51",
      "text": "当然还有大家对中国最敏感的芯片行业的关心。因为deep sick的出现就会导致算力的需求或者英伟达的需求显著下降，还是会更多需求，以及因为它带来的模型上的变化，是导致更不同的跟英伟达类似的芯片公司的机会，还是更多的变成了更靠近英伟达相关的机会。以及中国在出现了deep sick之后，影响了大模型底下的这些硬件需求和硬件环境之后，中国的不同的芯片企业会不会有更特别的中国机会。我们用争取1到2集的时间来讨论一下这个话题。作为一个投资机构，我们也要求科技相关的同事各自去描述了自己的看法。今天我们给大家先带来的产业观察，是由我们投的最先开始做推理芯片。其实今天更多的是更宽泛产品线上的AI芯片相关的星云科技的CEO觊觎。当然他也是知乎上的一个非常著名的芯片相关领域的大V和我们科技组同事李刚他们两位来一起先给大家做一个围绕着deep sik出现以后，跟硬件跟芯片相关可能会有的影响。欢迎大家在听完以后提出自己的观点意见或者不同类型的建议。想听到关于deep sik的什么问题，我们争取下一期讨论deep sik的时候来跟大家回应。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:16",
      "text": "大家好，我是枫瑞资本投资人李刚。我平时主要关注科技，特别是硬件相关，包括机器人AI芯片。基宇也是我们的老朋友了，先请继续简单介绍一下自己。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:28",
      "text": "谢谢小刚。大家好，我是邢云的创始人季宇，我们是一家做针对大模型推理的GPU芯片公司。其实之前逾期的高能量里面，我也来参加了这个节目。然后分享了当时是关于英伟达的股票，包括英伟达的这个统治力各方面的一些分析行为。本身就是一个做芯片的公司，会有很多新的机会是来源于下游的大模型，因为这个是行业最大的因素。其实今天来聊一聊最近这个特别火热的dipstick，因为也是我们本身一直关注的一个方向。因为我们公司的期望就是希望把这样最好的模型能变成一个消费级价位的东西，让所有人都能用得起，能用最满血的这样的一些模型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:14",
      "text": "这个春节期间dept c和讨论热度是尤为的高，它不仅引发了英伟达的股价震荡，甚至号称有政府说要限制或者禁用deep sk我们很好奇说deep sk为什么能掀起这么大的影响力？但是在讨论这个问题之前，我们可以先各自聊一下，我们自己用语言模型，特别是deep sick的经历。咱们其实可能在半年甚至一年之前就已经开始聊到过deep sik。然后据我所知星星也很早在内网就部署了deep k的模型。要不季总先说一下你的这个经历还有感受。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:54",
      "text": "对，其实我们开始关注私有化部署，包括去尝试使用这些模型，是从大概去年8 9月份，就是AI编程当时火热起来之后。但是因为AI编程如果全依赖云端的话，其实有大量的订阅费，还有信息安全的问题。所以当时我们在这样的一个情况下，正好看到deep sik v2包括2.5的模型，市面上反馈还不错。所以我们就尝试了一下，感觉确实效果非常不错。尤其在我们当时关注的AI编程这个场景下，觉得已经达到了一个高度可用的状态。这也是我们希望去了解未来大家去私有化部署，包括去使用大模型的时候的一些实际的体验。把我们自己变成我们自己的客户的这种视角来感受。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:41",
      "text": "我们内部其实在最开始是部署了很多种模型都试了一遍，包括千问，包括deep sig其实这些模型都非常优秀。而且私有化部署之后，跑的效率非常高比云端的API还要高得多。但最后确实还是用的deep sk 2.5的这个模型，因为它的效我确实是最好的。其他的模型有些体量会小一点，所以跑的速度会更快。可能就是大家问一个问题之后，刷的一下整个屏幕里面就全部填满了。但是一旦上到编程这样一个高强度的逻辑性的场景里面，对模型的能力要求还是会比较高的。我举个例子，我们比较关注很多开源的插件，包括在AI编程里面的一些使用。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:22",
      "text": "我们最早是用的continue这么一个插件，后来其实还有了像叫c line这样的一个agent流的一个工具，然后们也都使用了一下。确实只有这种特别大规模的模型，然后能够在这些上面比较稳定的工作。然后相对比较小的。虽然它的整体，比如说做代码补全可能OK。但是一旦到了那种agent流，对于这个指令跟随，包括这方面有更强要求的。可能相对小一点的模型，其实会出现指令跟随丢失，导致插件开始崩溃的这种情况。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:56",
      "text": "我们其实还有一个特殊的地方，就是我们是一家芯片公司。所以大家在AI编程里面关注的比较多的是像python或者前端，可能会多一点。对。但是在芯片公司，像VERLOG这个其实可能大家关注不会那么多，包括尤里奥也不会那么多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:12",
      "text": "所以其实我们内部刚开始使用的时候，很多做芯片研发的同事其实对这个事情是比较怀疑的一个态度，所以想尽一切办法去考验他。但是确实每个人都经历过，就是说从完全不屑到使用了之后感觉还不错，甚至有点惊喜。对，再到后面其实开始尝试高强度的使用的这么一个阶段。所以我们觉得在那个时间点，deep sic的这个模型已经达到了一个可用的状态。所以我们看到像V三这个模型发布，然后包括而望这样的一个带reasoning能力的模型发布。开源模型已经从一个小范围可用，可能已经变成一个大范围可用的状态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:52",
      "text": "基于我觉得更多的是以生产者的角度来聊了一下这个语言模型的使用。对，你们主要是在编程，用在生产力和输出上面。我平时基本上是混用所有的模型，像kimi豆包，包括腾讯的、阿里的都在用。然后更多的还是属于消费者角度，就是问了一些问题让他帮忙总结一下文章。然后在春节期间正好有空在我的电脑上自己部署了一下这个32B的量化的模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:24",
      "text": "也是发现在本地化部署解决了一个非常大的问题，就是在线的模型除了朋友之外，大家其实都非常的吝啬。他不会愿意输出长文。你丢给他一个长文章，虽然号称大家可以常上下文，但是测试之后发现他还是以这种搜索的方式去读。然后你给他一个哪怕几万字的文件，让他全文翻译或者说做详细总结，他其实都是做不出来。我是发现在我自己3090正好能跑这个32B的模型。虽然会越跑越慢，但它是能把你的任务给完整执行下来。这个也算是我最近感受到这个本地化部署的威力。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:05",
      "text": "坦白讲从各个模型的能力上看我倒是觉得大家好像差距没有特别大，可以说各有所长。对，那deep sick感觉春节这会儿他出圈很大一部分就是他的这个行文风格，还是挺有趣的。但是这个在早期的GPT，包括用cloud这些，你调试一下还是能看到这块。我觉得未来如果我们的安全的需求变高，它的创造力我估摸着可能也会有一些下降吧。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:35",
      "text": "这段时间的deep sk所谓被进入到大众视野更火，还是一个算是意料之中也是意料之外的情况吧。我觉得deep sick能火我是不意外的。因为从历史上看，他们的这个工程能力和基座模型能力一直是很强的那特别是他做强化学习和所谓的他有思考的这部分能力出来之后，确实是至少在国内是比较有突破性的一个进展。但是它的开源加上它的免费使用，也是促进了它的这个变火。但是它火成这个程度确实是比较超预期的。因为没有想到这个好像能把它捧到了一个非常高的高度。也看到说这个是国运的层面，包括是叫中国特色的AI平权，我感觉还是整体还是挺惊讶的。不知道你对这段的热度怎么看？",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:32",
      "text": "其实整个出圈程度我相信是超过所有人的预期的。当然我觉得这里面有一个很重要的因素，可能也是春节我举个例子，我创业就是本身在做大模型相关的事情。然后跟我的父母或者我的一些亲戚朋友去讲我到底在干什么的时候，我可能需要花一点时间去跟他讲一讲。你可以下一个APP，然后你可以在出去旅游的时候去问他一些东西或者去怎么着，然后再解释我们做芯片到底是为了什么。这次我觉得节假期有一个好处，我们平时在日常工作或者在假期的这个时间点，其实我们也很难去教。可能爸妈听说了deep sic很好活，但是怎么用不知道。然后我们刚好回家过年，就有机会去手把手教他，这也是他这个东西能大规模出圈的一个很重要的因素。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:19",
      "text": "当然我觉得其实还有一个从技术的角度其实。之前的模型，包括我们之前用的2.5的模型，它还是上一代的这种就是帮你补全，或者去帮你chat这种模型。然后带深度推理能力的开源模型，其实这个算是比较早的一个，而且是真正做到了效果非常不错的，也增加了大家使用它的一个易用性。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:42",
      "text": "对，因为以前的模型我的感觉就是说如果你能很好的prompt你的模型的话，你才能够去使用它。这个其实就造成了，比如说我去给我的父母去介绍这个东西的时候，他们可能问了一个他们觉得很简单的问题，但是这个模型打的一塌糊涂。然后我还得想办法解释说你得这么问，就会导致大家用起来会相对难一点。但是而让他自己能够思考，甚至我记得好像district的这个tech report里面，其实还建议不要去过度的prompt你的模型。对，就是你可能prompt了之后反而效果会变差，让模型自己去理解你。所以我觉得这个也反过来使得这样的一个模型到了大众视野里面，大家用千奇百怪的方式去问他的时候，都能发现这个模型可以很好的解决大家的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:28",
      "text": "对，正好刚才说到了这个开源跟思考这两个关键词。Deep six的这个开源模型就这两方面来看有什么大的区别吗？和国内外的模型相比。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:42",
      "text": "我觉得其实有几个点。第一个就是说思考类的模型，其实之前应该主要就是o one。对，然后其他几家包括像kimi的这个K1.5，也是差不多同一个时间去推出来的对，其实不同的模型区别还挺大的。我自己使用下来，我感觉像TV的那个模型，我不知道是不是标注的人的风格的问题。我发现他的语言非常方言化，有非常多的北方的口语化的这种用词。然后dept k的那个模型就相对好像更板正一点，就是会用相对更书面化的一种方式来描述。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:21",
      "text": "一般意义上这种开源模型，其实真正有深度推理的能力的还是比较少的。因为深度推理的能力其实很依赖模型本身的质量要足够高。因为如果一个很小的模型，它可能连自己的上下文理解都会出问题的话，这个深度推理能力相对会难一些。所以虽然看起来现在市面上有非常多的模型，但是我们从实际使用并且想把它用到生产力场景的过程中，也把市面上各种模型筛了一遍，最后发现首先得选高质量模型，非常大的这种模型。然后其次，这种非常大的模型如果还要加上reasoning能力，目前可能也只有deep sick这个是可以达到这样的一个要求的那其他的像拉玛虽然也有特别大的模型，但是它整体的质量可能相比70B的模型没有特别大的提升。所以这里面可能还是有一些技术门槛，包括难度。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:13",
      "text": "我这里顺便可以给大家解释一下这个开源模型，闭源模型的这个概念。开源其实我觉得在源模型的这个时期是它有了很多种不同的开源。我们现在通常讲的开源模型一般指的是会把模型的参数给开源出来。至于模型的训练，或者说它的更上游的架构，通常看还是开源的比较少。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:39",
      "text": "现在比较流行的开源模型包括deep seek，然后拉，然后还有阿里的千问的系列。这些开源模型通常他们会有一个所谓的最大的完整版的模型。在这个完整版的模型基础上会对它的模型规模进行一定的压缩，会发布一系列的不同参数的模型，可以方便大家跑在各种不同的设备上。比如说像电脑、手机，你就可以跑一个GB的小模型，那你在服务器上你就可以跑相对大的模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:11",
      "text": "Open I其实最早的也是一个开源的典型了，它的GPT2、GPT3都是开源。但是他们开始商业化之后，都基本上已经不怎么开源了，甚至他们的技术报告也都是比较保守了。开源生态这个其实是一个很复杂的事情了。当然我们可以简单的理解说，这个开源是把相当大的一部分模型能力给释放出来。可以让第三方和个人去自己来使用类似的模型能力，而不需要依赖这个模型公司本身的算力和它的API。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:47",
      "text": "回到另外一个，我觉得deep sik它的模型的一个比较大的特点，就是它是这个MOE的架构。它是一个参数规模相对比较大的，但它的推理成本是比较低的。你觉得为什么他们的技术路线能够在保持模型质量情况下，还能比较大的降低了成本？我们从API调用看deep sick的r one的调用成本大概是GBTO3 mini的接近10分之1。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:18",
      "text": "我觉得这里面其实有几个方面的原因。我觉得首先是ME这个结构本身是参数量可能非常大，包括大家可能也听说过像这个671B大家成为这个满血的模型。那一般这个多少B这个B链这个参数其实就是跟这个G其实是一个概念。所以如果不考虑这个数字的精度，如果我们就按巴比特来算的话，其实671B基本上就是671GB的这个存储。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:47",
      "text": "可能一般大家只会觉得硬盘会有671B以上一个T的硬盘或者多大的硬盘。但是它对于运算的时候需要的这个内存也好，显存也好，需要这么大的这个其实它的需求量是非常大的，但是它有另外一个好处，就是实际上真正参与生成，大家用的看到的每一个token的实际用到的参数量其实并不是全量的。因为它所谓的MOE就是一个稀疏的模型，就每次参与到去计算下一个token的参数，其实只有37B所以这个跟以前的dance模型是有比较大的区别的。以前的dance模型可能70B的模型，它的这个存储容量需求可能就是70G然后它的这个显存读取的这个要求，可能也是要为了生成这一个token，也要读70G的参数。那这个时候其实就会造成实际上虽然看起来是一个6 700B的一个模型，非常大。但是它每次推理一个token，其实需要读的参数量甚至可能不如一个70B的模型的参数量。所以这个造成了它推理的成本实际上可以变得更低。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:53",
      "text": "然后第二点，我觉得也跟deep sic本身在推理上的一个优化有很大的关系。Deep seek其实他们本身在整个info跟算法上是做了一些联合的创新的。以前大家可能更多受限于dance技术路径的一个惯性，所以大家可能会更倾向于按照TP并行或者这样的一些方式。但是它本身在不管是训练还是推理上，其实都把原来这种模型分布式的方式完全转向为MOE的expert的这个维度去做。加上整个推理框架，其实都是为这样一件事情去定制的。所以这里面还有更大的空间可以挖掘出来，这也是把这个模型进一步降本的核心方法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:35",
      "text": "我觉得总结起来其实就两个点，第一个就是MOE这样的一个架构，从地形原理的角度来讲，它的对推理的成本确实就是会比这种大的dance会要低。而且达到的效果可能会是一个软硬件结合起来更好的一个做法。然后第二个就是大家过去的路径依赖，导致大家的软件框架或者各方面其实都没有针对MV做太深入的针对性的优化。这块其实做更深入针对性的优化，本身又可以进一步的去降本。这个我觉得是更多是dipstick团队本身在跨领域协同，包括这个原创性的能力上可能更强。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:15",
      "text": "回到最开始的问题，DPC为啥能掀起这么大影响力？我简单总结一下，当然首先是开源加免费，它以非常低的门槛让大众消费者能有接触AI的机会，再叠加上春节这个比较特殊的时间点，大家可能产生了比较大的关注。技术层面上讲，刚才有说MOE，我理解是不是可以认为它是把更大规模的模型能力下放到了可能相对低成本的一些硬件上。对于业界来讲，大家也纷纷有了比较大的关注。最后就是刚才咱们可能没有提特别多，就是他的的思考和推理的能力，使得他天生的能够输出更长的结果。至少现在看更长的结果是能够提升整体问答或者说模型的质量的那在这个影响下，我总结就还是一个叫中国特色高性价比高质量的一个模型。它在天时地利人和之下，确实是产生了比较大的影响和关注。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:23",
      "text": "我们后面可以讨论一些相对更细节的问题。我们先从软件的来看，从transformer和attention这个架构出来这么多年。上次引发比较大规模影响力的是GPT3.5，算是语言模型的从0到1。这次看到是一家中国的公司展示的创新，而不是传统意义上的美国公司。当然这个强化学习在原模型确实还是OpenAI最早提出来的。但这次是中国公司或者说是deep seek背后可能的原因是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:00",
      "text": "Deep sik之所以会做这样一件事情，跟我们之前观察到的一件事情还是有很大相关度的。就是从很多美国公司的角度来讲，因为他们可以相对无限量的去拿到像英伟达H100这样的一些机器。包括很多创业公司。可能今天国内的创业公司很多会选择4090这种消费级的卡去搭建他们的整个基础设施。还有上面的软件，包括应用体系。那很多硅谷的创业公司可能直接就用的H100去做，因为对他们来讲这块是没有受阻的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:32",
      "text": "然后另外一方面，就是像NVIDIA本身也在推进像GB200这种更大规模更强的这样的一个机器。继续沿着open I的这个scaling load这样的一个路径上面。大家实际上是在一个随时可以买到大量H100，而且有预期的未来可以拿到比H100更强的GB200的这样的一个机器的预期下去做。软件做应用，做商业模式的，它是没有选择压力的，所以所有的路径都在往前走。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:01",
      "text": "然后在国内，其实我们看到因为受这个芯片禁令的一些影响，所以第一个国内不一定能拿到H100对，而且拿到的一般都是阉割版的一些芯片。所以其实在很长一段时间内出现了国内基本上要么是小规模的dance模型，要么是超大规模的MOE模型。这个其实就是选择压力带来的。但是在硅谷，比如说像meta，其实他们会训超大规模的dance模型，是因为大家的这个预期。当然硅谷这边也有很多MOE模型，但是这个属于一半一半。但是在国内就造成了基本上一个要么小小的单词，要么超大的MOE这样的一个路径上去选择。这个选择的过程中，其实因为原有的技术战本身是建立在大家可能从最开始的scanning low做小的单词做大的单词这么一个路径上去挖掘起来的。所以像dept QUE本身，它再次针对性的对M1做优化，其实就会带来巨大的竞争优势。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:02",
      "text": "在这样一个环境里面，因为其他的可能都是基于dance或者相对简单的MOE的这种方式去优化，那他可能只能做小的dance。但是在北美那边可能你还是可以用大的dance去跟这条路径去竞争的，而且你可能还不需要面临太多技术上重新去设计，重新去调整的一系列的压力，也能取得相应的成果。所以回答您刚刚的问题是，为什么是由一家中国公司来做的？我觉得反而是被这个禁令产生的这个环境的变化倒逼出来的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:35",
      "text": "然后现在市场上也有挺多传言说什么open I训练受阻了，毕竟他也一直在拖GPT5或者GPT4.5的发布。你觉得对海外他们这个算力资源不受限的情况来看，AI的发展或者训练是受到了阻碍吗？还是说这只是一个正常的节奏？",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:59",
      "text": "我觉得实际上是遇到一些阻碍的。过去两年，整个AI在排除中美竞争这件事情之外的主流叙事，实际上还是skin law。Skin law其实本质上就是沿着OpenAI，最开始把ChatGPT给训练出来，从这个GPT1、GPT2到GPT3这样一个路径，想进一步延续到GPT4GPT5。所以无论是这些大的基础设施厂商去采购大量的GPU，去建这个万卡集群，10万卡集群这样的一个方向努力。还是下游的芯片厂商，包括互联，包括硬件各方面去围绕这样一件事情，打造下一代规模更大，然后集成度更高的这个集群。其实都是为这样一个主流趋势去推进的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:42",
      "text": "但是我觉得从算法技术的角度来讲，skin law本身它可能突破是在GPT3往后。但是它很快实际上会达到一个技术路径能达到的临界点。GPT3或者GPT4，基本上他获得的这个提升是比上一代的深度学习模型是要高很多。但是你不能指望这条路径可以持续的帮你不断的获得提升。所以这里面是需要找新的范式的来维持这件事情。所以我觉得其实可能跟这个无关。更多的还是去年9月份的时候，坊间有越来越多的传言，说这个skin老师不是受阻。对我觉得其实这个跟deep sk能杀出来，这是一个相对独立的事件。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:22",
      "text": "当然我觉得deep sik它至少给大家普及了一个概念，就是似乎在单纯模型能力受阻情况下，我们用更长的上下文或者说更长的推理是能够提升性能。这一点其实包括open I的论文里面也能看到。那我自己的感受是对于大部分问题，我们能看到deep seek他的思考部分大概会占了一半的长度。那刚才你也说到，可以认为他其实是把人工输入复杂prompt的这部分需求给削弱了很多。你觉得这种长输出带来的模能力的提升，在未来它会进一步提升的。像open I他们现在可以通过比如说同时生成多个回答，然后从中投票出最好的答案。假如说模型的绝对的规模和能力速度增长没有那么快，那长度的增长会是下一个突破的点吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:19",
      "text": "其实这件事情我从很早之前就认为是必然的。因为就像我刚讲的，scaling law本身是一个范式，帮我们把语言模型这么复杂的一个任务给获得了让这个语言模型可以去理解我们的自然语言。那自然而然下一步就是我们能不能利用这个能力去达到更高的高度。因为如果我们持续的去沿着预训练的scaling要走，我们实际上是在不断的去让大模型能获得自然语言的基础能力越来越多。但是这个基础能力并没有办法立刻帮我们带来，我们人所拥有的更发散的。不管是思考的能力，还是能快速找到一些正确方向的能力。所以本身他有了这个基础能力作为平台之后，他自然要往下一个方式去走，才能再创造下一个节约式的一个提升。所以其实在去年9月份的时候，open I本身也在讲新的skinning law是要建立在推理时间的探索上。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:18",
      "text": "这件事情其实仍然会有一些技术上的因素，实际上今天可能还没有完全解决。比如说像不管是欧文还是r one，它本身都是建立在像数学或者coding这样的一些可以快速的获得大量的可靠的reward的场景上。它才能够利用这些场景去建立强化学习的这套学习机制，来帮助模型自我进行调整迭代。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:43",
      "text": "当然因为确实语言本身是一个泛化能力非常强的系统。所以当语言本身通过coding或者数学这样的一些方式去激发了他本身思考的基础能力的话，这个基础能力自然而然也会扩散到更多的可能没有经过强化学习调节过的这个领域，让这些领域看起来也可以很好的思考。但是如果我们希望去搭建一个模型，能进一步的去让他不收敛的往上去提升的话，光靠这两个领域去驱动，其实在更多领域的泛化会变得越来越弱，可能未来也会慢慢撞到新的墙。所以在这个过程中，我们其实很难指望说通过一个简单的范式，然后持续投资源，就可以一直不停的提升。反过来，也正是因为资源受限，大家才会寻找新的解决方式，对吧？所以我觉得未来可能也会有类似的一些情况。我相信在未来几年可能还是会有更多的新的范式会出现。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:37",
      "text": "它可能跟原来的范式并不是说非此即彼的一个关系，它可能是承接的一个关系，就像这个后训练也是在一个足够好的基座模型，像V三这样的模型基础上迭代出了R1。那后面可能是R望本身在数学这个领域或者coding这个领域已经走到非常强的一个状态。这个时候我希望他进一步的泛化，可能要引入新的机制过来辅助他，帮助他能够在更发散甚至没有reward的领域，也可以不收敛的往前去提升。那个时候可能又能带来下一次AI的能力的巨大的节约。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:13",
      "text": "正好说到数据，感觉现在比较易得的数据可能已经都被AI训练过了，互联网的数据，还有一些公开生态圈的数据。刚才也讲到现在强化学习这步，其实是用了一些像数学编程这种可以验证，或者说可以部分自我闭环的数据来去训练。那后面数据肯定永远是最大的那未来会变成AI自己生成数据来自己训练自己吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:41",
      "text": "你觉得我觉得他可能不一定是说数据从哪儿来，就像我们刚刚说的，预训练的时候是需要数据的对吧？但是到了r one这种推理的模型的时候，他可能要的并不是数据，他要的其实是这个reward。Reword是一个比较泛的概念，但本质上也是一种监督信号，就告诉你模型该往哪边去走你怎么去调整你才能提高。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:04",
      "text": "其实强化学习的基本原理很简单，就是说大的方法论就是它随机生成一大堆，然后你通过一个外部的信号告诉我，我生成的哪些是好的，哪些是不好的那我就调整自身，让我下一次生成的时候能生成更多好的。只要有这样的信号输入，其实就可以。数据是一个非常强的监督信号，告诉你的是你必须得生成这样才是对的，否则其他的都是不太好的那这个可以进一步弱化对于监督信号的要求。我可能只是告诉你，你生成的这一堆里面这个好一点，那个稍微差一点，其实也算广义的一个数据。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:41",
      "text": "然后我觉得更重要的是语言本身它有思考的能力。我觉得这个可能不一定能完全套到强化学习的这个框子里面。因为大家可能认为这个里面最重要的是强化学习。当然这个是我个人的一些观点，我其实认为这里面最重要的还是自然语言本身。因为强化学习在过去可以在很多的任务上去照着刚刚讲的这个，我尽可能往做的对的reward的多的方向多努力这样的一个方式去转变。但是语言本身才是提供思考能力的一个底层基座。我们其实可以看到，思考本身是一个可以自我去验证，自我去迭代的过程。也就是大家可能经常想的自我博弈。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:20",
      "text": "左右互搏这个事情可能是在阿尔法狗的时候得到了比较大的出圈。但是实际上从概念的角度跟今天语言模型自己去判断自己对不对，这个事情是完全两个概念。因为它是相当于我两个人一起去下棋相互对抗对吧？但是今天这个可能是一个模型要生成另外一个模型，可能要去校验他说的是不是对的。虽然看起来好像都是2个AI在相互的提高，但是实际上左右互搏其实并不是一个在不管是强化学习的概念空间里面，还是在大模型的概念空间里面被充分定义，而且可以落入到大家已有的工具箱里面的一些方法论。所以我觉得这里面是有探索。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:00",
      "text": "中间的。但这个探索，它可能不是基于强化学习的那套方法论去探索。因为强化学习会告诉你，你其实最终还是要有一个reward作为前途信号的。这个东西就变成了我能不能在开放领域获得无穷无尽的reward的这样的一个监督信号。但是自然语言，我们想一个很简单的道理，我们实际上可以自己就闷头去思考问题。我思考一下午，虽然我可能没有对话，但是我脑海里自己做逻辑演绎，然后找到了一些思路，或者把我原来认为是对的，或者原来认为是错的一些东西想的更清楚了，然后得到了更深刻的结论。这件事情它可能是语言本身带来的一个能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:38",
      "text": "所以我觉得这里面其实还有更大的空间可以去探索，而不是完全靠今天强化学习走通了，我就给他去不断的找更多的reward，让他在更多的领域去变得更强。当然这两件事情不冲突的，就是我觉得实际上如果能找到更多的reward，也可以让他今天的能力扩散的更强对吧？因为其实扩散的更多之后，本身也能反向激发出模型更深层次的能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:04",
      "text": "就像ChatGPT之所以能做成，其实在17年到22年之间，大家也做了很多的探索。但是当时其实真正的突破点是在于把代码跟自然语言放到一个模型里面去训。之前有专门信用代码的模型，有专门训自然语言的模型，但是效果都不是特别好。都放到一起之后其实就训的更好了。如果今天大家能找到更多的领域能做强化学习，可能也能因为不同领域之间这个数据特征的差异，把模型的不同方面的能力给激发出来，然后产生更强的能力跳跃。但是也可以去找我们刚刚说的，可能你要去找一些利用语言本身的能力，再去创造新的scaling load这种方式。实际上这些是相互不。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:50",
      "text": "冲突的对，是的，毕竟像阿尔法狗时期这个评价是比较非黑即白，这个数和影是比较客观。现在在原模型领域，当然有一些是能够评价像数学，像编程，他有确定答案，但更多的确实还是这种他也没有确定答案，甚至你很难评价谁好谁坏，有时候甚至只是偏好的不同罢了。确实看起来下一个阶段的数据也好，评价方式也好，可能是一个新的需求。至少看起来之前大家都是追求谁的数据多，谁的算力多久领先dept k现在证明至少在有限的算力下，我们依然能做出来非常好的结果。刚才我们也讲到了，数据只是一方面的原因，像如何评价AI模型的质量变成了一个难题。就从模型的发展上来看你觉得还会有别的什么瓶颈吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:52",
      "text": "我觉得模型的发展上另外一个瓶颈还是来自于硬件资源。因为所有的这个技术路径最终都要落地到商业的基础设施。就像这个scaling law的支撑，其实是需要万卡集群，包括更强的机器在背后去支撑的那这个里面其实也会受到经济模型的影响。这件事情如果能把成本降到10分之1，我能商业闭环，但是我愿意花十倍的资源去博下一个未来。但是他的经济模型实际上还是有个上限的那超过这个上限之后，其实大家就会觉得这个投资可能会比较难以收回成本。所以本身我觉得AI的发展肯定也跟资源投入，跟经济模型会高度相关。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:34",
      "text": "所以我觉得其实dipstick k也是一个很好的契机。因为本身开源模型，包括让技术平权这件事情，可以让他在商业上能，这个商业不一定是说deep sick的商业，而是整个社会对于AI这个事情的商业可以闭环起来。让更多的人开始用AI在AI上可以投入的资源，包括这个产生的经济循环会越来越多，实际上也会为未来AI本身的发展可以注入更多的经济动力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:02",
      "text": "假如简单畅想下未来，以后模型可能它通过很深度的思考之后能够给你一个答案。那大家第一个面临的问题就是我们是不愿意等着模型想个三分钟五分钟的。我们可能还是希望说，尽管你要想很多，但能够尽快的给我一个答案。特别是春节看到很多人教你用deep sik说要加上一句，不要过程，只要答案。特别是想让deep sk帮忙做题的这些同学。话说回来，就看到这个DPC开源之后，大家可以很容易的在自己这里部署，甚至是说复制出来这个高成本的模型。包括deep c的火热，让大家感觉好像之前大模型公司的高昂的投入，好像很快被追上。你觉得在开源或者说在现在这个生态下，AI模型或者说AI公司的护城河在什么地方？",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:58",
      "text": "我觉得任何一个新的技术发展，它可能并不是说简单通过技术就可以成为护城河。我觉得护城河最终还是建立在一些商业的逻辑上。当然就很多商业逻辑可能希望把这个护城河建立在，比如说我有1万张卡，或者我有很多的数据，对吧？靠资源建立的护城河。但资源的护城河是容易被技术打破的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:20",
      "text": "其实最终真正能形成护城河的往往是一些商业模式或者一些生态。如果单纯的以模型的质量或者以GPU的数量，或者数据的数量，规模，这些东西可能都会逐渐被打破。像deep sk对NV最大的冲击就是把过去这两年很多的云厂商或者非常巨头的这些公司，希望围绕I的算法，围绕GNV的GPU，形成一个将来以GPU资源，包括这个万卡集群为门槛，来人为创造一个技术的门槛。其实都在这条路上狂奔，只不过说这件事情被打破了。所以我觉得更多的还是把护城河应该放在在商业，包括商业模式上面。",
      "speaker": "发言人3"
    },
    {
      "time": "00:37:02",
      "text": "我觉得一个很直接的问题在于，AI本身确实大家对他的期望很高，但是它现在还没有进入到经济系统当中，发挥出巨大的商业价值。在这个过程中去构建这些门槛，这些本质上都是对这个行业的拔苗助长。相反就像DPCK这样去先让这个行业能发展起来，商业模式自然而然会逐渐形成。因为只要你有经济循环，自然就会有商业结构，有商业结构自然就会有商业模式以及相应的一些新的护城河。相反就是在技术还没有真正大规模精细化之前，我觉得这些所谓的门槛可能不堪一击。",
      "speaker": "发言人3"
    },
    {
      "time": "00:37:41",
      "text": "你去年来咱们这儿聊英伟达的时候，提到说支撑英伟达股价一个是大模型产业发展，另外一个就是英伟达在产业中的垄断地位。这段时间也看到外媒有报道，甚至有人叫嚣说要完全封禁显卡对中国或者几个少数发达国家的使用，我觉得这个是明显反映出他们有点着急了，他是面临挑战的，第一反应就是更加的固步自封吧。你觉得deep sik是破局者呢，还是说这是产业发展的一个必然的方向？",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:17",
      "text": "我觉得布局这件事情，尤其对于这样一个庞大的体系跟生态来讲，deep stick当然是一个非常重要的。而且由于它本身发酵跟出圈的程度，对这个事情有非常大的一个促进作用。不过真正你要去嚼这个护城河，我觉得这可能只是一个起点。因为继续往后需要有更多类似的创新。这个创新不光是模型层面，包括这个inflight层面去改变经济结构。其实也包括更多大家围绕AI普惠这件事情去搭建起来的从上到下的一整套的体系。就像我刚刚说的，过去两年OpenAI也好，微软也好，很多这样的公司，大家形成了一个利益共同体。都希望把这个东西建立起未来整个商业社会的一个格局。就是有资源的跟大厂可以去将来让所有人都用他们的基础设施来服务，用他们的模型dept是撬动了这个体系的第一步。我觉得其实后面更重要的是AI普惠的产业结构跟通过一些硬件或者数据，或者各种各样的资源来形成垄断体系的小圈子之间的一个博弈。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:30",
      "text": "狄浦斯克我觉得肯定是开的第一枪。这个卡的目标肯定不光需要像模型，包括英特尔层面做。芯片自然也是非常重要的参与角色，这也是我们公司一直以来都希望参与进去的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:44",
      "text": "最近大家都在发布说产品介入deep seek，然后国产芯片兼容deep seek的模型，包括有人在讨论说deep sk能够绕开酷大生态，这个不知道你怎么评价，酷大生态在现在这个阶段它是一个什么样的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:00",
      "text": "我觉得绕过扩大生态，包括刚刚讲的就是这种破局的行为，肯定不是简单的说我有国产芯片或者我有国产模型。就是美国有OpenAI我有国产模型，美国有英伟达我有国产芯片。如果是这种简单的逻辑，这不是今天deep sig真正出圈的原因。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:16",
      "text": "D PK并不是说因为它是一个国产的模型所以出圈了。实际上它是找了一个新的路径让大家看到的。实际上可以比较温，或者大家过去坚持的skin look可能更好的路径，包括非常极致的MOE，这可能是没有人探索过的路径。然后让大家感觉，确实像这种非常极致的MOE，它本身在软硬件综合的取舍上还能取得更好的经济的效应，就成本更低，不管是推理还是训练。所以我觉得对硬件行业一样的，就是如果硬件行业大家今天想的只是简单的说，media可以跑dept yi e我们的芯片也可以跑dept sic我觉得这个其实是很难真正意义上冲击的对吧？它并不是一个deep事件，它还是过去两年很多国产模型去追随美国的路径的一个逻辑。所以我觉得像硬件层面，如果国产的这些芯片想要去推动，我们的思路是希望塑造一个比今天美国这边或者现在主流的围绕NV的这个体系更有吸引力，更有竞争力的一个体系。这是我觉得真正的破局之路。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:19",
      "text": "在去年大概十月份的时候，我也对外讲过一些我们的理念。我们是觉得今天这个scanning law跟千卡万卡集群，本质上在推动一个大型计划的计算机体系。包括在锋锐的年会上我也讲过，如果将来围绕deep sig包括围绕国产的芯片，围绕AI普惠的这个目标，我们去创造一个就像以前的这种叉八六集群，叉八六个人电脑这样的普惠的逻辑。其实可以更大程度的让大型机这样体系变得越来越失去价值。我们其实是站在这样一个视角，今天NV的这套体系，包括跟原来urban a2 skin law这套体系，本质上是通过算法来塑造机器要做的越来越强，越来越像以前上个世纪80年代那种大型机。几百万上千万的机器才能跑一个今天最好的模型，来塑造一个非常大的门槛。如果未来大家发现可以花个几千块钱几万块钱的芯片，就可以让今天大家都能用得上这个deep sig然后包括将来用这种几万块钱的芯片组一个集群，其实总的服务能力可能比那一台非常昂贵的高价值的机器还要强。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:30",
      "text": "其实这个在历史上本身就发生过，就是整个PC革命，包括互联网革命都是建立在叉八六这套体系上。甚至很多人可能都不知道IBM在80年代以前是一个什么样的行业地位。但是这样的一个所谓蓝色巨人，就是被这样一个看着很不起眼的，看起来很弱的、很低端的叉86芯片给颠覆掉了。但是它本身编织了一套更好的计算机底座的体系，更经济性的计算机底座体系。所以这个我觉得也是在芯片层面我们想去推动的一个方向。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:03",
      "text": "这次我观察到一个现象，就是第一次大规模的出现了，有人开始本地化部署这个模型。但你之前提到过这个计算机行业惯性是非常大的，就不说别的，至少从芯片上我们看到需求变化到芯片做出来，可能就两三年过去了。你觉得这次的影响让计算机行业也好，或者说芯片行业也好，大家开始重视需求的变化，或者说开始考虑飞英伟达的路径了吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:35",
      "text": "我觉得这里面其实给了很多人一个机会。因为过去的国产芯片很多是很难找到很好的下游商业场景的。然后现在dip sick这样一个开源模型本身又是相对比较标准化的。就是不管你用什么样的芯片，只要你能把它很好的跑起来，都可以接入API去作为服务。这个其实给了很多国产芯片一个出口。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:58",
      "text": "这件事情不是说所有的国产芯片都在这一部分都会成功，经过一段时间的发酵之后，肯定还是会回归到谁的这个方案最好，包括更符合经济逻辑。因为时间也比较短，大家基本上就是要么是几百万的满血模型，然后要么是跑一个低精度的蒸馏的模型，其实也形成了这样的一个特点。但是我们其实希望的是说把因为硬件资源包括价位的gap给打破。我们实际上还是希望延续这样的路径。但是把DPC的满血模型变成一个标配，变成大家都用得起的一个标配。当这件事情肯定有很大的难度，但是芯片本身自身做出很多的改变，实际上是可以逐渐去推进这件事情的成型的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:41",
      "text": "你觉得deep sit的爆破对星云有什么影响或者启发吗？然后我们对此有没有一些规划和想法？",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:53",
      "text": "我们从去年9月份开始关注计划部署这个场景，也是因为我们成为了AI编程的一批自称用户。当然确实从那个时候我们跟很多人讲私有化部署，大家会对这个市场抱有比较大的怀疑。因为大家觉得需求到底在哪儿？这个市场可能今天是零，今天我觉得这件事情可能已经成为一个共识。大家都知道，至少私有化部署和云端都是一样重要的这对我们来讲比较积极的因素。当然我们也需要更快的去拥抱，因为这个行业发生了这样的一个认知上的巨大变化。在未来一段时间，哪怕在我们的芯片产品还没有出来之前，我们也希望给大家提供一些可能跟现有的这些截然不一样的可能性。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:37",
      "text": "就我们刚刚讲的，我们希望用大家可能都花得起的一个钱，而不是那种上百万，可能跟大家没什么关系的这个价位，就给大家提供能跑这种满血，而且不经过量化压缩的。因为其实量化压缩可能今天就是大家已经形成了一个惯性的认知。觉得满血的模型是要么接云，要么去那些大企业花个几百万去买。个人就用一用这些蒸馏的模型也凑合能用了。对，但我觉得其实没有必要凑合。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:06",
      "text": "作为一个创业者，你是怎么看待梁文峰说的这个技术优势是短暂的，真正的护城河是文化和组织。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:14",
      "text": "我是高度认同这一点。梁洛安本身躬身入局，为我们做了一个很好的榜样。因为其实技术的优势，你像open I其实刚出来的时候，大家其实所有的人的技术都是追不上他的技术。这一点会造成优势。但是这个优势有可能是可持续的，因为全世界有这么多优秀的人，大家一定是可以把这件事情给做出来，去浮现出来。你很难去通过技术挡住别人。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:39",
      "text": "全世界优秀的人才有很多，怎么把人才用起来是一个非常难的事情，尤其涉及到这种跨领域的协同。像deep sik之所以能成功，它是在infrared算法，包括在模型各方面都产生了联合的创新，而不是说单点上去做了一个创新。所以这种联合的创新本身对组织能力的要求是非常高的。像deep本身它的这些核心成员很多都是国内高校的一些研究生，或者刚毕业的博士生。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:13",
      "text": "我之前也跟我一个师弟就在DPCK我的师弟聊过。他跟我讲他们老板对于他写的这个库大蒜子里面的每一个县城到底在干什么事情，这些事情都是了如指掌的。说实话其实今天可能很多做info的人都不一定对deep sk他做的这个info优化到底是怎么回事有比较深入的了解。Tip他们组织能把这件事情做好，我觉得这个也有很大的因素。因为创新不是简单的说我把一堆不同领域最聪明的人聚在一起，他们就可以迸发出价值。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:44",
      "text": "因为每个人可能在自己专业领域有很强的能力，然后大家也有很强的思考能力。但实际上还是需要组织一个全局的大的方向。这个大的方向我可以包容你去试错，但是如果单纯的靠试错，就大家脑洞一个方向，然后去试一试，然后错了我再重新来，这个效率其实是很低的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:05",
      "text": "就是创新本身也是需要效率的。这个效率的保障其实就是你要有第一性原理的思考。但这个第一性原理思考光靠每个人各自为政其实也是很难的。所以组织起来本质上就是要给大家一个通盘看起来make sense的一套方向。然后大家在各个维度沿着这个方向去齐头并进的努力。但是你要组织这样一个通盘的思路，本身就需要你能深入到细节里面，你知道每一层到底要干一些什么事情，才能把这个事情有效的组织起来，去打破每一层的边界条件去看。所以我觉得这个是所谓文化跟组织的一个护城河。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:42",
      "text": "这件事情我觉得其实是非常难的。杨老板对我来讲也是一个非常大的激励。因为其实国内很长一段时间，大家组织不管是投资也好，还是创业也好，大家都很相信这个经验主义。虽然很多人都不会认为自己相信经验主义，但实际上做的事情，包括想的东西都是一样的。就大家会相信行业专家，相信大牛，相信过去在这个行业里面取得过巨大成功的一些人，相信这些标签，相信把这些人攒到一起之后可以做。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:12",
      "text": "当然这个方法不是说它有问题，实际上中国过去这四十多年的经济腾飞，本身就是靠这样的一种方式来发展起来的。确实大家会有一个巨大的认知惯性。因为他解决了一个很好的问题，就是怎么高效的去做事情。有经验的人知道能耗做事情一定是高效的，所以这个事情的成功率确实是高的。反经验主义并不是单纯的我把这些东西抛弃掉就行，我摧毁一个东西很容易，但是我要重新搭建一个重新让整个组织能高效的去做事情的方法也很重要。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:42",
      "text": "我相信大家是真正意义上去在拥抱创新的。其实国内不缺创新，对吧？大家有很多非transformer架构的模型的，有很多非GPU路线的，所以冯诺依曼路线的芯片，这些其实确实都是很激进的创新。但这些创新本身能不能成功，实际上赌性很大。因为它其实大方向是缺乏这种通盘的思考，所以这样可能也会比较低效。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:08",
      "text": "就是他可能做了，然后失败了，总结经验再去做下一个，就不断的去重复。其实创新本身是需要很强的一套方法论。除了抛掉以前的，除了反经验主义之外，还要去build up一个新的组织方式。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:24",
      "text": "我其实也非常赞同梁老板的这个观点。从投资人的视角来看，功利的说就是我是觉得一个初创企业，它的需要关注的点就是它的资金利用效率。因为同样的钱如果它有价值，那自然会有更成熟的企业来做。那从这个点衍生出去，本质上就还是人才密度和团队的组织。大家怎么能够找到最优秀的人，然后把大家给搭配起来。其实我觉得跟大模型是一样的，每个人可能就是一个MOE的专家。那我们怎么把一个公司，把每个专家能够组织起来，形成除了规模大还要有高能力的公司的这么一个大模型。我们看到中国过去接近20年、30年的发展，其实从最开始的叫中国制造到中国创新。你觉得DPC的出圈，是中国企业的创新在全球科技竞赛中开始发生转变的一个标志性的事件。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:30",
      "text": "我觉得这个就是真正意义上的转变。其实不是靠一个dipstick这样的事件出现的，一定是出现了大量类似的这种情况，我们才能真正意义上说这件事情发生了转变。万事开头难，有这样的第一个例子，后面会有更多这样的例子。我相信这样的例子本身也会激励更多的希望促成这样转变的人，就包括梁老板自己。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:53",
      "text": "在一些公开的访谈里面也讲到，这是一个认知周期的一个问题。就是中国企业在过去这么长时间内，通过经验主义来获得了巨大的成功。其实包括你刚刚讲的这个MOE说专家把很多专家组织起来，这也是一个很典型的经验主义的体现。实际上你看梁老板不光是说要把人才组织起来，什么是人才定义？可能跟大家也会有很大的不一样。不是那种大家普遍以上认为大厂原来干过一个很强的事情的人，他可能找的都是一些在校的学生，而且是国内的。实际上这个本身就是梁老板自己认知上的一个对人才的定义，可能也会不太一样。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:31",
      "text": "但是我觉得更重要的是说，他讲到这种转变，就需要成功案例来激励整个社会。如果大家都没有看到这个成功案例，那这件事情到底是不是对的？无论是从投资的角度，从创业者的角度，从参与到工作当中的人的角度，大家其实都会对这件事情有所怀疑。这个其实形成了一个巨大的认知惯性。要扭转这个惯性，确实需要更多的这种成功案例来激发大家。他自己躬身入局成为了第一个案例，我觉得是扭转的一个起点吧。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:04",
      "text": "正好也是2025年，这个可能是一个非常有代表性和标志性的事件。我简单总结了一下，最近大约30年。从2000年到2010年这十年左右，大概是主要就是讲中国制造，我们可以以更廉价的成本生产出大量的商品。这些商品它不一定是高质量的，最典型就是像衣服，鞋子这些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:30",
      "text": "再往后十年，2010年到2020年，这个时候中国叫物美价廉。这个典型代表就是小米这类公司。我们可以可能20%的价钱做出来，可能达到跟国外80%性能或者能力的产品。这个当然是伴随着中国企业的生产能力和设计能力的增加，当然也包括了很多专家，有经验的人在企业中到中流底柱。可能最近五年是我们看到叫中国变成了一个me Better，我们可能已经在某些行业里面做到了远超海外的能力，同时还保持相对低的价钱。这波的人也是一样的，包括我们投资更追求的是大家有更深度的思考，对产业有更好的认知，能够从底层上去拥抱变化。在AI肯定要投这个AI native的创始人了。竞争上看，中国科技的在全球的地位也是保持一贯的，这个高增速还在继续增加。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:32",
      "text": "从咱俩二三年底聊的时候，就已经讨论过刺客106，然后也讨论过长上下论文。我们可以畅想一下，比如说在三年之后，这个AI的推理成本得到了大幅的降低，这个速度上也有了很大的提高。你觉得会出现什么样的有趣的应用，或者说它会怎么样的发展呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:55",
      "text": "我们本身也是参与者，我们肯定也希望去推动甚至超过大家预期的一些事情发生。首先第一步肯定是希望所有人都能用得起满血的模型，就是这种低精度压缩。这些事情可以抛到后面。当大家发现这个东西是很便宜价格的时候，就像今天大家用电脑一样。你不会在乎浏览器可能吃掉了你一个G的内存。就是因为你的内存可能已经足够大了，而且也足够便宜。你没有什么感知，不会说因为那个浏览器能帮我省很多的内存，我就一定要装那么一个东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:29",
      "text": "然后另外一个，当这件事情大规模普及之后，其实对几乎所有的行业都可以渗透下去。因为当所有人都用得起的时候，每个行业才有机会付出很低的成本去使用你甚至不付出成本。为什么？我们之前一直想就这个行业有很大的垄断性，包括很大的惯性在于今天比如说像巨神这样的新的机会起来，这样的一个新的技术领域，它并不需要从头去搭建所有的基础设施。它可以直接原来在手机、在平板、在LT设备，包括在PC上的一些硬件基础设施、软件基础设施直接平移过来。然后直接复用这上面的生态去打磨自己的一些东西。所以我觉得其实AI这个事情也是一样的。他可能会从一些看起来比较高价值的，愿意为这件事情付费的一些行业，就像我们去年开始关注的AI编程这些行业先入手。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:23",
      "text": "我们先把AI编程变成除了像我们这种体验版的用户之外，可能变成更多的大家真正意义上生产力工具。大家可以真正意义上从值不值得花钱，甚至大家不用考虑我值不值得花，就因为这个东西太便宜了，成本可以基本上忽略不计的。我就可以私有化的拥有这样的一些东西，然后让大家大规模用起来，去搭建一个基础的平台。后面越来越多的行业，就是哪怕非计算机行业，非互联网行业。更多的行业，大家可能就跟今天去采购一些电脑，开始自己的工作流一样的这种方式去搭建起来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:56",
      "text": "然后另外一边，这个事情不一定终局全是私有，就是云一样，是有巨大的机会的。因为整个互联网其实拼的就是体验，靠体验来获得流量，靠流量获得相应的商业回报。再靠商业回报反过来去把体验打磨得更好。那其实这件事情也一样会发生，就像今天deep seek的流量一样。然后就天天服务器繁忙。本质上他们的服务器的投资成本其实也不低，花了非常大的资金去建设。那如果在这么破天的流量下，这个服务器得扩很多倍才能实现，可能这个商业回报也会变低。但是我觉得只要我们逐渐的去把基础设施的开放性，包括成本做的越来越低，然后让大家可以很好的去搭建，可能就像以前google攒一堆的叉861样，去传搜索引擎的基础设施，你才能让搜索引擎给全世界的人用。那一样的就是如果将来类似于deep sik这样的一些基础设施，也可以用这种非常便宜的机器攒起来，攒一个非常大规模的机器，然后可能也没花多少钱，你这个时候才有可能去服务成千上万的应用。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:03",
      "text": "简单来讲就是我们希望不要以硬件资源来划分这个商业结构，而是以哪种商业结构最适合。就像我们一直认为生产力工具可能就应该私有化部署，这个是最符合生产就是经济关系的那像消费娱乐类的，可能它就适合互联网。无论是哪边都不受限于底层硬件的成本，包括大家能跑的模型的质量。我们就是用最好的硬件，最好的模型，然后去创造下游的这些，不管是互联网还是私有化部署，或者甚至个人电脑所谓的AIPC里面的这些应用场景。这个是我们希望去推动，而且我们相信其实可以在非常短的时间内实现的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:47",
      "text": "我其实最近也是思考了挺多，短期我觉得其实open I还是比较有叫指路效应。比如说他最近上这个deep research，这个可能就会变成一个非常普及的现象。就是所谓的个人助手，你可能丢给他一个任务，他就能在或长或短的时间内帮你完成。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:08",
      "text": "不管是深度的研究还是一些日常中的任务，对于我们体验应用上，我觉得会有两个变化。一个是也是你刚才说了，首先肯定还是体验优先。那我们能可能能看到更多的设备也好，终端产品也好，现在可能连屏幕都不需要，它只要有个喇叭，有个扬声器，那它因为后面接入了云上面大模型，它已经能够实现非常强的功能。另外一点就是在我们已经有的一定硬件基础上，整个硬件形态可能会变得更加的智能，反过来讲更加傻瓜化。像我们这代人还是打字打得很溜的那这个00后可能全都是触摸操控了。确实可能10后的时代就是纯语音，甚至可能还会有些更新的操作形式。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:59",
      "text": "AI的门槛降低了之后，是对于人的能力的一个极大的扩展，我们不需要记那么多东西，甚至可能连很大一部分简单思考的工作都可以让AI来做了。让未来可能能保留更多的更有创造力和更复杂的思考。但是今天其实没有看到大家比较好的利用起来大模型的能力，可能还是要等一下，特别是这个基础设施的一些变化。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:31",
      "text": "因为现在看到一些比较惊艳的应用，它背后还是需要调用大量，然后很多都是限制了使用。其实没有无限制的去放，大部分也都是在调OpenAI的o one的模型。我觉得这个放开之后，确实是可以更奢侈的去用这些能力了。另外一个就是上下文还是不够长，这里边还是有比较大空间。我感觉芯片现在看可能还有一个小的机会，但是这个不是很确定，就是在laptop这个level，他会不会有本地的需求。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:10",
      "text": "对，会的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:12",
      "text": "因为现在明确大家已经覆盖的是端侧推理，就用那个堆叠。它可以比如说什么8B模型跑个200 token每秒。对那服务器还有这个私有化部署，你们其实也有规划了。然后最大的训练其实也有了，大家也都在follow英伟达去做最大的有在做了。我觉得盘下来可能就中间这块好像还没有满足需求。对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:43",
      "text": "其实laptop反而觉得有挺大机会的。核心其实不在于技术本身，其实还是在生态你怎么切的问题，就像端侧，如果是手机，说实话这个市场如果你不是做手机SOC的，很难切进去。对然后laptop我觉得大家是有机会的，包括那种迷你主机。但这个取决于下游商业的变迁，迷你主机什么时候变成主流？如果是一个laptop，其实就有一个问题，就是laptop你首先得是一个正常的桌面操作系统的机器。你不可能说我自己做了个芯片，然后上面跑linux然后去卖laptop，你也得跑windows。或者像苹果跑macos我甚至觉得像迷你主机都有可能会面临这个问题。然后还有一个就是hold lab，你可以比如说就是买个迷你主机，然后我电脑还是用正常的那他就给我提供大模型的能力。但这个市场今天的需求可能还没有真正意义上激活起来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:35",
      "text": "然后今天非常感谢基于跟我们一起讨论deep seek的影响和AI未来可能的发展。我们看到这个春节期间，deep sik是属于天时地利人和，有了非常大的热度。当然它也是中国科技生态和科技产业的一个代表了公司了。它的后续影响我想肯定不只是这一段时间的热度。对于应用也好，对于生态也好，对于行业的认知，包括基础设施的需求都会产生比较大的变化。我们也相信未来中国科技和中国AI和中国芯片会有更好的发展。谢谢大家，再见再见。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "在近期的讨论中，多位科技行业专家共同探讨了Deep Seek在中国及全球科技界引发的广泛关注及其深远影响。春节期间，Deep Seek成为科技话题的焦点，不仅在中国市场引起重估与希望，在美国科技行业也产生了显著影响。专家们深入分析了Deep Seek技术背后的科学、工程创新及其对芯片行业和大模型底层硬件需求的潜在影响。对话中还涵盖了AI行业未来发展趋势，包括AI模型的开源趋势、AI硬件创新以及AI如何提升生产力。此外，讨论扩展至AI在教育、娱乐及日常生活中的应用，强调了降低AI使用门槛，促进更多人掌握AI技术的重要性。整个对话展现了参与者对于AI技术进步和未来发展充满深刻见解与积极期待。",
    "qa_pairs": [
      {
        "question": "在春节期间，关于Deep Squeeze在中国和世界的出圈现象，大家主要有哪些讨论点？",
        "answer": "大家主要讨论了Deep Squeeze对美国科技行业姐妹花估值的影响，以及它如何带动中国科技的重估和希望，从而影响了中国资本市场的走势。",
        "time": "00:00:03"
      },
      {
        "question": "技术层面上，大家关心的是什么？",
        "answer": "大家关心的是Deep Squeeze在哪些方面比其他模型优秀？它做了哪些不同的事情？以及它究竟是科学创新、工程创新还是技术创新？为什么能成功完成其他大模型公司未能实现的事情。",
        "time": "00:00:33"
      },
      {
        "question": "对于芯片行业的影响，具体是怎样的情况？",
        "answer": "Deep Squeeze的出现可能导致算力需求显著下降或增加，它带来的模型变化可能会给英伟达类似的芯片公司带来机会，也可能让更靠近英伟达相关需求的芯片公司受益。同时，中国在出现Deep Squeeze后，对于大模型底层硬件需求的变化，也会对中国不同的芯片企业产生特别的影响。",
        "time": "00:00:51"
      },
      {
        "question": "在你们公司内部，为什么最终选择了Deep Squeeze 2.5模型？",
        "answer": "尽管多种模型表现优秀，但经过测试发现Deep Squeeze 2.5模型在效率上比云端API还要高，且在高强度逻辑性场景中表现出更好的能力，因此我们选择了该模型进行私有化部署。",
        "time": "00:04:41"
      },
      {
        "question": "季宇，能否分享一下你们公司（星云科技）使用Deep Squeeze的经历和感受？",
        "answer": "我们从大约去年8、9月份开始关注私有化部署并尝试使用Deep Squeeze模型。当时由于AI编程火热，云端服务存在订阅费高和信息安全问题，而Deep Squeeze v2和2.5模型在市场上反馈不错，我们在内部尝试后发现效果非常好，特别是在AI编程场景下达到了高度可用状态。",
        "time": "00:03:54"
      },
      {
        "question": "对于Deep Squeeze在大众视野中的火爆程度，你们怎么看？",
        "answer": "我们认为Deep Squeeze的火爆出圈在意料之中，因其工程能力和基座模型能力强大，特别是强化学习和思考能力突破性进展，加上开源免费使用，促成了其火爆程度超出预期。此外，春节期间家庭聚会等环境也有助于让更多人了解并接触到Deep Squeeze。",
        "time": "00:08:35"
      },
      {
        "question": "在使用模型时，为什么有时直接prompt模型会导致用户使用困难？",
        "answer": "因为如果模型需要很好的prompt才能有效使用，那么当用户以简单直接的方式提问时，模型可能无法给出理想答案，这时用户需要理解并调整提问方式，这增加了使用难度。另外，过度prompt可能会影响模型的表现，让模型自行理解输入内容反而可能得到更好的结果。",
        "time": "00:10:42"
      },
      {
        "question": "Deep Six开源模型与国内外其他模型相比，在开源和思考方面有何区别？Deep Six选择做开源创新的原因是什么？",
        "answer": "Deep Six等开源模型在参数层面是开放的，而训练架构或更上游的部分通常仍以私有化为主。目前流行的一些开源模型如Deep Six、拉玛、阿里千问系列等，会提供不同规模的模型供用户根据设备需求选择。这些开源模型中，只有Deep Six具备高质量且带有reasoning能力的大规模模型。Deep Six之所以做开源创新，是因为在国内芯片禁令的背景下，国内创业公司无法获取H100等大型机器，从而出现了小规模dance模型和超大规模MOE模型的选择困境。在此情况下，Deep Six针对性地优化M1架构，从而获得了巨大的竞争优势。",
        "time": "00:13:13"
      },
      {
        "question": "为什么说开源模型中，具备深度推理能力的较少？",
        "answer": "具备深度推理能力的开源模型较少是因为深度推理能力很大程度上依赖于模型本身的高质量，较小规模的模型可能无法处理好上下文理解，因此深度推理能力较难体现。经过实际使用和筛选后发现，只有Deep Six等少数模型能达到这一要求。",
        "time": "00:12:21"
      },
      {
        "question": "Deep Six为何能在保持模型质量的同时降低推理成本？",
        "answer": "主要原因有两个方面。首先，其采用的MOE架构使得参数量虽大但实际参与生成每个token的参数量较少，降低了内存和显存需求。其次，Deep Six在训练和推理上进行了算法创新，转向了MOE expert维度进行分布式计算，并优化了整个推理框架，进一步降低了推理成本。",
        "time": "00:16:53"
      },
      {
        "question": "Deep Six为何能掀起较大影响力？",
        "answer": "主要原因有三：一是开源免费，降低了大众接触AI的门槛；二是春节特殊时间点的关注度提升；三是其中国特色高性价比高质量的模型特性，以及输出更长结果的能力，使其在业界和用户中产生了较大影响。",
        "time": "00:18:15"
      },
      {
        "question": "为什么是由一家中国公司来承担这个项目，而不是北美公司？",
        "answer": "这是因为禁令带来的环境变化倒逼出了由一家中国公司来执行该项目的可能性。",
        "time": "00:22:02"
      },
      {
        "question": "在海外算力资源不受限的情况下，AI的发展或训练是否受到阻碍？",
        "answer": "我认为是遇到了一些阻碍。过去两年，排除中美竞争因素后，AI发展的主流叙事是围绕OpenAI的GPT系列模型进行的迭代升级。然而，从算法技术角度看，GPT3及其之后的模型可能达到技术路径的临界点，单纯依赖原有范式难以持续获得显著提升，需要寻找新的范式来维持进步。",
        "time": "00:23:42"
      },
      {
        "question": "长输出带来的模能力提升是否会成为未来AI发展的关键突破点？",
        "answer": "我早就有这个看法。随着预训练范式的推进，语言模型的基础能力逐渐增强，但要实现更发散和高效的应用，必须探索新的方式。例如OpenAI通过增加上下文长度和生成多个回答进行投票的方式，可能成为未来提升性能的一个重要方向。",
        "time": "00:24:22"
      },
      {
        "question": "是否可以通过强化学习以外的方法来增强AI能力，比如利用自然语言本身的思考能力？",
        "answer": "确实如此。虽然强化学习在过去在许多任务上取得成功，但语言本身具备的思考能力是底层基座，它提供了一种自我验证和迭代的过程，这种能力可能超越现有的强化学习框架。因此，在探索提升AI能力时，除了强化学习，还可以关注自然语言带来的思考能力及其在开放领域中的应用和潜力。",
        "time": "00:29:41"
      },
      {
        "question": "数据方面，AI是否会转向自己生成数据来训练自己？",
        "answer": "数据来源并不一定局限于已训练过的互联网或公开数据。在预训练阶段需要数据，而在推理模型如R1阶段，重点转向了reward，即通过外部信号指导模型调整。未来AI可能不再受限于特定领域的数据，而是通过更泛化的监督信号进行自我迭代和学习。",
        "time": "00:28:41"
      },
      {
        "question": "在AI模型的发展中，除了数据和算力之外，目前存在哪些瓶颈？",
        "answer": "我认为AI模型发展的另一个瓶颈是硬件资源，尤其是像万卡集群这样的基础设施。AI技术路径最终需要依托于商业基础设施落地，而这些资源投入与经济模型密切相关。当成本降低到一定程度时，商业闭环可以实现，但超过一定上限后，投资回报可能难以回收，这限制了AI发展的经济动力。",
        "time": "00:33:52"
      },
      {
        "question": "对于未来AI模型的发展，用户希望模型能快速给出答案，这是否对现有AI模型或AI公司的护城河产生影响？",
        "answer": "是的，随着技术进步，用户可能更期待AI模型能在短时间内给出答案，而不是深度思考的过程。这确实对当前以资源和数据为核心护城河的AI模型和公司提出了挑战，因为资源壁垒较易被技术打破。真正能形成护城河的往往是商业模式或生态体系，而非单纯依赖模型质量或硬件规模。",
        "time": "00:36:20"
      },
      {
        "question": "开源的DeepSIC是否打破了以往由GPU资源形成的门槛，并对未来AI行业发展产生何种影响？",
        "answer": "DeepSIC确实打破了过去围绕GPU资源构建的技术门槛，它通过开源的方式让更多人可以部署和使用原本高昂投入的模型，加速了AI在社会中的应用和发展。不过，护城河的建立并不只是靠技术，更关键的是商业模式和生态建设。DeepSIC的出现可能只是第一步，后续还需要更多创新来构建可持续发展的商业模式和产业结构。",
        "time": "00:36:20"
      },
      {
        "question": "DeepSIC是否是破局者，能否绕开英伟达的垄断地位？",
        "answer": "DeepSIC在某种程度上是推动行业发展的关键因素，但它并非完全绕过英伟达生态，而是提供了一种新的路径让大家看到不一样的可能性。真正的破局需要在模型层面、硬件层面以及AI普惠的整体体系上进行综合创新，形成比现有主流生态更具吸引力和竞争力的新格局。",
        "time": "00:38:17"
      },
      {
        "question": "国产芯片是否能够通过兼容DeepSIC模型来挑战现有格局？",
        "answer": "国产芯片若仅通过提供兼容DeepSIC模型的产品就想绕过英伟达生态是不够的。DeepSIC之所以受到关注，是因为它展示了不同于传统路径的高效经济取舍，使得软硬件综合成本更低。国产芯片要想真正破局，需要塑造一个比现有主流体系更加优秀且具有竞争力的计算机底座体系。",
        "time": "00:40:16"
      },
      {
        "question": "本地化部署DeepSIC模型的现象是否会让计算机行业或芯片行业开始重视需求变化并考虑类似英伟达的发展路径？",
        "answer": "这次DeepSIC模型的本地化部署给行业带来了一个机会，让国产芯片找到了更多下游商业场景。尽管从需求变化到芯片研发有一定的时间延迟，但这种情况促使行业意识到需求的重要性，并开始考虑如何通过芯片设计更好地满足这些需求，从而可能影响未来芯片行业的发展方向。",
        "time": "00:43:03"
      },
      {
        "question": "这件事情（指国产芯片的发展）不是所有国产芯片都会成功，最终会回归到谁的方案最优、最符合经济逻辑吗？",
        "answer": "是的，经过一段时间的发酵后，市场会倾向于选择方案最优、性价比最高的芯片。目前大部分芯片采用的是满血模型或低精度蒸馏模型，但我们的目标是打破硬件资源和价格差距，将DPC的满血模型变成大家都能用得起的标配。",
        "time": "00:43:58"
      },
      {
        "question": "deep sit的成功对星云有什么影响或启发？星云对此有何规划和想法？",
        "answer": "星云从去年9月开始关注私有化部署场景，并认为私有化部署与云端同样重要，这一认知上的巨大变化对星云积极。即使在芯片产品还未推出前，星云也希望提供与众不同的可能性，如用更经济的方式提供不经过量化压缩、满血的模型运行。",
        "time": "00:44:53"
      },
      {
        "question": "对于梁文峰提出的“技术优势是短暂的，文化和组织才是真正的护城河”，你怎么看待？",
        "answer": "我高度认同梁文峰的观点。虽然技术优势可能短暂，但文化和组织能力是可持续的竞争优势。星云组织内部具有深度理解和管理复杂项目的能力，通过联合创新（如infrared算法和模型各方面创新）展现了高效组织的重要性。",
        "time": "00:46:39"
      },
      {
        "question": "创新过程中如何有效利用人才和构建高效组织方式？",
        "answer": "创新不仅需要人才聚集，更要有全局视野和通盘思路，通过第一性原理思考来保障效率。组织应提供一个能包容试错并有效组织各领域人才的方向，打破层级边界，形成高效协同，这样才能真正发挥文化与组织作为护城河的作用。",
        "time": "00:48:05"
      },
      {
        "question": "中国企业在创新方面的转变标志是什么？",
        "answer": "DPC的成功出圈是中国企业在全球科技竞赛中从经验主义向重视人才密度和团队组织转变的一个标志性事件。梁老板以独特视角寻找和搭配人才，这表明了中国企业在创新道路上开始寻求新的成功案例以激励社会。",
        "time": "00:50:24"
      },
      {
        "question": "在AI技术进步背景下，未来三年可能出现哪些有趣的应用或发展趋势？",
        "answer": "当AI推理成本大幅降低且速度提高后，可以预期AI技术将在更多领域得到广泛应用，比如更深入地融入生活、生产各方面，推动中国科技在全球的地位持续增长。",
        "time": "00:54:32"
      },
      {
        "question": "AI技术普及后，对于用户来说会有怎样的体验变化？",
        "answer": "随着AI技术的普及，用户将能以极低的成本使用原本需要付费才能获得的高级功能。就像现在大家使用电脑时对内存消耗的无感知一样，AI模型的低精度压缩等技术会让用户可以轻松拥有和使用这些工具，无需过多考虑成本问题，从而在更多行业中实现大规模应用。",
        "time": "00:54:55"
      },
      {
        "question": "AI技术普及对行业应用有哪些影响？",
        "answer": "当AI技术普及后，几乎所有的行业都将有机会以低成本甚至不付出成本的方式使用这项技术。新出现的技术领域如AI编程无需从头搭建基础设施，可以复用现有硬件和软件生态，直接进行打磨和适应性开发，使得AI技术能够首先在一些高价值行业，如AI编程等领域获得突破并逐渐推广至非计算机和非互联网行业。",
        "time": "00:55:29"
      },
      {
        "question": "AI技术对于终端产品形态及硬件需求有何影响？",
        "answer": "AI技术的发展使终端产品形态变得更加智能和傻瓜化，比如未来的设备可能只需喇叭和扬声器就能接入云端大模型实现强大功能。同时，AI技术也会促使硬件形态演变，比如00后可能主要通过触摸操控，而不仅仅是打字输入。此外，在AI技术的帮助下，个人电脑（IPC）等设备将能更好地集成大模型能力，满足用户需求。",
        "time": "00:59:08"
      },
      {
        "question": "对于AI助手OpenAI的发展及其带来的影响是什么？",
        "answer": "OpenAI近期的发展具有指路效应，例如Deep Research等应用可能成为普及的现象。AI助手能在短时间内完成深度研究或日常任务，显著提升用户体验。随着AI门槛降低，人的能力得到极大扩展，许多简单思考工作可由AI完成，让人们能专注于更复杂的思考。但目前仍需等待基础设施进一步变化和完善，以释放大模型的应用潜能。",
        "time": "00:59:59"
      },
      {
        "question": "在AI技术普及下，对于芯片市场有哪些新的机遇？",
        "answer": "在AI技术普及的过程中，芯片市场存在一定的机遇，尤其是在laptop级别上可能有所需求。目前端侧推理和私有化部署已有较大发展，但在中间层训练方面仍有待满足的需求。对于laptop和迷你主机等市场，机会在于能否突破生态壁垒，提供大模型能力支持，并随着下游商业生态变迁逐步激活市场需求。",
        "time": "01:01:43"
      },
      {
        "question": "AI基础设施的发展趋势是什么？",
        "answer": "AI基础设施的发展趋势是逐渐开放、降低成本，让更多用户能够搭建自己的平台。就如同互联网初期Google通过构建搜索引擎基础设施让全球用户受益一样，未来AI基础设施也会变得更加便宜且易于搭建，服务于成千上万的应用场景。同时，AI服务形态也将多样化，包括私有化部署和云服务等。",
        "time": "01:02:35"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "Deep Sick现象对科技行业与芯片市场的影响",
        "summary": "本期节目由峰瑞资本的李峰主持，聚焦春节期间热议话题Deep Sick在中国和全球的影响力。讨论范围广泛，包括Deep Sick对美国科技行业估值的影响、对中国科技行业重估和资本市场上涨的带动作用，以及技术层面的分析，如Deep Sick的创新点、与其他大模型公司和国外公司的不同之处。同时探讨了Deep Sick对芯片行业，特别是算力需求和英伟达需求的影响，以及它是否为中国芯片企业带来了新的机会。本期邀请了星云科技的CEO和知乎著名芯片领域大V，以及科技组同事李刚，共同分析Deep Sick出现后对硬件和芯片相关领域可能带来的影响。"
      },
      {
        "time": "00:02:15",
        "title": "大模型推理GPU芯片及DeepSick模型应用探讨",
        "summary": "本次对话围绕大模型推理GPU芯片及DeepSick模型的应用展开。讨论首先提及DeepSick模型对英伟达股价及行业的影响，随后分享了DeepSick模型在AI编程领域的实际应用经验，特别是在私有化部署和处理高强度逻辑性任务方面表现出色。此外，还提到了不同模型在代码补全和指令跟随等场景下的表现差异，以及芯片公司内部对DeepSick模型从怀疑到认可的转变过程。最后，讨论了开源模型从一个小范围可用状态逐渐演变为大范围可用的趋势。"
      },
      {
        "time": "00:06:52",
        "title": "大模型本地化部署的体验与Deep Sick的出圈现象",
        "summary": "用户分享了在本地部署32B量化模型的经验，指出这解决了在线模型处理长文本的局限性。尽管各种模型各有优势，Deep Sick因其独特的行文风格和强化学习能力，在春节期间通过口碑和免费使用迅速普及，超出了预期。此外，模型的深度推理能力和易用性提升，使得非专业用户也能有效利用，进一步推动了其普及。"
      },
      {
        "time": "00:11:27",
        "title": "开源模型DeepSix与深度推理能力",
        "summary": "对话讨论了开源模型DeepSix在深度推理能力方面的优势，以及与其他国内外模型如O One、Kimi的K1.5、TV模型和Dept K模型的区别。强调了深度推理能力高度依赖于模型的质量和规模，指出高质量和大规模模型在生产力场景中的重要性。同时，解释了开源模型与闭源模型的区别，以及当前流行的开源模型如DeepSix、拉玛和阿里千问系列的特点。开源模型通过释放模型能力，使第三方和个人能够在不同设备上使用，无需依赖模型公司的算力和API。"
      },
      {
        "time": "00:14:47",
        "title": "DeepSick MOE架构的推理成本优化与影响",
        "summary": "DeepSick的MOE架构通过其大规模参数量和稀疏模型的特点，实现了在保持模型质量的同时，显著降低了推理成本。这种架构每次参与生成token的参数量远低于整体参数量，减少了内存和显存的读取需求。此外，DeepSick在推理框架和算法上的创新，进一步优化了模型的分布式处理方式，使得模型在硬件上的运行效率更高，成本更低。这些技术优化使得DeepSick能够在较低成本的硬件上实现大规模模型的能力，吸引了业界的广泛关注。此外，其开源免费的策略，结合春节这一时间节点，使得大众能够以更低的门槛接触AI，进一步扩大了其影响力。DeepSick的高性价比和高质量模型，在天时地利人和的条件下，产生了重大影响和关注。"
      },
      {
        "time": "00:19:22",
        "title": "中国公司在AI芯片限制下的创新突破",
        "summary": "讨论了中国公司在AI领域展示的创新，特别是由于芯片禁令影响，导致国内AI公司更多地依赖于小规模或超大规模的模型，与美国公司形成对比。这种环境变化迫使中国公司在技术优化和应用上寻求突破，从而在与国际竞争中取得竞争优势。"
      },
      {
        "time": "00:22:34",
        "title": "AI模型训练及技术路径的突破与挑战",
        "summary": "对话围绕AI模型训练中的挑战和突破展开，特别是关于OpenAI在GPT系列模型训练上的进展。讨论指出，尽管算力资源不受限，AI发展和训练仍面临阻碍，这主要源于单纯模型能力提升的局限性。提出了“skin law”路径在GPT3之后可能达到技术临界点，需要寻找新的范式来维持持续的性能提升。进一步讨论了通过长输出和推理时间探索来提升模型能力的方法，以及如何利用强化学习等技术在不同领域实现泛化能力的提升。最后，强调了资源受限可能促进寻找新的解决方式，并预期未来几年会有更多的新范式出现，以推动AI能力的进一步提升。"
      },
      {
        "time": "00:28:12",
        "title": "AI模型的未来发展方向与瓶颈探讨",
        "summary": "对话探讨了AI模型特别是自然语言处理领域的数据训练、强化学习及其未来趋势。讨论指出，当前易得的数据可能已被AI广泛训练，而未来AI可能转向自己生成数据自我训练。强调了强化学习在模型训练中的作用，以及模型推理阶段对reward的需求。进一步讨论了自然语言处理中语言本身思考能力的重要性，以及在开放领域获得有效监督信号的挑战。最后，提到了AI模型质量评价的难题和未来发展的瓶颈，指出探索如何利用语言本身的能力以及不同领域数据的融合可能是突破点。"
      },
      {
        "time": "00:33:51",
        "title": "AI模型发展与商业闭环的挑战与机遇",
        "summary": "对话围绕AI模型的发展瓶颈、硬件资源限制以及经济模型的影响展开，强调了开源模型和AI技术平权对推动商业闭环和AI产业发展的重要性。讨论指出，AI模型的护城河不应单纯依赖技术或资源，而应建立在商业模式和生态上。开源模型如DeepSick的出现，打破了由资源和技术形成的高门槛，促进了AI行业的普及和发展。同时，对话也探讨了AI产业在经济系统中的角色和面临的挑战，以及如何通过创新和构建普惠的产业结构来应对这些挑战。"
      },
      {
        "time": "00:39:29",
        "title": "国产芯片与AI模型的创新与破局",
        "summary": "对话围绕国产芯片和AI模型在技术领域的突破与挑战展开。强调了国产芯片和模型不仅需要在技术层面与国际标准看齐，更重要的是寻找新的路径和模式，以实现经济和性能上的优势。指出简单的复制国外技术路径并不能真正实现突破，而是需要构建一个更具竞争力和吸引力的体系。通过借鉴历史上的PC革命，探讨了如何通过经济性和普惠性的芯片和模型，推动AI技术的广泛应用和普及，从而颠覆传统大型机体系的价值和地位。"
      },
      {
        "time": "00:43:03",
        "title": "DeepSick模型本地化部署对计算机及芯片行业的影响",
        "summary": "对话讨论了DeepSick模型首次大规模本地化部署的现象，及其对计算机和芯片行业的影响。这一变化促使行业开始更加重视需求的变化，并可能为国产芯片提供新的商业机会。由于芯片行业有较大的惯性，从需求变化到产品实现通常需要两到三年的时间，因此这次现象为国产芯片提供了一个展示其能力的窗口。此外，讨论还提到，尽管目前市场上的解决方案大多为低精度的蒸馏模型或昂贵的满血模型，但目标是将满血模型变为经济上可接受的标准配置。最后，提到了未来计划，即在芯片产品未推出之前，提供一种价格合理、能运行满血模型的方案，打破硬件资源和价格的差距，以适应行业认知的巨大变化。"
      },
      {
        "time": "00:46:05",
        "title": "创业者的护城河：文化和组织的重要性",
        "summary": "创业者认为，尽管技术优势可能带来短暂的竞争优势，但真正的长期护城河在于组织文化和组织能力。技术的领先是可被追赶的，而如何有效组织和利用人才，尤其是跨领域的协同创新，才是构建持久竞争力的关键。成功的组织需要有全局视野和高效的方法论，同时能包容试错并基于第一性原理进行思考。在国内，尽管存在对经验主义的依赖，但真正拥抱创新并建立新的高效组织方式是推动持续发展的重要路径。"
      },
      {
        "time": "00:50:24",
        "title": "中国科技企业创新转型的标志性事件与路径",
        "summary": "从投资人的视角来看，初创企业需关注资金利用效率，人才密度和团队组织至关重要。中国近30年的发展经历了从中国制造到中国创新的转变，标志性事件如DPC的出圈表明中国企业在全球科技竞赛中开始展现创新实力。这种转变需要大量成功案例来激励社会，扭转认知惯性。梁老板的认知周期问题和对人才的重新定义，强调了成功案例的重要性。从2000至2020年，中国经历了从低成本制造到物美价廉，再到某些行业超越海外能力的转变，体现了中国企业生产、设计能力和专家经验的提升。未来投资将更侧重于AI native的创始人，中国科技在全球的地位和增速持续增长。"
      },
      {
        "time": "00:54:31",
        "title": "AI技术普及与成本降低后的应用展望",
        "summary": "讨论了当AI推理成本大幅降低且速度显著提高后，AI技术在各个行业的广泛应用前景。首先，目标是让所有人能以低成本使用高性能的AI模型，就像使用电脑一样普及。随着AI技术的普及，所有行业都将有机会低成本地使用AI技术，推动AI成为生产力工具，并逐渐渗透到非计算机和非互联网行业。同时，AI技术的普及也将为云计算和私有化部署提供巨大机会，使硬件成本不再是限制因素，而是根据最适合的商业结构进行部署，以实现最佳的用户体验和商业回报。"
      },
      {
        "time": "00:58:46",
        "title": "大模型AI对未来科技和硬件生态的影响",
        "summary": "对话探讨了Open I的大模型AI在短期内的指路效应，特别是其在普及深度研究和个人助手应用方面的作用。讨论指出，AI技术的门槛降低将极大扩展人的能力，减少记忆和简单思考的负担，保留更多创造力和复杂思考。同时，未来的硬件设备将更加智能和傻瓜化，操作形式也可能从触摸向纯语音等新形式发展。此外，还提到了芯片和laptop本地需求的潜在机会，以及生态和商业变迁对这一领域的影响。最后，讨论了春节期间Deep Seek的热度及其对中国科技生态和AI产业的长远影响。"
      }
    ],
    "mindmap": null
  }
}