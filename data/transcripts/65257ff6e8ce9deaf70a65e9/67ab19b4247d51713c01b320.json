{
  "pid": "65257ff6e8ce9deaf70a65e9",
  "eid": "67ab19b4247d51713c01b320",
  "title": "要不要本地部署DeepSeek？核心是平衡成本、精确、智能！",
  "task_id": "wg57n3awaoeyqkr3",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎收听人民公园说AI遇见真命AI做高能创客。这里有最不新最不快的AI解读，也有最走心最落地的创客分享。大家好，我是主播小苏。欢迎在小宇宙苹果播客和小红书关注我们的频道。如果你有好项目和好想法，也欢迎在show note中跟我们联系。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:30",
      "text": "最近有非常多的朋友就是在deep sk火了以后，其实他很快就出圈了。然后有很多非技术的朋友，然后啊一些圈外的一些朋友就会问说deep sick这个东西它我能不能布在自己本地用一用。然后我有一些需求想要不在本地，很多都是这样来找我的。所以我就想说，这个背后其实有非常多的深层次的原因。就比如说你为什么要不在本地，是因为服务不稳定，还是你要自己做一些项目，还是说你有其他的对于安全性隐私的一些考虑等等。这个我们不知道，但是背后一定是有一连串的问题。它不仅是一个就是我要不要在本地部署一套deep sick这么简单的事情。所以我就想说拉来老修贤哥我们一起聊一下，就是要不要在本地部署deep sick，谁适合在本地部署deep sick？",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:29",
      "text": "对这样一件事情哈那前几天我发了一个发了一个播客，就是在讲一个观点是什么呢？就是说deep sick出来以后，其实他很像当年的安卓，就有点像AI的安卓时刻，对吧？是的，大家如果回想一下，当年在iphone出来以后，安卓马上在后面的一年里面就跟进上了，然后迅速的开源，获得了广大的手机厂商的支持。那在国内也是小米也是借着米UI然后再借着供应链的成熟做了小米手机，用1999元打爆整个山寨机的市场，从而帮助智能手机获得了更多的用户，让大家都用得起更大屏的触控的智能手机。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:20",
      "text": "所以这是安卓在那个时间点非常伟大的一个历史贡献。当时有ChatGPT出来之后，老黄就说这个是AI的iphone时刻。所以我当时就想，什么时候是安卓时刻到来？后面我们看好像拉玛也不是，对吧？一会儿老师可以讲，其实拉玛也不能完全算是安卓时刻。但是我觉得从我的体感上面来讲，最近的deep sick就真的有点像那个时候的智能手机的安卓时刻了。就是它引起了一个更大圈层的讨论，它有更大的争议。不管这个争议是对于说中美不同路线的，还是对于民族自信的，还是对于技术自信、道路自信的这种争议。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:07",
      "text": "我们不且不管他是什么争议，但是至少deep sick这个事情就是让更多的群众用起AI了，对吧？大家都用起来了，不用翻墙了。让那些过去不用AI，不了解AI的人已经开始在了解AI，问AI。所以我觉得这是他非常重要的一个贡献。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:26",
      "text": "但是讲回具体为什么又要有一个历史，又有一个惊人的相似，又又有什么很像的地方？就是大家记得当年安卓开源，然后出来以后是那种刷机的那种系统满天飞，对吧？人人都觉得我可以买一台三星，买一台HTC，我就可以刷一台小米系统，我可以刷一个开源的安卓系统，我可以自己玩一玩，改改UI改改功能。人人都觉得我离这一步非常近，人人都可以做这件事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:57",
      "text": "今天的deep sk真的有点像，大家都想把它布到本地玩一玩，都想试一试我在本地能怎么玩。就像当年我们刷机刷那个安卓的rome Young。所以今天跟大家简单开场聊一聊，要不要在本地布deep seek这个问题。首先我想说从可行性上面问一下老徐，你觉得普通人，就是我们且且不考虑别的因素，在本地布一套deep sick有没有意义？然后该不该这么做？",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:30",
      "text": "对，从可行性上来说，普通人是很难做到。就是有两个很很硬的一个问题。第一个问题是你的硬件，其实他对硬件是有要求的，就不像当年的安卓，你随便一个手机，它其实因为当时的能做安卓的机子，它是硬件跟软件是一起配套来做的。这个跟我们现在的这个大模型不一样，我们大模型的大家要本地想跑顺畅，一个大模型你没有一个独立好的显卡的足够的GPU显存你都跑不起来。那我们直接换成那个钱，也就是你有一个独立的大几千块钱的显卡在在你的电脑上，这其实就可能筛掉了90%的人了。就除非原来就是游戏爱好者，可能很少有人有这么好的显卡。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:13",
      "text": "那那然后还有CPU也有要求，就是你的CPU可能差不多也得个四核八核，八核以上差不多才是个基础入门线。因为dept sick本身强又强于在推理。就算是用它最小的那个模型1.5B它的这个CPU跟内存的要求很多。百分之可能我认为是80%到90%的人的家里的电脑是不太够跑的，除非你电脑上什么也不干。而且还能够通过一些工程化的方式去做一些优化。你能勉强启动而已，那那这个时候就惨了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:44",
      "text": "勉强启动是什么？就是我们大家可能我们我觉得像做个类比，就是很多的那个我们说如果是买车汽车，家用汽车，大家知道一般什么盖板的，就是最低的这个版本，什么东西都可以没有，那可以跑起。但是这个大模型这个东西还不不比这个汽车。因为我们说汽车再低的盖板，它这个发动机和变速箱这些东西没办法减配。他至少你是能跑得起来的。就再带上几个轮子，大沙发、大冰箱都有了，都可以对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:15",
      "text": "但是你这个问题是大模型它是本身它就相当于是汽车的那个引擎的部分，发动机的部分。那他这个东西如果减配了，你这个车可能跑起来，那不一定可能就是不一定跑得过马，不一定起步的人。是的，是这样子的，就是他能能也许能启动，就是最低配能启动。但是你跟他聊一句话，他他很慢的跟你说出一大堆那个字，可能要好好好长的时间，就是也许是十几秒几十秒才给你回了简短的一句话。你这个你也你能用也等于不能用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:48",
      "text": "还是说你这个比喻挺有意思，就是他我们是我们的本地的设备，就像一个底盘一个总成，然后最后要把这个发动机换下去。但是发动机如果不行，他就基本上就是浪费了整个底盘。且不说他连跑都跑不动。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:03",
      "text": "对吧？他就是很勉强，其实就会像这个，如果是科学上真实发过的，就是最早的电动车就是这样。最早的电动车是跑不过马车的，它的速度很慢，然后那个电也只能跑个几公里，大概是这样子。正常人是忍不了，那个时候就贵族可以坐一下，慢慢的慢慢悠悠的那边弄，但是正常人就是你实用性来讲，你这个受不了，接受不了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:25",
      "text": "他妈，我问一下你，你最近不是去年不是你也换了一台macbook？当时我们是要跑lama，然后对你你应该买的配置还蛮高的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:36",
      "text": "对，两万多靠。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:40",
      "text": "对，现在那台现在跑deep seek，现在OK.",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:44",
      "text": "只能勉强跑那个7B的水平。我们刚才说最低是1.5B，我这个也只能都跑到7B我这个是什么水平？是32G的内存，然后CPU是16核的，然后GPU有31个，GPU是这个水平的，然后跑起来也只能勉强跑个7B，然后才算是也就是勉强可以用的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:08",
      "text": "所以首先在这个设备门槛跟金钱投入上就卡掉了。大部分的需求就是我觉得可能至少现在你去买一台macbook，你也要买到3万以上才能说有一个相对宽松的环境。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:22",
      "text": "对，相对宽松一点，而且内存可能还得选高一点的才行。就是因为这大模型最基本是它的东西大，16G基本上是入门的，就是那个1.5B你可能也得有个16G不然你可能会很勉强。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:36",
      "text": "所以并不像自媒体老师讲的这么一键部署。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:40",
      "text": "对吧？就是能部署，我跟大家说，你把一个引擎装上去能装，那你最后跑个两三公里每小时，你跟人走路差不多，那有没有意义呢？可能还有就是推理能力也会很差，也会差很多。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:55",
      "text": "所以背后就有一个更深层的问题。那为什么大家想要去玩一把，想要去本地部署一把，想要自己放在电脑上面玩看看。其实你理论上你体验云端的也可以，对吧？然后至少如果说你觉得deep seek的服务不稳定，那你翻个墙，你用一下GPT，对吧？那那这个门槛也并不是那么的高。那为什么会有就是大家都会觉得很手痒想要做这样一个事情。我就想说问一下贤哥在背后有有哪些的心理？然后是什么人会想要去本地部署一套deep sick，他背后的心理是怎么样的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:39",
      "text": "我看这个问题，我觉得这个问题特别好，因为很有典型性。因为最近讨论DPC太多了，而且这个持续在发酵，所以很多人都会来讨论各个问题。确实刚才小苏说到有些人会来问，就想私人部署一个这个东西。其实这个事儿我觉得在open OpenAI出来之后，就有很多人想这个事儿。但当时是不具备这个条件，而且成本比较高。所以所以相当于是大家一个念想。然后很长时间都想，我们能不能自己私有化一个AI系统在自己的本地，对吧？我觉得可能就是个人看啊个人看提这种需求的人可能有几种心态。一种就是说自己做的行业特别私密，或者说自己的这个东西是金刚钻，不能随便的就能够放到这个，就怕数据安全问题，或者说know how被被那个什么了，被被稀释，或者被公有化，或者被未来的自己的一个屏障就没有了。我觉得这可能是第一性元的一个需求。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:30",
      "text": "第二种可能性就是什么呢？就是说想拿来玩玩，对吧？就是自己深度来拆解一下。比如说这个东西它以前是非卖品，然后现在突然是可以有价格可以卖的了。那我无论多贵，只要我能承担起，我就拿过来玩玩把玩一下。那真正说拿回家之后，有可能就雪藏起来，有可能就拿出来随便用，这种也是一种心态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:50",
      "text": "还有一种可能性就是什么呢？就是说觉得OK这个东西新鲜，我想就是讨论一下。但真正如果说去讨论真的去怎么部署，花多少钱去部署，部署之后有什么用，我没想过根本就没想过这个事儿。但我想说的，其实我觉得前三类都没有说特别强的需求，或者说我都不能称之为一个需求。我觉得只能一种情绪，或者说一种想法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:14",
      "text": "但我觉得第四类就是我个人觉得真正有必要去做私有化，就是说有且必要的这种情况就是什么呢？就是说他大模型问问目前的有限性局限性，能不能用私有化部署的方式来做一些补偿，或者说做一些优化。比如说现在你看很多时候大家要讨论的是说大模型的这个幻觉问题，对吧？还有大通用大模型的这种就是长对长文本的这种记忆性问题。比如说我三个月前问了他一同一个问题，等我三个月以后再问相关的或者升级的问题的时候，他可能已经不知道我在问的是同样的问题或者说同一个事情了，对吧？而且加上存储，就是数据存储，这是一个安全性问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:53",
      "text": "还有就是刚才说know how有很多的专有know how怎么样能够训练出来。那我不可能说去微调，就是说整个调整大模型，升级大模型，那我能不能做个小模型来来自己来做。当然这些问题都能够触发和私有化部署这个事儿。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:08",
      "text": "当然还有一个响应速度的事儿，比如说前两天我用DBC，就是经常就刚问两个问题就崩溃了，就过不了了。对，然后就是你想如果我现在做的是一个非常精密的事儿，或者说非常需要及时反应的事儿，突然他那边掉线了，那他这个不可控性我是无完全无法预知，完全无法避免的那这个时候我是不是就要去做了？比如说举个例子，我现在用这个大模型去操控一个什么精密的仪器，就到这一步突然他掉线了，这跟咱们怕停电是一个道理，所以才会有UPS有有这种东西。所以我想先回答小苏刚才说这个问题，就是大家到底为什么想要私有化？我觉得前三种都是情绪或者都是一种个人感情上的诉求。只有第四种情况就真的是有需求，而且是有必要去做私有化的那至于怎么做，我觉得后面咱可以慢慢聊。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:57",
      "text": "对，其实我觉得从实际的投产比来讲，就是去私有化或者本地部署价值不高。哪怕是说非常有实力的企业，你去本地去布一套，也并不是完全划算的。我个人会觉得说，可能后面我们会聊到。如果是说在一些创业企业来使用的话，我觉得混合的方案会更好。就是复杂的走云端，然后一些基础的一些总结归纳提炼的一些场景，可以走一些本地，这样子能响应速度更快，然后做一个这样混合的组合可能会更好。但是另外一个角度就是说其实我觉得他也开启了另外一种可能。老板他有可能会有一个压缩版的，更小更轻的一个模型放在一些其他的智能的终端上面。你觉得未来会不会有这样一个趋势？",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:58",
      "text": "其实现在已经在发生了，就有人在在尝试这个事情。只是说他现在的版本做这种小版本，其实我们还是要回到那个词，大家听的有点听得有点耳朵磨烂了，但还不知道什么意思，叫蒸馏的那个。对，但是英文就是的。那那这个词其实用英文去解释，我后来想了一下，英文解释反而更简单的。它本身英文的意思就是提取的意思。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:22",
      "text": "对，然后他去提炼。因为其实你如果是这样去讲，你可能会反而不会很混淆。他简单的说就是一个把R一作为标准的了，它相当于是个老师模型。然后你去通过这个老师来教下面的学生，然后那那这个老师懂东西很多，让学生可以从中间去学习他直接的结果。那那这样子的话他就可以只要他可以不知道背后的原理，只要知道说一些结果，然后我能回答这个特定的这些结果的那问题就可以了。他就是学生跟老师之间的关系。他现在的话其实本身这次首发开源的时候，它是有通义千问和拉马的两种的小的模那个参数的模型。也就就是我刚才讲到的，我们能在本地跑的其实都是这一类调的那那这一类调的话它叫蒸馏出来的，那它这种调出来的那个模型的话，它就可以跑的比较小。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:18",
      "text": "但是这种就是大家要去解决什么问题？因为现在的话是由于大家他首先开源和论文里面讲的都是逻辑推理这件事，也就是强化学习。他本身那个论文讲的就是强化学习这件事情，带来的这种一个比较强的思维能力。因为这种能力他现在的话突出的是这个能力，他没有解决说日常大家去解决实际使用中的那些场景到底是要什要多强，要做到的什么样。所以它最小的那个1.5个B看起来很弱。但是他也已经达到以前向千问大概是60个B或者是拉马60个B就是十倍。它只要10分之1的大小就可以做到原来十倍大小模型的那个推理的能力。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:04",
      "text": "但是它综合的能力是没有那么好的，这个是必须得讲清楚的，就是他只是在推理这个地方，对，也就是举一反三这个能力他OK。但是他他他这种我们可能有另外一个比喻，就是说他的相当于他触类旁通，举一反三，碰到没见过的东西的时候他知道怎么办。但是很多基础的知识由于被是蒸馏提取的，它只提取了一些老师的精华知识。他有很多基础知识他反而不知道了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:36",
      "text": "就相当于刷题刷出来的。但是真正的基础原理并不并不对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:41",
      "text": "这里有一个比喻，有一个比喻很有意思，它其实也是实际的一个情况。就是我们说老师，比如说我这个老师就是R一认识，有他在碰到1000张都是狗，我们号称都是动物的那个照片。他看过了，他知道说这一千张里面有800张都是狗，有200张有是那个狗之外的东西。然后他就知道一个分布，就是他不仅仅知道结果，他知道分结果的分布。因为所有大模型它最后它是一个概率的那我们知道它普通的大模型到最到本质是预测下一个token，下一个他可能会出现的那个选择到底是什么。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:21",
      "text": "那那老师的话他就是在预测的时候，他实际上是知道分布的。比如说排名第一，80%应该是够，就是不用看都知道是狗，80%是狗。但是看了以后他可以区分出来这狗子外面还有狼，还有狐狸什么的。然后他能告诉你狼可能在里面有15%，还有狐狸5%。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:38",
      "text": "比如说这样子的一个比例，那那他交给学生去蒸馏的话，学生他就提取这个精华。他就直接知道这100 1000张图里面有800个是狗，然后150是狼，还有50是狐狸。他直接知道这个分布，但是他并不知道这里面他们的他的一些特征。他他他只是听老师讲了一遍，他基本上比较熟的那个狗他能认识，但是到底狼和狐狸他就可能不是很区分的出来了。但是他这个情况下他可以靠混，就是他蒙也蒙的出来给我一张图，百分之我说是狗，80%是对的，他就会优先去把告诉你这个就是狗。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:15",
      "text": "好，然后那他后面你问他，这到底我觉得像狼，然后他说那他再看一下，他这个时候狼跟狐狸他就分不清楚。他但是他也可以给你一个答案，因为他知道另外两个答案，这里面没不会说达成是个人，不会达成是个猪。他说另外两个答案反正就是狐狸或者是那他就这个这个就是他的一个局限性，就是老师教给你了这一千个里面就这么三种，他就只知道这三种，但是其他的种类他不知道。其实有可能你随便换个样本，那他回答不了了，他完全里面的东西都不认识。但是在这个特定的领域里面，他其实就已经可以工作的很好了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:51",
      "text": "所以回到小苏的那个问题，就是小的模型我相信肯定会出来，只是需要有人去调，就是你需要去跟你的场景去调。因为现在是个相对还是太通用了，它还是有很多通用的知识在里面。所以那个1.5B做起来还是要那么多的硬件，还有那么多的训练。你调它也不容易。但是你各自去根据自己的场景使用行业去结合的话，你可能根本有很多知识还是可以剔除掉的。他还是有很多通用的知识，还是学了很久的那这些知识可能对你都没有用。你可能到后面根本上也许是个0.15B的东西，就够你那个行业用了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:27",
      "text": "1.5亿都太大了，B是B点是10亿，因为我们我们再比较一下这个参数，就大家在网上直接跟他聊的那一个模型，我们经常叫满血版。满血版所有的功能都堆好了的，它是671个B点，就是6710亿的那个参数。然后我刚才说我们在本地现在能碰到的是1.5个B就是100就是15 15亿而已。这已经差了几百倍了，就在在这里400四五百倍对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:58",
      "text": "那那然后我们实际用可能我是觉得也许比1.5B有些可能还可以低一点，都有应该是可以做出来的。然后他的推理可以不要那么强，还可以再弱一点，但是应该够我们日常的很多企业的使用。我觉得是这样，因为我们企业内的很多流程其实不是在于难，难在它的推理特别的难，或者说有特别多的未知条件要需要他推理。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:21",
      "text": "其实企业里面应该是可能80%到90%的场景是我们已经预定义了。我们是知道它的场景的，只是我们之前说过很多问题是预定义，这里面的很多SOP是没有在你的材料里面。就是AI自直接自己学习不了，然后老师傅也教不清楚。你可能过程中还得靠人去我们说的那个人工的调整，人工的微调，还得去把知识提取出来交给他。最后有10%也许是人也讲不清楚的那这个时候就得靠你这个老师教给他方法，让他自己去推理。但是可能难度没有那么大。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:52",
      "text": "所以这里我觉得说这个趋势一定是小于1.5B的专用的模型应该会有，然后到时候手机也能跑。但我们现在是刚才讲的私有部署的很多还是以电脑为基础的，没说用手机。对对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:06",
      "text": "其实我觉得这个问题不仅是说在企业内部用是SOP的问题。可能再往前一步是整个流程解构的问题，就是你要把需求解构到什么程度。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:16",
      "text": "其实刚才听老师这样讲，贤哥我突然明白，我们其实最近也遇到非常多的人在问，就有一些是创业者，有一些是这种一些pro的一些用户，我觉得可以大概是不是可以用这样一个三角来解释，就是你要平衡，就是你要不要本地部署一个大模型，或者一个本地部署一个小模型来讲，你要平衡一个三角。第一个是成本，第二个是速度或者精确性，然后第三个是智能。其实你就平衡这三个三角，我们先不考虑隐私的问题。隐私这个事情从云端的时代已经证明，就是只要你有一个长板特别牛，你这个隐私是可以放弃的对，是的，所以我觉得隐私这个事情当做一个底线讨论，不当做一个三角里面。所以我在想说，不管你是企业也好，还是你是创业团队或者怎么样，你要不要去本地布一套类似像deep sick这样的一个模型。我觉得你要考虑的应该是成本，速度跟速度跟这个精确性，还有就是一个智能，就这三个三角。如果你想走智能的，你可能就要把这一块需求放到云端去。如果你想要成本低，你就把它解构掉，一些最简单的总结归纳的能力放在本地，然后就不用去走API，就不用去走云端去调用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:46",
      "text": "然后你想要速度跟精确性，那你肯定是要用你自己训练过的预定义的几个场景，能够实现过快速的识别猫跟狗。这是已经在你的这个库里面定义完的那也不用去走云端快速去识别掉。所以我觉得我不知道我这样理解对不对，可能是要更能跟非技术人员讲清楚，你要把这三个三角平衡好，然后想明白你这个事情是要为什么用你再去做对。是的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:16",
      "text": "是我觉得你刚才这个归纳真的特别好。他本身就是一个决策，就是一个动态的过程。如果站在这个时间点上去问这个问题，我需不需要本地部署？",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:25",
      "text": "如果我反过来就跟我朋友聊，我就会问你就是你现在是要赚什么钱，或者说你现在靠什么赚钱？你是靠你的是提供的是最你最最专家级的精确的数据和分析来赚钱。也就是说比如像会计，咨询对吧，完了或者是像法法律，法务这些东西？你是靠你的know how，靠你的精确的知识的回复，和你的这种私有定制化极高的这种东西来去挣钱的。还是说你是靠着走量to c端的一些东西来做的对吧？然后或者说你是说靠低价策略来来撕开市场的那不就是刚才你说这个三角成本，精确和速度对吧？还有智能情况。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:04",
      "text": "所以在这过程中的话，其实咱们一直在讨论就是说要不要私有化。但其私有化部署，这个问题的再往前一步，还有几个前置条件，包括我们到底私有化部署的是什么？就私有化部署之后是不是就可以完全不用API了，还是说用混合的方式更好。还有就是说现在我们针对到底是初期创业者，就是要重新去做一个AI创业的，还是说已经是在一个行业里面是处到一定江湖地位。他现在是要降本增效，还是说需要在原有的这个成熟企业之内，提升自己的竞争力。所以各个不同的状态之下，肯定他的需求是不一样的。我觉得这个问题本身是要考虑到底用什么赚钱，就回到经济本身，我们到底要赚哪份钱，然后这个问题就好回答了，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:51",
      "text": "像比如说我看到网上有个说法，我还是挺赞同的。就是说如果你是做to c生意，你的用户在1万人以下的时候，你考虑私有化部署，这件事本身就过过于过于超前了。那这个1万人是不是一个准确的数据？我觉得不必要，他只是给了一种思考方式。如果你服务的量级还比较低，你不是说先去打磨自己的产品，然后把自己商业模式和商业结构做好，先把AI的功能用起来，对吧？然后你先不用考虑像刚才说的隐私，准确等等这个问题。而且在这个在一定的数量级之下，就是用户的数量级之下，你用API的成本一定是低的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:27",
      "text": "等你到了一定的用户及以上之后，你要大量频繁的调用API。而且很多问题可能都是重复性问题的时候，那你私有化部署或者说云咱们自己私私，就是本地端在缓冲缓存一些这些知识的话，那肯定是更高效的。而且未来你是可以不断迭代的，还能构建自己整合。所以还是要回到行业本身来看这个问题。但我觉得对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:51",
      "text": "但我觉得有突然想到有一个点，我们之前聊过一个说苹果AI的一档节目，我觉得像类似。这样的小模型，其实苹果应该也会去考虑一下，可能升级一下他的策略。因为过去在依赖像找合作伙伴这个事情可能很不顺。像在中国这边百度他还遇到蛮多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:14",
      "text": "我猜苹果蛮开心的，背后应该加班加点正在干。是的对，是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:18",
      "text": "因为因为我我觉得不管任何的智能设备，你说现在的AI玩具或者是眼镜手表也好，我觉得有我自己的一个判断是就是如果本地的模型在手机上跑不起来，那其他就不要不要讲了。就是在手机上你都无法构建出场景。其实你在任何终端设备其实都只是手机的延伸而已，所以它它其实很难被被跑起来。为什么为什么会这么讲？就是因为你手机其实本质是一个多模态的东西，就是多模态的打引号。这手机上是叫什么？它它是有摄像头、有传感器、有陀螺仪、有GPS对吧？然后有有扬声器，然后有有这个麦克风，它是一个相对就是一个立体互动，多种模态支持的这样一个终端。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:08",
      "text": "如果你在手机上大模型都跑不出场景，或者大模型都跑不出性能，或者大模型都跑不出它的智能。其实你放到眼镜，你放到玩具上，只是最终其实最终只要手机进步了，你就会被熠熠出来给淹没掉，被手机进步溢出来的那部分智能给淹没掉。所以这差个体会还好。我突然想到我们那天在聊苹果AI的时候，我在想苹果现在应该也是挺开心的，有一些动作在在。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:41",
      "text": "上面很开心。没错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:42",
      "text": "而且是大礼，直接送来一个模型，开源模型对对对，这两天我看我那个因为我在海外，我用这个plexi，然后他就专门出了一个客户公告，就说我们已经接入了RE的系统。然后对于消费用户的话，对我一天有500个提问的这个权限，如果是非付用付费非付费用户的话，我每天有四次用户。但他声明的第三段特意写明说，我们跟中国的这个d sak团队没有任何关系。然后我们的数据完全存储在北美和符合本地的这个数据需求的要求。而且数据是你的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:14",
      "text": "数据不会离开西方国家。他是这么讲的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:16",
      "text": "原文是这么讲，而且对而且还特意提到就是说在这个受限搜索的内容，我你可以在proper protection上获得搜索。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:25",
      "text": "这邮件是这么写的，我是直接看他那个推特上面他们发了一个。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:32",
      "text": "我觉得这个邮件写的更严谨。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:34",
      "text": "对方的这个双标真是执行到很彻底，到了自己这边时候就可以完全。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:39",
      "text": "老徐像那个propel I他是自己布了一套RE对吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:44",
      "text": "对对对，这一步这里面其实又扯其实也扯到了私有化部署的第二个坑。就是其实现在市面上不管谁自己部署的RE都没有dev CK的那个满血版的性能和逻辑推理能力强。因为它背后其实还有很多的其他配置要调的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:04",
      "text": "不是，只是这个大模型看到的那个聊天那个部分，因为他背后我们说的，他基本上他有两个重要的动作，一个是深度思考，这个就是我们说的他的推理能力。还有一个是联网搜索，这是两个最最直接的联网搜索。实际上涉及到的是我们说的是扩function call。这一块方程扩这个东西其实是一直以来就是所谓我们说做agent，做代理这一块一直是依赖这个基础能力。但是这个基础能力其实各大模型之间的互相的调优都不一样。所以这个东西到最后一般来说都是自己母厂商自己做的那个相应的东西会调的比较好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:45",
      "text": "对，所以这个事情就是大家虽然都有满血版，但是有很多人真的是去试的。没错，就是你你相同的问题，你跑到我们自己的deep sik这里来问，和在别人那边问都有差距。比如说国内没错有什么360的纳米AI搜索，然后还有好多其他的轨迹流动等等。大家最后聊出来的都是有一点差距的。然后对我还是回到那个普通人为止，没有太大差别。我们就说真的要做做一些真的很很专业，有的人会有一些差别，是还是有些差别的，这也是自由化部署的差异。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:17",
      "text": "对，这我让我想起说国内原来这个官或者国内说四大官窑各个官窑都是用的同样的陶土和不同的，但是产出来东西就不一样，各自有各的特色。确实是，然后真正的就是这样的。虽然是开源的，虽然所有东西都可以通过论文来追溯或者到来倒推，但是最终查到效果肯定是不一样的，而且确实已经被证明了。不过我八卦一下，我听说好像自从这个RE火了之后，就是DPC火了之后，好像性能也做了降速。之前我看最早一批测试用户，他们说当时这个深度思考的时候，可以深度思考就是将近几十秒甚至上百秒，然后打出的内容会很复杂。但现在基本上深度思考就是十几秒左右的，是十几秒20秒次机会之内，在20秒时间，可能是说是不是也反映了它本身也限制了一定的性能，没有真正把王，就是所谓满血版，还有120% 140%的性能没有。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:11",
      "text": "释放出来的。这个不是很好说，但是有一个很现实的问题，就是他们deep sik这个团队还是初创公司，就是它的硬件上面并没有那么强的能力服务这么多人。对，所以这个有一个情况就是说有可能他并就是模型层面是满血的，但是真正运营层面不是满血的对，就是有点像。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:36",
      "text": "我还是想用车比喻，因为车大家比较熟悉，大家知道以前油车有一个叫发动机启停的功能，就是所谓的就是你你开的比较，比如说到市区比较堵车的时候，它会把发动机的功率降下下来，会降的比较低，怠速的时候它就比较低。然后要启动的时候，突然会听到它启动的声音，就有点像这样子。那他在运营的运行的时候，其实是有很多运营的手段的。会让你不管缓存还是各种各样的让他是不是完全负荷的跑。他们这个是过程中间会有动态的调整，这个不是说模型本身有问题，可能是在运营的时候，实在服务的人太多了，他得有个策略。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:16",
      "text": "其实跟那个还有一个例子，就像滴滴打车。滴打车其实很多人会觉得我面前有辆车，你为什么不把这辆车安排给我？但是滴滴打车的时候，他考虑的是全局最优，我觉得尽量让全局最多的人打到车，所以他不一定会把你面前这辆车发给你。但是找你的也是，大家可能有个最基本的规则，是可能最近的300米以内的车可以给你那给你另外车也是300米以内的，只是不是你面前的这辆。这在这个300米之内，大家是全局最优的，而不是个人最优，这种都是会有的。因为这种工程化的，我本来的这块是做的相对比较好，但是大家这个时候不得不做，因为实在是太多人在访问了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:54",
      "text": "所以像之前我们上一期节目也聊过，毕竟还是构建在云服务之上的，是云服务还是一个更底层的、更复杂的、更工程化的一个云一个底座就AI的底座，就AI只是云服务的一个卖点跟护城河。所以大家很不明白这一点，就是大厂跟小厂它的作用。在大厂其实能做好云服务，小厂是完全没这个能力投这么多资金做做这么好的，提供这么稳定的云服务的对对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:26",
      "text": "但是是非常烧钱的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:28",
      "text": "但是我刚才突然又想到，就是我们从要不要本地部署这个事情，从需求上要解构，就是说你要去平衡那个那个三角，你从需求上要把它解构出来。但是我后面听贤哥这么讲，我其实觉得我们对大模型的使用也是要解构的。比如说你今天有一个在chat上面可能比GPT更智能的一个AI其实不足为奇，或者不会引起什么的惊奇。但我觉得deep sick本质上我不知道我认我这样讲对不对，它其实是推理的出圈，因为GPT的推理他并没有出圈，或至少在国内没有出圈。但是我觉得大家用deep sick其实用的更多的就是aha moment，或者是惊讶的部分，还是在推理的这个部分。对但是如果对但是如果你把它给放到本地，或者是把它给阉割，或者是说你就离开了他这个满血版，其实你的推理也就就是不复存在了。对对对，是这样的，推理的体验是不完整的了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:38",
      "text": "所以说可能要分清楚场景，如果只是一个更智能的聊天，那其实无所谓。但是如果一个涉及到需要推理的一个业务场景，那有可能要重新想一想这个架构怎么做。因为我觉得最终要做，不管你是要在一道工序上去用好它，还是说你要做一个自己的产品，还是你整个公司的业务要基于大模型来改造。本质上这是一个架构的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:08",
      "text": "然后架构这个事情其实并不是每个人都能做，或者是说最基本本就如果你不懂技术，你要把需求拆得非常清楚，你才知道什么放本地，什么放云端，什么时候用推理，什么不需要推理，什么时候聊天。所以我想听一下，老兄如果是说大家没有讲出来的那个原因是说我们觉得我们。喜欢deep sick，想用deep sick是因为他的推理。又是本地上本地化这个事情，要怎么做？对的架构，本地化的架构。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:45",
      "text": "对这个本地化的架构其实跟我们之前聊过的，不管是拉玛的，其实还是类似的。就是说你的那个大模型到底在哪一边？这个事情其实刚才有提到，就是智能化你需要如果你需要的是好像杀杀声比较强。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:08",
      "text": "对对对，谁的那个那个OK.",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:11",
      "text": "我就说智能化要求比较高，推理这一块要求比较高。但推理的话它必须得，其实到跑不掉算力的问题，然后还有网络的问题。那这两个事情的话，你的成本都是其实是很高的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:28",
      "text": "我跟我说实际来做必须还是得先考虑。你先用API搞清楚你到底对这个核心的这个逻辑的推理是哪个部分。有多少的逻辑是可以你自己的小模型和相对比较轻的一些云服务或者是本地来代替掉。这一点还是我觉得是第一步要干的事。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:47",
      "text": "就是从需求上你要解决搞清楚你到底有多少逻辑是必须得用RE这种深度深搜索推理去做的那这个东西先就是我们说就是相当于一棵树要先做减脂。你你你作为创业者，那个减脂的动作一定要先做掉。你只有特别有必要的那个东西才用在这个R一的上面，就最最真正需要推理的部分。然后这个部分已经做好了，就减值先减好了，你就剩下这个。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:16",
      "text": "比如我相信这一步一般能减少80%的费用。其实应该有80%的东西可能都不需要用到RE那么深度的推理是可以做的，但是最后的20%可能很难，你必须得靠它，那就那就靠它。那这个时候那这个时候就是要做一笔，就是我觉得也还是算数。你要去算清楚你的客户量到底有多少要用到这个东西。那这个时候我还是觉得是刚才那个路子，就是你必须得有过API的经验，你才算得出来它调用次数。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:49",
      "text": "然后你的当时在这个上面花了多少钱调用次数，然后你再去算一下你换成本。本地那这里本地又会涉及到两种本地，一种本地是云端的本地，还有一种是你真正的本地。你真正的本地就很复杂了。真正的本地除了那个推理相关的那服务器相关的，你还有你还得有你的存储，还得有你的路由网络，还有你的安全防火墙等等的东西。你全部都得靠自己来，也就是云端有帮你实现的那些你可能平时感受不到的一些基建，你在本完全的本地也得自己重新做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:26",
      "text": "还有一个很大的事情就是有一个运营成本的问题，就是你你接下来运维他维护他们也是一个成本。因为现在这些模型的大概的迭代周期是六个月左右。六个月左右。上一代模型可能就一般就逐步的退出市场一年左右，他就不会再能够被调用了。那你买云端的时候，当时的那个消费消耗情况跟后面可能又会不一样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:51",
      "text": "但是云端相对灵活一点，就是如果说你核心的部分你在领云端，你可能大不了切换一个云服务，那可能好一点。但是本地你这里如果也是买下来实实在在的硬件了，当你需要去跟着这些一些云端的一些服务做配套，去调整升级的时候，可能这个成本也是比较大的，尤其是硬件成本。也许在我就说国内，硬件成本也许便宜一点，华强北还是有很多平替的。但是这里面有还有一个隐性的成本，是这些运维工程师你可能也不会请全职的，但是你要不断的请一些兼职的人来帮你调这些部署。因为是实体，实体它的可能得到你实体的硬件的部分来做调试。然后你其实你估计日常也得请着一堆兼职的人来帮你解决网络存储安全防火墙这些问题。那这些都是成本。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:44",
      "text": "我插一个老兄，我们可能要讲清楚一个概念，就是所谓的本地部署，也包括了你在云端的本地部署。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:52",
      "text": "对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:53",
      "text": "是不是完全就是在本地机房。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:55",
      "text": "就是这种形式物理性不低。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:57",
      "text": "对对对，就是对我得讲到最最基本的部署，刚才讲的是最最全完整的那那如果中间状态就是相对对于腾讯它宣传那种。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:09",
      "text": "什么一键接入腾讯云什么那种也是理论上也是本地的云端部署。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:16",
      "text": "对它我们一般这种叫混合云，混合部署就是有你本地的，然后也有那个云端的对。因为很多其实很敏感的数据，有可能是还真的还不能放到云上去的。比如说电力医疗的，有好多是不能放到那个上面的那他确实得考虑我们刚才那个事情，他本地都有存储，有些防火墙什么的，然后只是把计算的部分放到云端，那这个地方就是计算在云端，那就相对比较简单。但计算在云端也有相应复杂的，比如在国内可能要考虑用华为的那一套，有华为的一套的一一些一些东西。如果你的服务海外，那就是海外亚马逊，然后微软的微软。对，有有他他们的他们里面也有，他们里面其实也会有细节的那个网络和存储的配置，只是说在云端配了，也就少了一些线下的配置。所以这到云端这里就会还是我们刚才说的，也有个隐性成本，是工运维工程师的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:17",
      "text": "就云端的运维其实也不简单，也挺复杂的。这是为什么亚马逊云赚钱，因为亚马逊云是他他的他的赚钱的模式是他自己很大。他服务自己本身就要养很多运维人员，后面他把这个东西卖给别人，反正还是一波运维人员继续运维这些东西它就它的毛利会特别的高。但是我们自己去买它，买它的话，那这个东西成本并不太低。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:40",
      "text": "就是你还是要请一些线上的人帮你去运维这些东西。它持续的升级。我就跟他说六个月左右，基本上很多东西都要升级了。你用了很多组件，它可能现在就直接用不了，就直接用不了了，就是淘汰掉了，你必须得换。那你这个时候你自己是可能很难换，你还得找专业人员来帮你换。那就是云端也得有人专门去部署这些东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:04",
      "text": "或者所以我觉得这个点你讲到讲的非常到位，他就是一个现在现状僵持的原因。就我理论上是可以这么做，但我实际上的困难或者成本并不在所谓的模型这一端，对不？还有非常大的运维成本。跟比如说我还比如说假设你今天你是deep sick就好，你遇到到这样的问题，那你只能去招人，你就只能去招这些懂运维做云服务的这些人来来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:31",
      "text": "那就必须得弄。所以他最后还是得去买这些服务，他自己招就不划算。对，他自己招就很不划算。然后这里面，而且现在其实我们看一个事实，我觉得更容易看。今天是2月11号，那个开源的R一开源是20号。1月20号的事一直到现在，一共其实才三周，感觉好像又很久又很但又很快。对，但你会发现大概在上一周，就是四号左右，其实大部分的云厂商都已经接入完了。对，就是云厂商都接入完R一的那个私有化部署了，上周差不多都都有了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:09",
      "text": "对，但是你这个东西就是你可我们可以算得出来，就是你以这种无限的工程师资源，他差不多花了两周时间去把这个东西接入和定个价出来。怎么卖？比如100万token，比如说国际流动100万token是16人民币，你去调用它的API是16块钱人民币，100万的token OK。就这个东西他就两周左右就全部搞完了。那那但是你接下来你自己要把它接入到你自己应用里面。我们现在其实还没有看到谁，那么快就有一个应用说我已经是用RE已经怎么样了。其实这个需要时间的，你自己接入也需要时间。然后后面可能成本调优，就我刚才说的很多工程师的一些事情还是要进去的，就是哪怕是马上就有一些应用用上了，但是它的成本有可能要降低，也还得你真的得有运维工程师去介入的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:03",
      "text": "我们之前不是也有一些做AI的小伙伴，就专门做云端的那个调度的优化的，他能够降降的那个也能降到百分之降降很多，百分之八十九十都有可能。因为他也是有闲置跟忙时以及动态的一些。你可能不同客户在不同的区域要用不同的服务器去服务，那他都会有很多的闲置know how的里面的去怎么样去优化你的调度的问题。因为最后是调度，他的调度就很复杂。你就全如果从你的客户角度去要能够有一个体验跟成本的优化，这里面背后是有很多成本的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:41",
      "text": "所以这种混合云的架构其实是比较清晰的那一定是你那个最贵的东西，你能够把它放到云端去会好一些。那至少在现在这个阶段是这样子的，因为它变化太快了，淘汰率太高了，维护成本高。然后你相对那些。你那个很高频使用的，但是确定性高的东西，你放到你自己的本地，你只能能摊下来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:07",
      "text": "成本就比较低了。其实这里面就构成了一个悖论，就是你把所谓的推理跟智能放到还有后续的这种云服务运维稳定性全部放到云端去。那你本地就剩总结归纳，总结归纳在放在本地，首先你跑不过一个云端比你更智能的一个模型，除非你有特别好的应用。比如说你结合了视觉，比如说你结合的声音，你坐在比如说麦克风里面，你坐在某个玩具里面，那这又要求你有大量的训练标注以及数据。我觉得这个对一个团队来讲是不可能兼得的。就他能做得好这个架构，他能想清楚这个事情，但是他可能他做不了数据，他做不了这些训练，然后更不做不好一个本地的，只能把summary这个事情做好的一个模型。我觉得这个就构成了又构成了一个悖论，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:05",
      "text": "就特别困难。所以这个是为什么deep sick跑得快？跑得好有一个很重要是他很聚焦，他是很明确他不做应用的，他的东西只做这个推理模型这一块推理模型或者是大模型本身多模态等等这些事情。就是他解决大脑问题，不解决手脚，因为手脚这个事情他他自己想的很清楚，没办法兼顾去做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:29",
      "text": "这个也是为什么有有很多人去分析，为什么DPCK做的这个线路，感觉大家都是最后其实本质是基于google的transformer这一套。对，那open I也是这样做的。那open I或者是deep sik这些领先者为什么能做出来？好像大家理论都一样。因为大家到最后真正做这个工程化的取舍后会差异很大。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:50",
      "text": "对那那个那个我就是有很多应用，其实o open I它其实做应用的部分也很少。虽然它有一点点，但是他主要还是在做大模型的推动，而且它有先发优势，或者有很多东西是来做。对对对，他也融了很多的钱，然后去做多样化，更多样化一点。那那deep sick的话它也是很明确，就是我我不做这些应用。因为他他自己知道他自己的人员配比和所有的东西都是集中在他的那个研究上面。他现在100来号人，但是耗费也是很大的。我觉得后面看到好多处的数据都是100来号人，一年的年薪耗耗到一个亿是正常的。因为他大部分的博士生年薪百万是起步价，就是实习生现在都能给到七八十万的那个那个薪水。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:37",
      "text": "让你来干。所以做大模型这个事情跟应用是两件事情，也是两帮人两种技术能力，两种技术栈，两种人才类型。所以你看我们AI open a为什么用投资的方式去投这个做法律的harvey，然后去投这个做教育的speak？虽然从技术上来看，他们其实可能大部分就是用了OpenAI的能力。但是实际从技术实现、从架构、从业务、从人才上面是跟open a完全不一样的。是另外一套完全的架构，那就代表另外一套巨大的成本。所以open I为什么会用投资的方式来做应用，也是这个现实的道理所在。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:20",
      "text": "所以如果是以这个案例跟大家参考，大家可以去回看我们之前聊harvey聊speak的这几个视频拆解。我们对对对，我们也都已经有把这种里面的差异性给讲清楚了。做大模型的公司尚且都有这么巨大的差异，何况是说我们需要去用大模型的个人，或者是要用去用大模型去布大模型的团队呢？那这里面的其实你想象不到的坑可能会更多。如果你就是说你很你听完老师的讲法，你自己对技术上面去解构，去做这个架构，你有自己的想法也挺好。但我觉得从我自己的角度，可能更更偏硬，就是更偏创业的角度来讲，我会认为说你要想清楚做什么。我觉得大模型无非现在就是做几个事情。第一个是归纳总结，然后第二个就是推理，就无非是做这两个事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:22",
      "text": "就是到了这个阶段，我觉得在本地去做推理完全大可不必。那你在本地有且只有你就只能做归纳跟总结，那归纳跟总结在本地做，你怎么做的比别人不一样。那就涉及到你的数据，又涉及到你的标注，涉及到你怎么用多模态，涉及到你怎么去用这些混合的架构，混合的框架去组成你自己的场景。这个就是比另外一套非常重的成本，也非常吃人力，也非常吃你的我觉得经验跟多好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:00",
      "text": "对对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:01",
      "text": "所以就是你不仅从技术上解构，从大模型的应用场景，你要去解构它，什么时候做推理，什么时候用归纳跟总结。所以我觉得这个事情大可先看看苹果怎么做。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:17",
      "text": "对我我个人来讲，我还是喜欢比较举例子，举一个不太恰当的例子。我觉得就是说未来也好，或者说马上就能可见的未来也好，整个的这个大模型就像电力一样。它是电力是什么意思？就是给你供应你的这个能源的来源。但是你非要在自己家里搞个发电机，我觉得这个大多数家庭都是没需要的对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:39",
      "text": "但是你非要说自己想要搞一套，你说我自己要搞明白发明技术这东，你要想搞明白，不是不能。现在尤其这个R一开源之后，你是有这个可能性，而且成本也比以前想的很低，而且也突破了这个芯片的限制，对吧？相对来讲的话，也不用特别最高端的芯片就去做这件事儿。所以就是说你自己家里想搞个发电机，发电厂也可以，然后投入只要你能够能跟得上就行。但是有这个必要吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:02",
      "text": "我觉得没这必要，买个太阳能发电板就好了。对，太阳能屋顶装一个也是更多情况。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:09",
      "text": "就像刚才小苏说的是，我们是不是要考虑一下应用的问题。就是你可以用220伏的电或者说是直流电，你想用电池，你想做出一什么玩具来，做出一什么电器来，做出一电火锅、电磁炉，还是说做个什么做个洗澡的什么电热水器，还是说做个电视。你更多是考虑满足人民日益增长的文化和物质需求这方面，去考虑更多的AI的应用，而不是去更多的去考虑怎么样去搞个发电机发电厂。当然了，我在像比如说我在海外生活在新西兰也好，在在加拿大也好，都见过那种自自自有农场，几个acr几个樱木的这么一个2D然后需要自己搞一个发电厂的发电机。因为经常可能会涉及到停电或者其他的极端情况，那种特殊情况。也就是说这个需求是存在的，但并对我们广大群众来讲，这是没必要的一件事情。所以就做这个不恰当类比。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:04",
      "text": "我觉得未来这大模型这几家大模型最后都是电力公司，然后他们负责发电，然后我们更多的创业企业是做小电器，然后更多的用户去使用这些电器。让生活更美好。当然了还会有人去建水库，有天然的这个水库，也有自建的这种发电厂。水力发电、火力发电那些可能就是算力中心了，那是另外一回事了。当然这是一个不太恰当的类比，因为时代在进步，肯定会有新形式的东西出现。但是在我看来咱们说了好多，要不要私有化部署这个事儿，我们都是在讨论，就更多的是讨论私有化部署的可能性，但在我看来是更多是考虑的是说什么人需要，就是我们说了很多可能不需要的情况。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:45",
      "text": "那好，什么需要？我觉得是两种情况。我的第一种情况就是作为创业者，如果你在刚开始算创业阶段，可能要先算好这笔账，就像当老师说的似的，你要先算好这笔账。在某个阶段有可能你真的需要部署一套你自己的满足你自己隐私需要、数据需要，或者说行业壁垒需要，或者说是你说响应速度需要的这么一套模型。然后和大模型做接入或者说做升级，这是一种情况。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:11",
      "text": "另外一种情况可能是一些成熟的企业，它需要什么呢？保护自己已经有的专有数据。我觉得未来数据还是最核心的，尤其是你积累了以前的数据，怎么去做标注，怎么样在模型中把它变成可以AI化的这么一个过程。这些是非常需要目前的人，有这种技知识技能的人去做的工作。对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:34",
      "text": "而且我插一句，最近open I就是小道消息，就是open I一直在请那个博士生去做人工标注，1个小时差不多100到200美金1个小时。没错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:45",
      "text": "它已经不是简单的猫狗的问题了，有很多专业性的东西。这个东西已经不是说一般人或者没有一定能耗和和知识背景和工作经验的人能够去做的事儿。所以我觉得这个就像我前一段时间有个朋友的孩子在学法律，就是说未来法律会不会被很多AI取代。我说起码在过去未来一段时间，一个好的会法律的律师可以做数据标注，这个事情就很值钱。其实我是这么说的，当然就是说他怎么能理解另外一回事儿，他会不会觉得这种羞辱。但我觉得这不是。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:16",
      "text": "专业领域的数据标注，就是你刚才讲的像律师这个领域，其实已经正在发型师。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:22",
      "text": "比如你说四大会计师，四大原来所谓四大，国内说四大出来的都觉得高人一等。那你说最终其实四大是在一个非常明确的，因为我本身就是会计师。在学的这个非常明确的法律标法律这个法规的要求之下去做这种标准化的操作，最终能够实现什么呢？就是说全球通用，或者说一个地区通用的这么一种会计准则的标准。那这种过程不是就正是AI所擅长的归纳推理总结最后输出或甚至多模态，对吧？但是真正的一个好的会计师，或者说未来都会有可能会做咨询师。他所有的know how最后形成是对一个特定的一个案例的判断和建议。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:00",
      "text": "这个反倒是现在通用大模型，我觉得是不具备的，是一定是具备需要有大量的数据，优质数据，和不断的客户反馈，并且能保证什么呢？就是客户数据的隐私。因为每个被审计的公司都要签保密协议，而且都不希望自己的数据在没有被公开之前或者没有被认证之前再发布出去。还有一些东西是永远不要被发布出去的。所以整个来讲，我认为就是对一个行业来讲，如果它严重依赖于自己的能耗，而且其因为这本身就是他行业的护城河，或者说人本身的这个差异性决定了这个公司服务的质量。那他一定要尽早去做AI的私有化。这个私有化是个绝对是个过程。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:38",
      "text": "我再插一句，就你刚才讲的像会计师跟律师这样的行业，它其实用AI的场景就是总结归纳生成。对，然后完全是可以布在本地的。但是他对于数据标注，数据质量严谨性、精确性要求又非常高，甚至是需要说用到专业人员的去标注。专业的一定的，我觉得。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:59",
      "text": "对的是一定。对对对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:01",
      "text": "他的可能的数据样本量不需要像大模型那么大。这个时候其实你就是需要去做本地部署，且需要去做好专业的数据标注的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:14",
      "text": "还有一个就是角度，从创业者的角度来讲，我觉得是什么是说DPCKR1的出现，让我们真正有机会去摸到这个就是呃大模型或者说AI模型。私有化这么一个过程，像以前如果是在o OpenAI时代，甚至说当时我们有拉玛，虽然有拉玛对吧？也在有很多人在讨论私有化，但是都没有到这个性能。那R一已经达到了，就是说O3的这个性能其实75%也好，85%也好，甚至有些地方超过了。那好，那就变成什么？就变成我们有机会去私有化。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:45",
      "text": "作为一个公司，如果你已经在创业路上，或者说已经甚至说相对来讲成功。那早晚既然知道早晚一个企业要AI化，那就赶快开始，对吧？这个过程本身可能需要很长，而且整个团队能不能适应还是有过程。所以我觉得这类公司反倒是最最的应该现在就动手开始做私有化。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:02",
      "text": "但是要想老修说的是，并不是说所谓私有化就是把所有的API的都抛弃，完全要自己去实现。而是说怎么样去用一个混合的方式做到说有一部分的这个东西是由ipad调用，有一部分是私有云的部署，有一部分是本地的这个机房也好，对物理性的这种数据的保存，然后再加上这种数据隔离访问隔离等等等东西。这过程很多公司都现在可能还只在停留在一个，怎么说呢？就是说犹豫阶段，但我是觉得根本不要犹豫，开始对这种才是真正私有化的意义。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:34",
      "text": "还有像就是你之前也比较了解，就像或者就是deep sick的老本行，量化是这一块，量化金融类的那这一类都是走这种强小模型，强本地模型这些数据的路线。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:49",
      "text": "以前就是走算法的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:50",
      "text": "对他也是不能去走太多的云端。当然就比如说你做一个金融产品，生成一些所谓的偏瘫化的一些投资建议，那这个可以走云端。一对，这个可以走一些云端，但是你要把它解构掉。但是从数据部分你就必须走本地，然后你再去做一个整合。所以这种就非常这种行业就会特别是架构。比如说像你刚才讲的律所这种行业，它可能生成不需要这么强的能力，他完全不用联网，其实就本地做，我觉得是OK的这这是OK的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:25",
      "text": "但是有一些像说金融类的，比如说你生成一些投资建议，生成一个下一步行动，或者做一些及早的根据一些波动情况做一些预警的解读。那你这里面是涉及到一些更好的文字生成的能力。那这个时候可能适度的有一些联网的这种需求，否则你无法去总结历史这么多的这种告诉他说，那那什么时候应该给你一段这样的话，这这是成本的，这是我觉得这是成本的问题。其实我觉得凡事还是要回到成本的问题去去思考。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:03",
      "text": "对，再插一句，我觉得还有一个个人的应用层面，就是所谓的私有化这个过程。这个层面是什么呢？就是刚才咱们说到了美国最后在手机端可以自己私有部署的这么一个场景。我个人考虑就是这种场景的应用是在什么呢？就是说他能够真正变成你的私人助手。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:20",
      "text": "这个私人助手都了解到什么？了解到你这最底层的一些东西。这些数据你是永远不希望，甚至说不是有现在有些这个视频玩的梗，有的时候有哪些事儿是你你让希望不希望你父母都知道，就是连你父母都不想告诉，对吧？那这种东西就是说肯定会有很多数据，或者说你的真正的一天的做的事情，希望能够无感的把它储存到你的本地。有点像笔记，但比笔记要高级很多。对，因为AI可以帮你去做复盘，而且是在你最完全可以说是你的一个半仙儿，他在你还没有说感知到或者说预判到的时候，他已经提醒到你了。那这种私人助手的需求会非常巨大。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:00",
      "text": "其实就是一种多模态的搜索。因为它的本质是说你把手机里面存储的数据，不管是图片、声音、文字，或者是GPS的定位，或者是各种难以用语言描述的东西。比如说定位这个事情就很难用语言描述。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:15",
      "text": "对吧？我我我觉得把它变成，对对我我我我我可能考虑它不是太完全一样。我更考虑是说它不是一个搜索，它有点像类似于我们以前所说的潜意识。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:26",
      "text": "就是说对我们不在你身边。对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:28",
      "text": "不是我们以前说的其实我们视觉接收到的信息量是很大的，非常大的对，几千个，比如说几万个比特，但是通过我们语言总能表达出来就几十个。然后通过我们平常能够处理的信息可能就几百个比特。比如说如果未来有一个什么通过手机什么方式或者摄像头的方式，能够把这几千几万个比特每时每刻都记录下来，然后在后台做处理，然后AI做整理，然后在你还没有意识到的时候，突然就就提醒到你了。对，这就是我们以前所谓的潜意识，就经常说这个。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:00",
      "text": "本质也是搜索，只是是你去搜还是机器自己搜。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:03",
      "text": "这对对对，而且这个机你主动搜可能发生的概率并更低，可能未来就是跟冰山原则，就是你可能主动搜索只剩20%，但是被动搜索可能占80%。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:13",
      "text": "对他这个业务流其实是搜索，然后生成跟推送是这三步。只是说是大家现在为什么在手机上AI用不起来，因为这个搜索是你主动去搜的，你要在相册里面搜小朋友吃冰淇淋。对，你现在有感受到对这个动作是需要花钱去培养的，就需要手机厂商投添那样的广告去培养这个用户习惯。但是他没有任何商业价值，对，没错，但是iphone做的很好。就是说他是主动去搜，然后告诉你去年今日。对你会发现他这一块做的越来越AI，或者是大家没有。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:49",
      "text": "去帮你去总结一些你里面照片里面最经常出现的几个人的一些memory，一些回忆。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:56",
      "text": "对对对，他这一块已经做的越来越好，而且悄无声息的加了很多AI在里面。只是说你平常你不会去关注，你不会去发现，其实siri在这一块其实蛮强大的对，之前老修我们也研究过这个事情。对。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:12",
      "text": "没错，这就有点像什么。比如说我们看一部电影经常会二刷、三刷、四刷，然后每次刷还要靠搞，说要找到一些新的细节。但未来可能用AI看一遍，然后后面你可以不断的刷。对，刷的是因为什么？AI告诉你说你有些细节你可能会关注没注意到，或者说他有一些浅层次的意义。这就是完完全全就是说你进入到了另一个思考维度上。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:32",
      "text": "我觉得就是这种文件夹式的数据结构会被改变掉。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:36",
      "text": "就是说这种东西很多人我觉得。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:39",
      "text": "最早用苹果，他其实就是不习惯那种迁移过来，就不习惯苹果这种怎么还没有批人的这种收集数据的方式。对。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:49",
      "text": "用文件夹新建文件夹，C盘、D盘、E盘。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:52",
      "text": "F盘没有这个东西了。但其实你你在你在加了AI以后，这个东西会更被弱化掉。我觉得那个追人会很难，他会非常难受。因为你无法去去分类了。因为你这个时候已经不需要分类了，不需要说对你也不需要去做笔记，你也不需要去做任何的记录，你也不需要担心说这条录音要不要放到笔记里面去，无所谓了。没错，不管它放在哪里。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:16",
      "text": "对，到那个时候我觉得人类的就是因为所有的现在所有的我们的发明都是人类肢体或者说功能的延伸，对吧？那到那时候真正做到大脑功能的延伸，就是我们已经不再受到信息处理能力的限制了，数据带宽的限制了。这个就是完全的，我觉得就是。现在智能的一个升级了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:34",
      "text": "就是上次跟玉博聊到的那个观点，就是说没错，还要不要有一个笔记本那样的？第二大脑没有必要了。对，第一大脑足够强就不需要第二大脑。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:44",
      "text": "第一大脑只需要阅读所谓的AI给我们的东西推送就好了，所以就刚才你说的输出推送的部分，那你说这个东西就这些数据针对非常个人的一些数据，对整个通用模型有什么意义吗？对他的训练有什么意义？我觉得是没有的。所以这些东西反倒最适合做本地化，而且它的比特非常少，可能真的就是0.5个bi或者怎么样就够了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:07",
      "text": "但是挑战也在这里，就是全世界90%的数据都在本地，都在端测。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:14",
      "text": "对，就是这样。所以通用模型就变成了真的是逻辑推理能力越来越强，处理能力越来越强，响应速度越来越快。但是本地的数据就越来越个性化，而且说本地的数据就越来越能够真正做到千人千就是千人千面。甚至说没通过你的不同心情、不同时间、不同场景都有不同的推送。不光是针对你这个人了，而针对你这个人不同时间的状态。对，就好像昨天的我和今天我到底是不是一个人，这可能都是可以算成两个人了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:41",
      "text": "没错，所以所以我我我借的这个事情就是我觉得最终就是回到设备本身，我觉得有这么大的数据量跟数据模型，就是这种数据形式，只有两个，一个车跟手机，就只有手机。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:02",
      "text": "对，也没准再有材料是材料学的升级，对吧？有可能另外一种存储方式的出现。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:09",
      "text": "对，有可能一些可其可穿戴的什么东西，只是我们现在不习惯。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:12",
      "text": "没有不习惯。对对对，就像我们现在充满的充电宝，其实不也就是一个充电的延伸。对，我们为了能够保证手机不断电，不也要拿着它吗？未来人类可能还是会有这种东西挂在身上的对。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:26",
      "text": "我最后还想补充一个，刚才贤哥那个东西给到想起一个今天看的新闻，特别好玩，就是可能是一个彩蛋，我觉得是留给我们听众的创业者彩蛋，我觉得一定要去关注RE的应用。刚才贤哥讲到那个是我们觉得说感觉可以想象到的很好的一个贴身的助理。其实这里面有一个延伸的点，这个东西是什么？就是你要想象它是一个可以举一反三的助理。他是知道你过去昨天怎么样，你今天有什么不一样的时候，我该问你什么问题。举一反三的助理，他举一反三的能力，现在我们看到的实际上是一个雏形。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:01",
      "text": "R1绝对不是一个终点的，而且应该是一个新的起点。它有一个很好玩的整活，就是是老外youtube油管上面有一个人，他拿ChatGPT去跟deep sick去下国际象棋，然后你们猜猜几个结果是什么样子，其实很好玩，他的情况很像阿尔法狗跟阿尔法zero的情况。前面是ChatGPT一直在赢，其实def CK不太能赢得了。他就两边都没怎么受过国际象棋的训练。但是那个ChatGPT整体毕竟跑了那么久，又有那么多的人工标注，还是很全面，其实还是很可以的，前面几乎都碾压他。他们就是在一个国际象棋的棋盘上面，他们模拟的棋盘上面下，然后下到后面出现什么样的反转，就开始了绝地反击。是什么？Deep seek开始用了很多人的想象不到的操作，那他他怎么说，他就是吓着吓着突然跟他说，你这里面这个皇后跟冰其实可以用另外一种走法，然后他就忽悠了ChatGPT这个指的走法都变了，然后就可以直接跨越原来的走法去吃掉人家的籽。甚至他后面还发现说。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:13",
      "text": "这会攻心的，对不对？",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:15",
      "text": "他就完全在棋盘之外，他知道说在现有的规则内好像玩不过他，然后他就在创造新的规则跟他玩。他就说那我们我们这次玩一盘那个冰可以走什么日字形，然后哪个可以走什么米字型？然后ChatGPT居然同意了，因为ChatGPT非常的善良，手续nice，然后你说要干嘛我们可以商量，然后就干了，干了以后就开始出现dept sik开始会赢了，就是在他DPC新建的这种规则之下，在GPT玩不过他，然后就在后面，但是拆GP也在调整到后面，拆GP也适应了，这些东西又能硬。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:49",
      "text": "然后DFC甚至出现了说他下到一个人一定局面以后，他觉得自己赢不了，他就开始去忽悠ChatGPT说，在我现在这种情况下，你胜率很低我一定可以赢。然后怎么说乱七八糟就忽悠了他一堆，然后下GPT也信了，直接投降了。然后这种他就赢法完全不是下棋赢的，就是都是棋盘外的方式。就是我想举这个例子，就是他真正的用上了我们什么？很多中国的旁观者看到说真正用上了孙子兵法就算了。很多这些就是我我们中国的一些套略，一些谋略的方式去改变规则。玩不过我就改变规则，然后不断的去推理，说根据对方的这个表现和对方的血腥的程度，不断的去换，然后增加自己的胜率的方式。然后下法已经都不是我们人类正常理解的国际象棋的下法了，但是他们最后得到一定程度的胜率，那就不会原来一直输那种情况。这个是很有意思的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:49",
      "text": "首先我就觉得说这个视频因为油管也许有些人看不到，那我先讲一下。但是如果能看得到，大家可以去找一找。就是这种东西我觉得对创业者其实是很直观的东西。就大家下棋我们很好理解。他这个推理用在这个地方，就是他在用到说他怎么去举一反三。我在下不过的时候，我怎么想办法想到了棋盘外的办法，攻心之术全部都用上了。这个东西是让我看到是觉得很有意思的一个应用，很奇葩笑但是你可以看到这样的一个角，就是他在没有接受过训练的东西下，他怎么样能够去达成他的目标，因为他的目标是要赢，那什么样的方式都搞出来了完了都想象不到这个事情我觉得是当做一个彩蛋。就是作为每个创业者，我觉得真的要去关注一下阿姨怎么用的，或者是怎么玩的。因为很多东西有可能就是在这里面，你有你会有灵感怎么把这种一种强推理的模型应用到你的那个场景里面去，就是解决一些你原来没想过可以用这种东西解决的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:49",
      "text": "对，但是还是会在变化，就推理之后是什么？对，有可能最早的从GPT破圈是靠归纳总结生成吧？然后到现在deep sick破圈靠的是推理，那可能明年又会有更新的变化。对，就你可能永远也不知道下一步是什么。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:09",
      "text": "所以就是说这个事情我们今天聊到这里，也不能完全为今天的结论负责任，对吧？就很难有一个很清晰的立场告诉大家要不要本地。但是只能告诉大家说，最好从成本的角度去想一想这个事情，你去做决定，不然就是可能投入了过重的成本在上面，但是整个技术溢出又把你给的的溢出效应，又把你的成本最后给淹没掉了，那其实是非常亏的一件事情。所以就是期待我们明年再聊一次要不要本地部署模型。或者我们有没有在看到更多的基于端侧智能的一些产品出现，颠覆了现有的这种一些产品的生态，产生更多的创意。就期待这个事情。我觉得最有意思的就是每天都有新事情发生，每天都有新事情可以聊，然后都可以聊的非常久。但是聊完以后你会发现第二天又变了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:08",
      "text": "是的，有意思就在这儿，真的是非常期待。",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:12",
      "text": "好好，这期节目就到这里结束了。如果大家也对AI的话题感兴趣，AI创业AI应用，请大家多多关心人民公园说AI，多多关心，多多订阅我们的节目。然后可以在小宇宙、苹果播客各大播客平台跟小红书收看我们的节目。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:36",
      "text": "感谢各位听众的陪伴，谢大家感谢谢谢各位，谢谢各位，拜拜快乐。好。",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:41",
      "text": "拜拜。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "本次讨论集中于AI模型，尤其是deep sk的本地部署问题，深入探讨了私有化部署的必要性与挑战，包括成本、速度、精确性与智能之间的平衡。强调了对于有特殊数据安全、隐私保护需求或需高度定制化解决方案的行业，私有化部署是必要的。此外，讨论扩展至AI在创业应用和企业流程优化中的潜力与难题，指出选择合适部署策略的重要性。最后，提醒听众应保持对新兴技术和应用的开放态度，随着技术进步，AI应用的边界和可能性将持续扩展。",
    "qa_pairs": [
      {
        "question": "最近有很多朋友问是否可以在本地部署DeepSK，你觉得普通人有没有意义，应该这么做吗？",
        "answer": "从可行性上来说，普通人很难做到。DeepSK对硬件有较高要求，比如独立显卡、高性能CPU等，大部分家庭电脑可能达不到要求，而且即使勉强启动，性能也可能很不理想，无法满足实际应用需求。",
        "time": "00:04:30"
      },
      {
        "question": "那么大家为何热衷于尝试本地部署DeepSK呢？",
        "answer": "大家想要本地部署DeepSK背后的心理主要有三种情况：一是出于数据安全考虑，担心云端服务不稳定或信息泄漏；二是出于探索和玩乐心态，想自己研究和把玩这个新技术；三是对现有大模型的某些局限性，如幻觉问题、长文本记忆性问题等，希望通过私有化部署进行一定程度的优化和补偿。",
        "time": "00:08:55"
      },
      {
        "question": "那么在什么情况下，真正有必要去做私有化部署呢？",
        "answer": "真正有需求进行私有化部署的情况主要体现在：数据安全性、专有know-how的保护、模型微调与升级的灵活性、以及对响应速度和稳定性有极高要求的场景，例如在精密仪器操控或实时反应的应用中，为了避免因云服务不可控性带来的风险，会选择本地私有化部署。",
        "time": "00:11:14"
      },
      {
        "question": "对于企业来说，从实际投产比来看，去私有化或本地部署的价值是否很高？小模型在实际应用中会面临什么问题？",
        "answer": "我个人认为，对于实力较强的企业而言，本地部署一套系统可能并不划算。混合方案可能会更好，即复杂场景走云端，基础场景走本地，这样响应速度更快。同时，未来可能会出现企业将压缩版的小模型部署在其他智能终端上的趋势。小模型虽然在推理和举一反三的能力上表现较好，但在面对未曾见过的基础知识时，由于蒸馏过程中只提取了精华知识，它们可能无法准确理解或回答相关问题。比如，在图像识别任务中，虽然小模型能大致区分狗的种类，但对于狼、狐狸等其他动物则无法做出准确区分。",
        "time": "00:12:57"
      },
      {
        "question": "那么小模型是否会随着场景需求的发展而出现更多，甚至达到专用模型的程度？",
        "answer": "一定会出现更小的模型，但需要针对特定场景进行调优。目前的1.5B大小模型虽然看起来很大，但在特定领域经过精简后，可能只需要0.15B大小就能满足行业需求。随着对不同行业知识的深入挖掘和提炼，专用模型将会发展出来，而且可能运行在手机等移动设备上。",
        "time": "00:18:51"
      },
      {
        "question": "现在是否已经有公司在尝试构建较小版本的模型，并通过蒸馏技术来实现模型压缩？",
        "answer": "是的，现在已经有公司在尝试这样做。蒸馏技术在模型压缩中起着关键作用，它的英文名称“distillation”实际上就是提取的意思。通过蒸馏过程，可以从一个大的标准模型（老师模型）中提取精华知识，形成较小的学生模型，这些模型可以在本地运行，但其综合能力可能不如大型模型。",
        "time": "00:13:58"
      },
      {
        "question": "对于企业来说，在考虑是否本地部署大模型或小模型时，应如何权衡成本、速度/精确性和智能这三个要素？",
        "answer": "企业需要根据自身需求动态地平衡这三个要素。如果追求智能，可能需要将需求放在云端；若追求低成本，则可将一些基础的、总结归纳能力的场景放在本地；若追求速度和精确性，则应使用自己训练过的预定义场景模型。隐私问题作为底线，在考虑是否私有化部署时，企业应结合商业模式、服务对象（to B还是to C）以及用户量级等因素综合判断。",
        "time": "00:21:16"
      },
      {
        "question": "苹果是否会考虑升级其策略，尤其是在AI模型的应用上？",
        "answer": "苹果应该会考虑升级策略，因为过去依赖合作伙伴的做法在中国等地方并不顺利。如果本地模型在手机上无法有效运行，那么在其他终端设备上的应用也会受到影响，因为这些设备本质上是手机的延伸。",
        "time": "00:25:51"
      },
      {
        "question": "为什么手机上的模型表现对其他终端设备如此重要？",
        "answer": "手机作为一个多模态终端，拥有多种传感器和输入输出设备，如果大模型在手机上无法构建出场景或达到预期性能，那么在眼镜、玩具等其他终端设备上的表现也会受限，最终会被手机进步带来的智能所淹没。",
        "time": "00:26:18"
      },
      {
        "question": "苹果近期是否有相关动作？",
        "answer": "苹果似乎在积极行动，例如开源了一个模型，并且有邮件声明与中国的d sak团队无关，强调数据存储在北美和符合本地数据需求的范围内，且不会离开西方国家。",
        "time": "00:27:42"
      },
      {
        "question": "开源模型与私有化部署之间有何区别？",
        "answer": "私有化部署涉及到配置调整和逻辑推理能力的问题，目前市面上的开源模型版本往往无法达到满血版性能。同时，联网搜索和function call等功能的优化是各大模型厂商的核心竞争力，不同厂商提供的解决方案会有差异。",
        "time": "00:28:44"
      },
      {
        "question": "对于大模型的应用，在本地部署时需要注意哪些问题？",
        "answer": "在本地部署时，需要解构需求，明确哪些部分可以通过本地模型或轻量级云服务实现，哪些部分必须依赖于大模型的推理能力。此外，还需考虑硬件成本、运维成本以及模型迭代周期等问题，确保架构设计合理且经济高效。",
        "time": "00:38:26"
      },
      {
        "question": "云端部署是否也有运维成本？",
        "answer": "当然，云端部署也有很高的运维成本。亚马逊云服务通过自建运维团队来养活庞大的运维人员，然后将服务卖给客户，其毛利较高。客户自己购买云端服务时，也需要自行安排运维工作，成本并不低。",
        "time": "00:41:17"
      },
      {
        "question": "本地部署的成本主要有哪些方面？",
        "answer": "本地部署除了硬件成本外，还包括运维成本，因为实体硬件需要调试和日常维护，可能需要不断请兼职人员协助解决网络、存储、安全防火墙等问题。",
        "time": "00:41:17"
      },
      {
        "question": "云端部署是否完全在本地机房？",
        "answer": "不是，也可以是本地与云端的混合部署，例如有些敏感数据需要在本地存储，计算部分放到云端。",
        "time": "00:40:16"
      },
      {
        "question": "使用云服务时，对于模型和运维方面存在哪些困难或成本？",
        "answer": "使用云服务时，除了模型本身的接入和定价问题，还有将云服务接入应用、成本调优、运维工程师介入等问题，这些都需要时间及专业人员的支持，以确保服务稳定运行并降低成本。",
        "time": "00:43:09"
      },
      {
        "question": "对于想要使用大模型的团队或个人，应该如何考虑架构和应用层面的问题？",
        "answer": "大模型的应用通常涉及归纳总结、推理等任务，本地可能更适合做归纳总结工作，而非复杂的推理。团队应明确自身定位，合理利用大模型技术，并结合数据、标注、多模态等构建独特的应用场景，而非从零研发大模型。同时，应考虑投入与产出，不一定非得自建大模型，而是结合现有技术及服务进行创新应用。",
        "time": "00:49:22"
      },
      {
        "question": "未来大模型是否会演变为电力公司，以及在何种情况下创业企业需要私有化部署模型？",
        "answer": "是的，未来可能像电力公司那样负责发电，而创业企业则专注于开发小电器。在创业初期或某个阶段，创业者可能需要部署一套满足隐私、数据安全、行业壁垒和响应速度要求的自有模型，并与大型模型进行接入或升级。另一种情况是成熟企业需要保护已有的专有数据。",
        "time": "00:52:45"
      },
      {
        "question": "私有化部署主要针对哪些场景或需求？",
        "answer": "主要针对两种需求：一是创业公司在特定发展阶段对数据隐私、行业壁垒或响应速度有特殊要求时；二是成熟企业为保护其专有数据而选择私有化部署。",
        "time": "00:52:45"
      },
      {
        "question": "数据标注工作是否适合被AI取代？",
        "answer": "数据标注工作目前还无法完全由AI取代，尤其是专业领域的数据标注，例如法律和会计等行业，这些领域正在寻求与AI结合，实现标准化操作，但真正的专业判断和建议仍需由具备专业知识的人完成。",
        "time": "00:54:16"
      },
      {
        "question": "AI私有化部署在量化金融等领域的应用是什么样的？",
        "answer": "量化金融等领域倾向于使用小模型和本地部署策略，但在某些场景下，如生成投资建议或预警解读等，也需要适度联网获取最新信息和总结历史数据的能力。",
        "time": "00:57:50"
      },
      {
        "question": "对于像律师、会计师这类依赖高度专业性和能耗的服务行业，如何考虑AI私有化部署？",
        "answer": "这类行业由于其业务特性，严重依赖自身的专业性和能耗，并且对数据隐私保护严格，因此更适合进行AI的私有化部署。同时，对于数据标注的质量和精确性要求较高，也需要本地的专业人员参与。",
        "time": "00:55:00"
      },
      {
        "question": "创业者是否应尽早开始着手AI私有化部署？",
        "answer": "是的，创业者应当利用像DPCKR1这样的技术进步机会，尽早开始私有化部署过程，以适应未来的发展趋势，并适应整个团队适应AI化的过程。",
        "time": "00:56:45"
      },
      {
        "question": "私有化部署是否意味着完全抛弃云端API，自行实现所有功能？",
        "answer": "不是这样的，私有化部署是采用混合方式，一部分通过云端调用，一部分进行私有云部署，一部分保留在本地机房，并确保数据隔离访问等安全措施。",
        "time": "00:57:02"
      },
      {
        "question": "个人层面，AI私有化部署能带来哪些应用场景？",
        "answer": "个人层面的应用场景是拥有一个私人助手，该助手能通过深度学习和智能搜索技术，对用户的手机本地数据进行实时分析和总结，提供无感提醒和复盘功能，实现多模态搜索和个性化服务，从而提升用户的日常生活体验和信息处理效率。",
        "time": "00:59:03"
      },
      {
        "question": "通用模型的发展趋势是什么？",
        "answer": "通用模型的逻辑推理能力、处理能力和响应速度正在变得越来越强，而本地数据则越来越个性化，能够实现千人千面的推送。不仅针对个人，还针对人在不同时间、不同场景下的需求变化。",
        "time": "01:04:14"
      },
      {
        "question": "目前数据形式的主要载体是什么？未来可能还会有哪些发展？",
        "answer": "目前主要有手机这一载体，未来可能由于材料学升级或新的存储方式出现，甚至可穿戴设备也会成为数据形式的一部分，就像现在的充电宝一样，人们可能会习惯于使用挂在身上的设备来保证数据和设备的不断电。",
        "time": "01:05:02"
      },
      {
        "question": "对于RE的应用有何看法？",
        "answer": "RE是一个具有举一反三能力的贴身助理应用，能够根据用户过去的行为和当前状态进行适应性互动。它不仅是现有技术的一个雏形，而且是一个新的起点，展示了人工智能在理解和运用策略、谋略层面的应用潜力，比如通过改变规则和推理来达到目标。",
        "time": "01:05:26"
      },
      {
        "question": "如何看待ChatGPT与Deep SIC在国际象棋对弈中的表现？",
        "answer": "在这场对弈中，Deep SIC通过创新和适应变化，利用非传统走法和攻心战术战胜了预期中表现更优的ChatGPT。这个例子生动展示了AI在面对复杂问题时，如何运用强推理模型去尝试、调整并创造新的解决方案，这对于创业者来说是一个很好的启示。",
        "time": "01:06:01"
      },
      {
        "question": "对于AI模型部署是否应本地化有何建议？",
        "answer": "对于AI模型是否应本地化的问题，建议从成本角度考虑，避免投入过重的成本而被技术溢出所淹没，造成不必要的损失。随着AI技术的不断更新变化，需要持续关注并探讨最优部署方案。",
        "time": "01:10:09"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "DeepSick是否适合本地部署的探讨",
        "summary": "播客主播与老徐讨论了DeepSick在本地部署的可能性及其背后的原因。讨论指出，DeepSick的出现类似于AI领域的“安卓时刻”，引发了广泛讨论和使用，让更多人开始接触和了解AI。主播提出了普通人是否适合在本地部署DeepSick的问题，并询问老徐对此的可行性看法。"
      },
      {
        "time": "00:04:28",
        "title": "大模型本地部署的硬件门槛与心理驱动",
        "summary": "对话围绕大模型本地部署的硬件要求展开，指出这需要较高的硬件配置，如独立显卡和四核以上CPU，且即便是配置较高的设备也只能勉强运行某些模型，体验并不理想。进一步讨论了人们为何仍倾向于本地部署大模型的心理动机，即使云端服务提供了相对便捷的解决方案。"
      },
      {
        "time": "00:09:38",
        "title": "探讨私有化部署AI系统的需求与动机",
        "summary": "对话围绕私有化部署AI系统的动机进行了深入讨论，指出四种主要心态：对数据安全和专有知识的保护、对新技术的好奇和探索、对技术新鲜感的讨论，以及对大模型局限性的补偿与优化需求。其中，第四种心态被认为是真正的需求，涉及到大模型的幻觉问题、长文本记忆能力、专有知识的训练、响应速度和可控性等关键问题。"
      },
      {
        "time": "00:12:56",
        "title": "混合部署与模型蒸馏在AI应用中的未来趋势",
        "summary": "讨论指出，对于企业尤其是创业公司而言，混合部署方案在AI应用中更具价值，即复杂任务在云端处理，基础任务本地化以提升响应速度。此外，提及了模型蒸馏技术，通过将大型模型的知识“蒸馏”到小型模型中，实现轻量化部署，尤其适用于智能终端。蒸馏模型虽在推理能力上接近大型模型，但在基础知识掌握上有所欠缺，类似于通过大量练习掌握特定问题解决技巧，但缺乏对底层原理的理解。蒸馏模型在特定领域表现良好，但在面对未见过的样本时可能无法识别。"
      },
      {
        "time": "00:18:51",
        "title": "企业级AI模型的优化与应用策略",
        "summary": "讨论集中在如何根据特定行业和场景优化AI模型，特别是减少模型大小以适应实际需求，例如从1.5B参数减少到可能只需要0.15B参数即可满足行业需求。此外，讨论还涉及了在企业内部应用AI模型时的成本、速度、精确性以及智能程度的平衡问题，指出企业应根据自身需求选择是否部署本地模型或使用云端服务，以及如何解构需求以优化模型应用。"
      },
      {
        "time": "00:23:16",
        "title": "AI部署决策：本地部署与API使用策略",
        "summary": "对话围绕AI部署决策中的关键因素展开，讨论了私有化部署与使用API的成本、效率和适用场景。提出在初期创业或用户量级较低时，优先考虑打磨产品和商业模式，利用API进行AI功能的快速部署。随着用户量的增长，私有化部署能提供更高的效率和成本效益，尤其是在处理大量重复性问题时。同时，讨论了行业地位、赚钱方式（如提供专家级服务或低价策略）对部署策略的影响，并提到苹果等公司可能正在优化其AI策略，以适应不断变化的市场需求。"
      },
      {
        "time": "00:26:18",
        "title": "手机作为多模态终端对AI设备的影响",
        "summary": "对话围绕手机作为多模态终端在AI设备中的核心地位展开，强调如果手机无法有效运行大模型，那么其他终端设备如眼镜和玩具也难以实现高性能的智能场景。手机因其内置的多种传感器和功能，如摄像头、传感器、陀螺仪、GPS、扬声器和麦克风，成为一个立体互动的终端。此外，讨论还涉及了苹果在AI领域的进展以及开源模型的接入，以及相关数据存储和隐私保护的问题。"
      },
      {
        "time": "00:28:44",
        "title": "私有化部署大模型的性能差异及优化挑战",
        "summary": "对话讨论了私有化部署人工智能模型时遇到的性能和逻辑推理能力的差异问题。指出，尽管市场上有多种自部署的推理引擎（RE），但它们往往无法达到开发者版本（dev CK）的满血性能和推理能力，因为背后需要复杂的配置和调优。此外，提到了深度思考和联网搜索是模型的关键功能，而各大模型厂商在这些功能上的调优差异导致了最终性能的差异。还讨论了模型在实际运营中可能受到的性能限制，以及初创公司在硬件资源有限的情况下如何通过动态调整来优化服务。最后，通过类比云服务和AI模型的关系，强调了大厂和小厂在提供稳定云服务上的能力差异。"
      },
      {
        "time": "00:33:28",
        "title": "大模型本地化部署的挑战与成本考量",
        "summary": "对话围绕大模型如DeepSick在本地化部署中的挑战和成本问题展开。首先强调了大模型的推理能力是其核心价值，但在本地化部署时，需要平衡算力、网络成本以及推理需求。建议首先从需求出发，识别哪些逻辑必须通过深度推理实现，以优化成本。指出本地化不仅涉及推理相关的服务器，还包括存储、网络、安全等基础设施，以及运维成本和硬件迭代成本。云端部署相对灵活，可以更容易地应对模型迭代，而本地部署则需要更多实体硬件和兼职人员的支持，增加了隐性成本。"
      },
      {
        "time": "00:39:44",
        "title": "本地部署与云端部署的混合应用及成本问题",
        "summary": "对话讨论了本地部署和云端部署的概念，包括完全本地部署和混合云部署，后者结合了本地机房与云端计算。提到了敏感行业如电力和医疗的数据安全问题，以及在云端部署时可能面临的复杂运维和持续升级成本，强调了运维工程师在云端部署中的重要性和隐性成本。此外，还探讨了不同云服务提供商如腾讯云、华为云、亚马逊云和微软云在全球范围内的应用和选择问题。"
      },
      {
        "time": "00:42:31",
        "title": "云计算与AI模型开发的挑战与策略",
        "summary": "对话围绕云计算服务商对接开源AI模型R1的快速部署以及相关成本和效率问题展开。讨论指出，云服务商利用丰富的工程师资源，能在短时间内完成模型的接入和定价，但将这些服务整合到具体应用中仍需时间。此外，对话强调了将推理和智能处理放在云端的混合云架构优势，以及本地部署高使用频率但确定性高的任务以降低成本的策略。同时，提到了Deep Sick和OpenAI等公司在AI模型开发上的聚焦策略和人才成本，以及他们如何通过投资方式扩展到应用领域，以应对技术、人才和成本的挑战。"
      },
      {
        "time": "00:48:20",
        "title": "大模型应用与私有化部署的必要性探讨",
        "summary": "讨论强调了大模型在归纳总结与推理两个主要功能上的应用，并对比分析了在本地部署大模型的必要性。提出将大模型类比为电力供应，认为大多数情况下，使用现有大模型的服务比自行部署更为经济和高效。此外，还探讨了技术解构、多模态应用以及数据标注在构建个性化大模型场景中的重要性，最后指出，创业企业应更多关注于如何利用大模型来满足用户的实际需求，而非投入资源自行构建大模型。"
      },
      {
        "time": "00:52:45",
        "title": "创业与企业AI模型的私有化及数据标注需求",
        "summary": "对话围绕创业者和成熟企业在AI模型私有化及其数据标注需求上的讨论展开。创业者在初期需考虑部署满足隐私、数据或行业壁垒需求的模型，而成熟企业则需保护专有数据，进行专业数据标注以实现AI化。提及了专业数据标注的高价值和专业性，以及AI在专业领域如法律、会计中的应用潜力。强调了行业依赖于自身能耗和数据隐私的重要性，以及AI模型私有化的机会和必要性。"
      },
      {
        "time": "00:56:44",
        "title": "企业AI化及私有化策略",
        "summary": "对话强调了企业应尽早开始AI化和私有化的过程，指出这一过程可能漫长且需要团队适应。讨论了混合方式的重要性，即部分功能由API调用，部分功能在私有云或本地部署，同时强调数据隔离和访问隔离。提到了金融类行业特别适合使用强本地模型和数据处理，但生成投资建议等可能需要适度的云端连接。最终，建议企业在考虑私有化和AI化时，需回归成本问题进行思考。"
      },
      {
        "time": "00:59:02",
        "title": "未来的个人AI助手及其多模态数据处理",
        "summary": "对话围绕未来个人AI助手的发展进行了深入探讨，重点强调了这种AI助手能够深度理解并处理个人的多模态数据，包括图片、声音、文字、GPS定位等，从而在用户尚未意识到需求时提前提供服务。讨论还提及了当前手机厂商在AI应用上的进展，比如通过AI整理和提醒用户过去的数据和回忆，以及未来可能的被动搜索趋势，预示着AI助手将在日常生活中扮演更加重要的角色。"
      },
      {
        "time": "01:02:32",
        "title": "AI技术对未来个人数据管理和个性化推送的影响",
        "summary": "对话探讨了AI技术如何改变个人数据的管理方式，以及如何通过AI实现更个性化和场景化的信息推送。讨论指出，传统的文件夹式数据结构可能因AI技术的普及而被弱化，人们将不再需要手动分类和记录信息。同时，强调了本地化数据的重要性，以及这些个性化数据对通用模型训练的意义。此外，还提到了未来设备，如手机和可穿戴设备，在处理大量个性化数据方面的潜力。最后，讨论提到了AI助理的未来，包括其举一反三的能力，以更好地适应用户的个人需求和状态变化。"
      },
      {
        "time": "01:06:01",
        "title": "ChatGPT与Deep Seek下棋的创新策略及AI创业启示",
        "summary": "在一段对话中，讨论了通过YouTube上的一个视频，展示ChatGPT与Deep Seek进行国际象棋比赛的有趣场景。视频中，Deep Seek通过创新的策略和改变游戏规则的方法，成功逆袭并取得胜利。这一案例不仅展示了人工智能在面对未知挑战时的适应性和创造性，也给创业者带来了启示，即在面对困境时，可以尝试跳出传统框架，寻找棋盘外的解决方案。此外，对话还提到AI技术的快速发展和不断变化，强调了创业者在决定是否进行本地部署模型时应考虑成本和未来技术溢出效应的重要性。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "高端显卡（数千元级别）"
                },
                {
                  "children": [],
                  "content": "CPU至少四核八线程，推荐八核以上"
                },
                {
                  "children": [],
                  "content": "内存至少16GB，推荐更高"
                }
              ],
              "content": "硬件需求"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "推理能力受限，响应速度慢"
                },
                {
                  "children": [],
                  "content": "实际体验可能远低于云端服务"
                }
              ],
              "content": "实际运行问题"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对于普通用户，硬件升级成本高"
                },
                {
                  "children": [],
                  "content": "维护与升级成本不容忽视"
                }
              ],
              "content": "成本考量"
            }
          ],
          "content": "本地部署DeepSeek的可行性与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "特定行业对数据安全有极高要求"
                }
              ],
              "content": "隐私与安全考量"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对新技术的好奇与探索欲"
                }
              ],
              "content": "玩味心态"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "高效响应与定制化需求"
                }
              ],
              "content": "实用性需求"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "平衡成本、速度、精确性与智能"
                }
              ],
              "content": "成本效益分析"
            }
          ],
          "content": "需求与心理分析"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "适用于手机等终端设备"
                },
                {
                  "children": [],
                  "content": "专注特定场景，如多模态搜索、个性化推荐"
                }
              ],
              "content": "小模型（如DeepSeek的轻量化版本）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强大的推理与逻辑能力"
                },
                {
                  "children": [],
                  "content": "更适用于复杂决策与深度分析"
                }
              ],
              "content": "大模型（如DeepSeek满血版）"
            }
          ],
          "content": "小模型与大模型的应用场景"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "核心推理能力依赖云端"
                },
                {
                  "children": [],
                  "content": "基础归纳总结能力本地化，提高响应速度"
                }
              ],
              "content": "混合云架构"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "初创阶段，优先考虑API调用成本与效率"
                },
                {
                  "children": [],
                  "content": "成熟企业，注重数据安全与专有知识保护"
                }
              ],
              "content": "成本与效率平衡"
            }
          ],
          "content": "架构与部署策略"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "私有化部署成为可能，但需综合考量"
                },
                {
                  "children": [],
                  "content": "个性化AI助手，深度理解用户需求与状态"
                }
              ],
              "content": "AI模型的普及与个性化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "手机与车辆成为承载大量本地数据的主要设备"
                },
                {
                  "children": [],
                  "content": "端侧智能的重要性提升，多模态数据处理需求增加"
                }
              ],
              "content": "设备与数据形态的演变"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强推理模型的应用探索，如DeepSeek在非传统棋局中的创新策略"
                },
                {
                  "children": [],
                  "content": "持续关注AI模型的进化，预测未来应用方向"
                }
              ],
              "content": "技术迭代与应用创新"
            }
          ],
          "content": "未来趋势与展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "AI技术快速迭代，需灵活调整策略"
                },
                {
                  "children": [],
                  "content": "平衡成本与效率，探索最适合的部署模式"
                },
                {
                  "children": [],
                  "content": "预见未来趋势，提前布局个性化与端侧智能应用"
                }
              ],
              "content": "持续关注与灵活应对"
            }
          ],
          "content": "结论"
        }
      ],
      "content": "人民公园说AI - 深度探讨DeepSeek本地部署及未来趋势"
    }
  }
}